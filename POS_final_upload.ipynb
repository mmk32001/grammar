{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cfmN7Awk-XC",
        "outputId": "44e3449c-19ea-48c8-8261-79c503c6aec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs0Auaz5BJ1X",
        "outputId": "00f89e3c-656d-40b1-8a3b-b3783e4c9d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (3.10.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm0Wo8uAlefe",
        "outputId": "08f4482e-03ad-45a6-bd78-0c387ef88e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.11.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.4.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.13.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHNu3tc7leiR",
        "outputId": "6c4b5ae5-168d-4d27-aab9-7bbf400f5a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dataset in /usr/local/lib/python3.9/dist-packages (1.6.0)\n",
            "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from dataset) (1.4.47)\n",
            "Requirement already satisfied: alembic>=0.6.2 in /usr/local/lib/python3.9/dist-packages (from dataset) (1.10.2)\n",
            "Requirement already satisfied: banal>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from dataset) (1.0.6)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=0.6.2->dataset) (4.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=0.6.2->dataset) (1.2.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtNv-FWYoozL",
        "outputId": "b8b51690-45e7-49dd-c241-64876e48c6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: neptune-client in /usr/local/lib/python3.9/dist-packages (1.1.1)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.9/dist-packages (from neptune-client) (2.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (8.1.3)\n",
            "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (11.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from neptune-client) (5.9.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from neptune-client) (1.4.4)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (1.3.1)\n",
            "Requirement already satisfied: boto3>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (1.26.103)\n",
            "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (3.0.3)\n",
            "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (2.27.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (1.26.15)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (8.4.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (0.18.3)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (3.2.2)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (3.1.31)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from neptune-client) (23.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from neptune-client) (1.16.0)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3>=1.16.0->neptune-client) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.103 in /usr/local/lib/python3.9/dist-packages (from boto3>=1.16.0->neptune-client) (1.29.103)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3>=1.16.0->neptune-client) (1.0.1)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.5.0)\n",
            "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (5.17.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=2.0.8->neptune-client) (4.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->neptune-client) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->neptune-client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->neptune-client) (2.0.12)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.3.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neptune-client) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas->neptune-client) (1.22.4)\n",
            "Requirement already satisfied: jsonref in /usr/local/lib/python3.9/dist-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.19.3)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (20.11.0)\n",
            "Requirement already satisfied: rfc3987 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.8)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.1)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.1.4)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.13)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2.3)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.3)\n"
          ]
        }
      ],
      "source": [
        "pip install neptune-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "LNw6BDYZoybh",
        "outputId": "1ce1db0f-53bd-4cd3-93e7-15c6bc503ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting awscli\n",
            "  Using cached awscli-1.27.103-py3-none-any.whl (4.0 MB)\n",
            "Collecting six\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting PyYAML<5.5,>=3.10\n",
            "  Using cached PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
            "Collecting docutils<0.17,>=0.10\n",
            "  Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "Collecting botocore==1.29.103\n",
            "  Using cached botocore-1.29.103-py3-none-any.whl (10.6 MB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "Collecting colorama<0.4.5,>=0.2.5\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting rsa<4.8,>=3.1.2\n",
            "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.1\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Installing collected packages: pyasn1, urllib3, six, rsa, PyYAML, jmespath, docutils, colorama, python-dateutil, botocore, s3transfer, awscli\n",
            "Successfully installed PyYAML-6.0 awscli-1.27.103 botocore-1.29.103 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 pyasn1-0.4.8 python-dateutil-2.8.2 rsa-4.9 s3transfer-0.6.0 six-1.16.0 urllib3-1.26.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "colorama",
                  "dateutil",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install awscli --ignore-installed six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adC32NMdo4hD",
        "outputId": "6df95ecc-b070-44cf-8f4f-40d4abcea18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/neptune/internal/backends/hosted_client.py:50: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
            "  from neptune.version import version as neptune_client_version\n",
            "<ipython-input-7-37c521bab1e7>:1: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
            "  import neptune.new as neptune\n"
          ]
        }
      ],
      "source": [
        "import neptune.new as neptune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQnsnY6oo-tY",
        "outputId": "93cf0ab3-2b87-4bc4-c4f4-1d9dea72a49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-14da174bcf50>:1: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
            "  run = neptune.init_run(project = \"mmk32001/ner-project\", api_token =\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2MWM4MjBkNy1mYjliLTRjZTQtYmZiMi0zODMxNWQwZTM2M2YifQ==\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/mmk32001/ner-project/e/NER-61\n"
          ]
        }
      ],
      "source": [
        "run = neptune.init_run(project = \"mmk32001/ner-project\", api_token =\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2MWM4MjBkNy1mYjliLTRjZTQtYmZiMi0zODMxNWQwZTM2M2YifQ==\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cgr_hO5zemP",
        "outputId": "27c63cb2-5e47-4c10-876a-7d8ea5e51312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING"
      ],
      "metadata": {
        "id": "U5kycxetgEgo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ExnZzN6V3FZH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tAtPKast3Fb4"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/english_sent.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3nEYGm4x3Fev",
        "outputId": "dfc9442a-2246-473e-cc38-1169c5ae6b85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0                                           sentence\n",
              "0                0           It is the county seat of Alfalfa County.\n",
              "1                1  Cherokee is a city of Oklahoma in the United S...\n",
              "2                2  Skateboard decks are normally between 28 and 3...\n",
              "3                3  The bottom of the deck can be printed with a d...\n",
              "4                4  The longboard was made by two surfers  Ben Wha...\n",
              "...            ...                                                ...\n",
              "166409      166409  Caffiers is a commune  It is found in the regi...\n",
              "166410      166410       549 people were living in Orange as of 2000.\n",
              "166411      166411  Orange is a town of Juneau County in the state...\n",
              "166412      166412  Orainville is a commune  It is found in the re...\n",
              "166413      166413  A text editor is a program that is run on a co...\n",
              "\n",
              "[166414 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f28a2d92-e0ff-4126-8511-1f4fcd3179f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>It is the county seat of Alfalfa County.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cherokee is a city of Oklahoma in the United S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Skateboard decks are normally between 28 and 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The bottom of the deck can be printed with a d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The longboard was made by two surfers  Ben Wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166409</th>\n",
              "      <td>166409</td>\n",
              "      <td>Caffiers is a commune  It is found in the regi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166410</th>\n",
              "      <td>166410</td>\n",
              "      <td>549 people were living in Orange as of 2000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166411</th>\n",
              "      <td>166411</td>\n",
              "      <td>Orange is a town of Juneau County in the state...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166412</th>\n",
              "      <td>166412</td>\n",
              "      <td>Orainville is a commune  It is found in the re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166413</th>\n",
              "      <td>166413</td>\n",
              "      <td>A text editor is a program that is run on a co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>166414 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f28a2d92-e0ff-4126-8511-1f4fcd3179f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f28a2d92-e0ff-4126-8511-1f4fcd3179f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f28a2d92-e0ff-4126-8511-1f4fcd3179f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODp8QGrI3Fhh",
        "outputId": "87a9512c-308a-476a-83c2-68ada6ecadfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "sentence      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vRGIA5yU3FmJ"
      },
      "outputs": [],
      "source": [
        "def replace_spaces(x):\n",
        "  return x.replace(\"  \",\" \")\n",
        "\n",
        "def replace_fullstop(x):\n",
        "  return x.replace(\" .\",\".\")\n",
        "\n",
        "def get_pos(x):\n",
        "  doc = nlp(x)\n",
        "  li = []\n",
        "  for x in doc:\n",
        "    li.append(x.pos_)\n",
        "  return li\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0Qqbl_G-5W2t"
      },
      "outputs": [],
      "source": [
        "data[\"sentence\"] = data[\"sentence\"].apply(replace_spaces)\n",
        "\n",
        "data[\"sentence\"] = data[\"sentence\"].apply(replace_fullstop)\n",
        "\n",
        "df_pos = data[\"sentence\"][:30000].apply(get_pos)         #pos of 30000 sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gOwUIhJ53Fpk",
        "outputId": "c9b9378b-4a82-4c16-a2b8-c9168cb7a1e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index                                           sentence  \\\n",
              "0          0           It is the county seat of Alfalfa County.   \n",
              "1          1  Cherokee is a city of Oklahoma in the United S...   \n",
              "2          2  Skateboard decks are normally between 28 and 3...   \n",
              "3          3  The bottom of the deck can be printed with a d...   \n",
              "4          4  The longboard was made by two surfers Ben What...   \n",
              "...      ...                                                ...   \n",
              "29995  29995  Marlboro currently sponsors the Ducati MotoGP ...   \n",
              "29996  29996  During the 2007 GP2 Series Season ART Grand Pr...   \n",
              "29997  29997  In 2006 a Marlborosponsored car won the Indian...   \n",
              "29998  29998  Marlboro also sponsored Scuderia Ferrari as se...   \n",
              "29999  29999  In mid2006 special racing editions of Marlboro...   \n",
              "\n",
              "                                                     pos  \n",
              "0      [PRON, AUX, DET, NOUN, NOUN, ADP, PROPN, PROPN...  \n",
              "1      [PROPN, AUX, DET, NOUN, ADP, PROPN, ADP, DET, ...  \n",
              "2      [ADJ, NOUN, AUX, ADV, ADP, NUM, CCONJ, NUM, NO...  \n",
              "3      [DET, NOUN, ADP, DET, NOUN, AUX, AUX, VERB, AD...  \n",
              "4      [DET, NOUN, AUX, VERB, ADP, NUM, NOUN, PROPN, ...  \n",
              "...                                                  ...  \n",
              "29995  [PROPN, ADV, VERB, DET, PROPN, PROPN, ADP, ADP...  \n",
              "29996  [ADP, DET, NUM, PROPN, PROPN, PROPN, PROPN, PR...  \n",
              "29997  [ADP, NUM, DET, PROPN, NOUN, VERB, DET, PROPN,...  \n",
              "29998  [PROPN, ADV, VERB, PROPN, PROPN, SCONJ, ADJ, N...  \n",
              "29999  [ADP, NOUN, ADJ, NOUN, NOUN, ADP, PROPN, PROPN...  \n",
              "\n",
              "[30000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9095063-023f-4c9c-823a-41080636dc11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>It is the county seat of Alfalfa County.</td>\n",
              "      <td>[PRON, AUX, DET, NOUN, NOUN, ADP, PROPN, PROPN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cherokee is a city of Oklahoma in the United S...</td>\n",
              "      <td>[PROPN, AUX, DET, NOUN, ADP, PROPN, ADP, DET, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Skateboard decks are normally between 28 and 3...</td>\n",
              "      <td>[ADJ, NOUN, AUX, ADV, ADP, NUM, CCONJ, NUM, NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The bottom of the deck can be printed with a d...</td>\n",
              "      <td>[DET, NOUN, ADP, DET, NOUN, AUX, AUX, VERB, AD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The longboard was made by two surfers Ben What...</td>\n",
              "      <td>[DET, NOUN, AUX, VERB, ADP, NUM, NOUN, PROPN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>29995</td>\n",
              "      <td>Marlboro currently sponsors the Ducati MotoGP ...</td>\n",
              "      <td>[PROPN, ADV, VERB, DET, PROPN, PROPN, ADP, ADP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>29996</td>\n",
              "      <td>During the 2007 GP2 Series Season ART Grand Pr...</td>\n",
              "      <td>[ADP, DET, NUM, PROPN, PROPN, PROPN, PROPN, PR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>29997</td>\n",
              "      <td>In 2006 a Marlborosponsored car won the Indian...</td>\n",
              "      <td>[ADP, NUM, DET, PROPN, NOUN, VERB, DET, PROPN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>29998</td>\n",
              "      <td>Marlboro also sponsored Scuderia Ferrari as se...</td>\n",
              "      <td>[PROPN, ADV, VERB, PROPN, PROPN, SCONJ, ADJ, N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>29999</td>\n",
              "      <td>In mid2006 special racing editions of Marlboro...</td>\n",
              "      <td>[ADP, NOUN, ADJ, NOUN, NOUN, ADP, PROPN, PROPN...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9095063-023f-4c9c-823a-41080636dc11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9095063-023f-4c9c-823a-41080636dc11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9095063-023f-4c9c-823a-41080636dc11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "small = data[0:30000]\n",
        "my_df = pd.concat([small,df_pos],axis=1)\n",
        "my_df.columns = [\"index\",\"sentence\",\"pos\"]\n",
        "\n",
        "my_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF9wo11X3Fse",
        "outputId": "a8984e86-36a3-4b45-ac5c-92fb7d888f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'AUX', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADJ', 'ADV', 'NUM', 'CCONJ', 'VERB', 'SPACE', 'PART', 'SCONJ', 'X', 'INTJ', 'SYM']\n",
            "18\n",
            "{'PRON': 0, 'AUX': 1, 'DET': 2, 'NOUN': 3, 'ADP': 4, 'PROPN': 5, 'PUNCT': 6, 'ADJ': 7, 'ADV': 8, 'NUM': 9, 'CCONJ': 10, 'VERB': 11, 'SPACE': 12, 'PART': 13, 'SCONJ': 14, 'X': 15, 'INTJ': 16, 'SYM': 17}\n"
          ]
        }
      ],
      "source": [
        "def print_len_sent(x):\n",
        "  return len(x.split(\" \"))\n",
        "\n",
        "def print_len_pos(x):\n",
        "  return len(x)\n",
        "\n",
        "m = my_df[\"sentence\"].apply(print_len_sent) \n",
        "\n",
        "n = my_df[\"pos\"].apply(print_len_pos)\n",
        "lis = []\n",
        "li =[]\n",
        "\n",
        "unique_pos = []\n",
        "\n",
        "for i in range(30000):\n",
        "  #print(m[i], n[i], n[i]-m[i])\n",
        "  if n[i]-m[i] != 1:\n",
        "    lis.append(my_df[\"index\"][i])\n",
        "    li.append(n[i]-m[i])\n",
        "    \n",
        "  pos_curr = my_df[\"pos\"][i]\n",
        "  for i in range(len(pos_curr)):\n",
        "    if pos_curr[i] not in unique_pos:\n",
        "      unique_pos.append(pos_curr[i])\n",
        "\n",
        "print(unique_pos)\n",
        "print(len(unique_pos))\n",
        "\n",
        "pos_to_num = {k:v for v,k in enumerate(unique_pos)}\n",
        "print(pos_to_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfaNDF5KM1Z2",
        "outputId": "72956288-945c-4a71-98b5-927d7b04fd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31, 33, 34, 51, 59, 108, 386, 390, 395, 399, 479, 575, 608, 660, 854, 931, 1332, 1385, 1393, 1410, 1727, 1740, 1750, 1769, 1783, 1802, 1959, 1960, 1961, 2081, 2375, 2429, 2472, 2597, 2798, 2936, 2978, 2985, 2993, 3138, 3203, 3743, 3793, 4190, 4325, 4339, 4354, 4364, 4404, 4459, 4671, 4737, 4779, 4901, 5115, 5162, 5518, 5646, 5658, 5820, 6006, 6704, 6737, 6806, 6840, 6867, 7240, 7387, 7427, 8265, 8464, 8491, 8552, 8554, 8555, 8556, 8568, 8824, 8825, 8828, 8829, 8830, 8965, 9018, 9110, 9209, 9339, 9850, 9943, 10012, 10017, 10426, 10463, 10543, 10581, 10705, 10726, 11519, 11619, 11797, 11802, 11870, 12120, 12220, 13105, 13126, 13157, 13400, 13709, 13733, 13869, 13918, 14003, 14205, 14339, 14430, 14541, 14656, 14770, 14891, 15020, 15072, 15073, 15083, 15296, 15388, 15593, 15602, 15947, 15956, 16062, 16068, 16070, 16166, 16288, 16313, 16341, 16866, 16972, 17021, 17040, 17178, 17216, 17666, 17926, 17963, 18231, 18302, 18610, 18725, 19169, 19268, 19556, 19920, 19960, 20031, 20047, 20111, 20122, 20189, 20202, 20496, 20580, 20600, 21254, 21417, 21421, 21485, 21612, 21614, 21738, 21778, 21916, 21926, 21999, 22058, 22111, 22173, 22174, 22175, 22192, 22402, 22414, 22865, 22889, 23107, 23360, 23380, 23408, 23515, 23903, 24050, 24133, 24221, 24491, 24495, 24535, 24576, 24611, 25140, 25146, 25339, 25345, 25357, 25389, 25475, 25493, 25494, 25661, 25810, 25821, 25912, 26232, 26251, 26352, 26353, 26445, 26596, 26652, 26674, 26700, 26717, 26781, 26883, 27067, 27114, 27432, 27453, 27899, 28137, 28409, 28462, 28563, 28606, 28754, 28829, 28840, 29133, 29249, 29291, 29392, 29432, 29470, 29579, 29838, 29894, 29907, 29970]\n"
          ]
        }
      ],
      "source": [
        "print(lis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IryT6-CI6Pnc"
      },
      "outputs": [],
      "source": [
        "for i in range(len(lis)):\n",
        "  index_name = my_df[my_df['index'] == lis[i] ].index\n",
        "  my_df.drop(index_name, inplace = True)   # inplace false means it will return a copy of our dataframe(means the index will get arranged again from 0 in sequence)\n",
        "\n",
        "my_df.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pwU4jROt6Uwv",
        "outputId": "1664873c-ea89-426f-e852-044ceb6c6433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       level_0                                           sentence  \\\n",
              "0            0           It is the county seat of Alfalfa County.   \n",
              "1            1  Cherokee is a city of Oklahoma in the United S...   \n",
              "2            2  Skateboard decks are normally between 28 and 3...   \n",
              "3            3  The bottom of the deck can be printed with a d...   \n",
              "4            4  The longboard was made by two surfers Ben What...   \n",
              "...        ...                                                ...   \n",
              "29747    29995  Marlboro currently sponsors the Ducati MotoGP ...   \n",
              "29748    29996  During the 2007 GP2 Series Season ART Grand Pr...   \n",
              "29749    29997  In 2006 a Marlborosponsored car won the Indian...   \n",
              "29750    29998  Marlboro also sponsored Scuderia Ferrari as se...   \n",
              "29751    29999  In mid2006 special racing editions of Marlboro...   \n",
              "\n",
              "                                                     pos  \n",
              "0      [PRON, AUX, DET, NOUN, NOUN, ADP, PROPN, PROPN...  \n",
              "1      [PROPN, AUX, DET, NOUN, ADP, PROPN, ADP, DET, ...  \n",
              "2      [ADJ, NOUN, AUX, ADV, ADP, NUM, CCONJ, NUM, NO...  \n",
              "3      [DET, NOUN, ADP, DET, NOUN, AUX, AUX, VERB, AD...  \n",
              "4      [DET, NOUN, AUX, VERB, ADP, NUM, NOUN, PROPN, ...  \n",
              "...                                                  ...  \n",
              "29747  [PROPN, ADV, VERB, DET, PROPN, PROPN, ADP, ADP...  \n",
              "29748  [ADP, DET, NUM, PROPN, PROPN, PROPN, PROPN, PR...  \n",
              "29749  [ADP, NUM, DET, PROPN, NOUN, VERB, DET, PROPN,...  \n",
              "29750  [PROPN, ADV, VERB, PROPN, PROPN, SCONJ, ADJ, N...  \n",
              "29751  [ADP, NOUN, ADJ, NOUN, NOUN, ADP, PROPN, PROPN...  \n",
              "\n",
              "[29752 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80ff7855-4de6-4f30-a28a-d4933cbda915\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>It is the county seat of Alfalfa County.</td>\n",
              "      <td>[PRON, AUX, DET, NOUN, NOUN, ADP, PROPN, PROPN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cherokee is a city of Oklahoma in the United S...</td>\n",
              "      <td>[PROPN, AUX, DET, NOUN, ADP, PROPN, ADP, DET, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Skateboard decks are normally between 28 and 3...</td>\n",
              "      <td>[ADJ, NOUN, AUX, ADV, ADP, NUM, CCONJ, NUM, NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The bottom of the deck can be printed with a d...</td>\n",
              "      <td>[DET, NOUN, ADP, DET, NOUN, AUX, AUX, VERB, AD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The longboard was made by two surfers Ben What...</td>\n",
              "      <td>[DET, NOUN, AUX, VERB, ADP, NUM, NOUN, PROPN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29747</th>\n",
              "      <td>29995</td>\n",
              "      <td>Marlboro currently sponsors the Ducati MotoGP ...</td>\n",
              "      <td>[PROPN, ADV, VERB, DET, PROPN, PROPN, ADP, ADP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29748</th>\n",
              "      <td>29996</td>\n",
              "      <td>During the 2007 GP2 Series Season ART Grand Pr...</td>\n",
              "      <td>[ADP, DET, NUM, PROPN, PROPN, PROPN, PROPN, PR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29749</th>\n",
              "      <td>29997</td>\n",
              "      <td>In 2006 a Marlborosponsored car won the Indian...</td>\n",
              "      <td>[ADP, NUM, DET, PROPN, NOUN, VERB, DET, PROPN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29750</th>\n",
              "      <td>29998</td>\n",
              "      <td>Marlboro also sponsored Scuderia Ferrari as se...</td>\n",
              "      <td>[PROPN, ADV, VERB, PROPN, PROPN, SCONJ, ADJ, N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29751</th>\n",
              "      <td>29999</td>\n",
              "      <td>In mid2006 special racing editions of Marlboro...</td>\n",
              "      <td>[ADP, NOUN, ADJ, NOUN, NOUN, ADP, PROPN, PROPN...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29752 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80ff7855-4de6-4f30-a28a-d4933cbda915')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80ff7855-4de6-4f30-a28a-d4933cbda915 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80ff7855-4de6-4f30-a28a-d4933cbda915');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "my_df = my_df.drop([\"index\"], axis=1)\n",
        "my_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJJ9hBf-Uo3G",
        "outputId": "b6991b98-d7c4-4f98-f67a-6898827f88f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [PRON, AUX, DET, NOUN, NOUN, ADP, PROPN, PROPN...\n",
              "1        [PROPN, AUX, DET, NOUN, ADP, PROPN, ADP, DET, ...\n",
              "2        [ADJ, NOUN, AUX, ADV, ADP, NUM, CCONJ, NUM, NO...\n",
              "3        [DET, NOUN, ADP, DET, NOUN, AUX, AUX, VERB, AD...\n",
              "4        [DET, NOUN, AUX, VERB, ADP, NUM, NOUN, PROPN, ...\n",
              "                               ...                        \n",
              "29747    [PROPN, ADV, VERB, DET, PROPN, PROPN, ADP, ADP...\n",
              "29748    [ADP, DET, NUM, PROPN, PROPN, PROPN, PROPN, PR...\n",
              "29749    [ADP, NUM, DET, PROPN, NOUN, VERB, DET, PROPN,...\n",
              "29750    [PROPN, ADV, VERB, PROPN, PROPN, SCONJ, ADJ, N...\n",
              "29751    [ADP, NOUN, ADJ, NOUN, NOUN, ADP, PROPN, PROPN...\n",
              "Name: pos, Length: 29752, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "my_df[\"pos\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d79iJA9Ba4B",
        "outputId": "c0860826-2af8-43eb-e6a9-7546f64d4414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-059d31a6344c>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  my_df[\"pos\"][i] = m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(29752):\n",
        "  m = []\n",
        "  for j in range(len(my_df[\"pos\"][i])):\n",
        "    cur = my_df[\"pos\"][i][j]\n",
        "    m.append(pos_to_num[cur])\n",
        "\n",
        "  my_df[\"pos\"][i] = m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0Bz_dBJ-FvVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5e6b2d1a-215c-48ff-a029-7b5e7dec088d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       level_0                                           sentence  \\\n",
              "0            0           It is the county seat of Alfalfa County.   \n",
              "1            1  Cherokee is a city of Oklahoma in the United S...   \n",
              "2            2  Skateboard decks are normally between 28 and 3...   \n",
              "3            3  The bottom of the deck can be printed with a d...   \n",
              "4            4  The longboard was made by two surfers Ben What...   \n",
              "...        ...                                                ...   \n",
              "29747    29995  Marlboro currently sponsors the Ducati MotoGP ...   \n",
              "29748    29996  During the 2007 GP2 Series Season ART Grand Pr...   \n",
              "29749    29997  In 2006 a Marlborosponsored car won the Indian...   \n",
              "29750    29998  Marlboro also sponsored Scuderia Ferrari as se...   \n",
              "29751    29999  In mid2006 special racing editions of Marlboro...   \n",
              "\n",
              "                                                     pos  \n",
              "0                            [0, 1, 2, 3, 3, 4, 5, 5, 6]  \n",
              "1                      [5, 1, 2, 3, 4, 5, 4, 2, 5, 5, 6]  \n",
              "2                     [7, 3, 1, 8, 4, 9, 10, 9, 3, 8, 6]  \n",
              "3      [2, 3, 4, 2, 3, 1, 1, 11, 4, 2, 3, 4, 2, 3, 10...  \n",
              "4              [2, 3, 1, 11, 4, 9, 3, 5, 5, 10, 5, 5, 6]  \n",
              "...                                                  ...  \n",
              "29747  [5, 8, 11, 2, 5, 5, 4, 4, 2, 9, 5, 5, 3, 3, 3,...  \n",
              "29748     [4, 2, 9, 5, 5, 5, 5, 5, 5, 1, 8, 11, 4, 5, 6]  \n",
              "29749                    [4, 9, 2, 5, 3, 11, 2, 5, 9, 6]  \n",
              "29750  [5, 8, 11, 5, 5, 14, 7, 3, 11, 4, 9, 5, 3, 3, ...  \n",
              "29751  [4, 3, 7, 3, 3, 4, 5, 5, 1, 11, 4, 2, 5, 4, 2,...  \n",
              "\n",
              "[29752 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83cfbda5-01cc-4868-9239-617d5465e11d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>sentence</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>It is the county seat of Alfalfa County.</td>\n",
              "      <td>[0, 1, 2, 3, 3, 4, 5, 5, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cherokee is a city of Oklahoma in the United S...</td>\n",
              "      <td>[5, 1, 2, 3, 4, 5, 4, 2, 5, 5, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Skateboard decks are normally between 28 and 3...</td>\n",
              "      <td>[7, 3, 1, 8, 4, 9, 10, 9, 3, 8, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The bottom of the deck can be printed with a d...</td>\n",
              "      <td>[2, 3, 4, 2, 3, 1, 1, 11, 4, 2, 3, 4, 2, 3, 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The longboard was made by two surfers Ben What...</td>\n",
              "      <td>[2, 3, 1, 11, 4, 9, 3, 5, 5, 10, 5, 5, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29747</th>\n",
              "      <td>29995</td>\n",
              "      <td>Marlboro currently sponsors the Ducati MotoGP ...</td>\n",
              "      <td>[5, 8, 11, 2, 5, 5, 4, 4, 2, 9, 5, 5, 3, 3, 3,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29748</th>\n",
              "      <td>29996</td>\n",
              "      <td>During the 2007 GP2 Series Season ART Grand Pr...</td>\n",
              "      <td>[4, 2, 9, 5, 5, 5, 5, 5, 5, 1, 8, 11, 4, 5, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29749</th>\n",
              "      <td>29997</td>\n",
              "      <td>In 2006 a Marlborosponsored car won the Indian...</td>\n",
              "      <td>[4, 9, 2, 5, 3, 11, 2, 5, 9, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29750</th>\n",
              "      <td>29998</td>\n",
              "      <td>Marlboro also sponsored Scuderia Ferrari as se...</td>\n",
              "      <td>[5, 8, 11, 5, 5, 14, 7, 3, 11, 4, 9, 5, 3, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29751</th>\n",
              "      <td>29999</td>\n",
              "      <td>In mid2006 special racing editions of Marlboro...</td>\n",
              "      <td>[4, 3, 7, 3, 3, 4, 5, 5, 1, 11, 4, 2, 5, 4, 2,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29752 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83cfbda5-01cc-4868-9239-617d5465e11d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83cfbda5-01cc-4868-9239-617d5465e11d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83cfbda5-01cc-4868-9239-617d5465e11d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "my_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NzSPVRn8BMzo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "ff7c6524f6c74659bfdc058328daa632",
            "dfd432854bdd4cb7bb635b93bfff0cae",
            "5d6da665b56241fdbe6c0d5d814b6665",
            "b7e51d07e93540eab6264db0a7531b55",
            "a71a3385cf6b4432974c55f0c19934f8",
            "81ba470d8a3d4b27ad8367623307d4bf",
            "99ab02e502bb4a0488ae2e777e810355",
            "a0374c77185941d5b21d7edca7e17ccf",
            "14edc4bf48644cb094ecd4efe5c81795",
            "78e06f1432f0494bb036dca504dfdb1e",
            "cb65876576874200871b32071c25671a",
            "af370a0a35f84d55a781d16dde8f6010",
            "4bd30675bf0743bc86f895f24d2d0287",
            "f6ecfc1766834469a4d21718dd5cb6fb",
            "8cfb33d9c4244be0854966dd23a0b2ac",
            "03fcee6969cb4313ac1c737cb69cf4b1",
            "9983f33465ee46e5aaf21693f1812ca3",
            "8ae1de94e26b4276985fa79181d67896",
            "14762929b6a6481380e38ce9d517e40c",
            "be8482e8804c4483894ebd1756014c4a",
            "b6edce16893348328ab461e67a66de90",
            "75b686fcc51e47adb8b207367a1f848c",
            "ef61595ad26e45b18c0cd3e9abed4dab",
            "ae9d20c281094f0c86a6e2349907e43e",
            "23735a9cd0094049a0c366f8c3650504",
            "63f6e9ae55584721965697c42a565108",
            "29ecc76d04ae4e6f8b50264a2eb64c0e",
            "36ccd5a55b324ff4be93647bad596d1e",
            "05183ccae2fb42b48d9b414649963def",
            "9774c56c1bf54a13a14ca0540d1845d1",
            "b786f7de85a8451c8d559c448fe02503",
            "ff25082d9a884c8d80da53b254ac1855",
            "892bd00d605643eb93bc12bf261f030a",
            "d82fe389b67c42febf2dc87395ead953",
            "88722dceb5344b699eb70440e8eabc44",
            "cc29b3b6516f4e92b76a120719f56372",
            "c4ebc5a2310e408984e3e751d96818c5",
            "b82ef592db634da4b9993c2324076d30",
            "e84190e863b140e4921cee986eea5513",
            "0198a1c5b7b4439ebf414ac51fbae123",
            "b5699a2d020f41a380a35d2ad9905487",
            "8a6c9cd404ea4a47991bfebfa786e9fb",
            "cc0a3408ceb34961952112fb28322e72",
            "ecc822cd94db4d6aadee326fa64fc938"
          ]
        },
        "outputId": "7b2e4301-c6af-4b37-94d3-030a069be54e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff7c6524f6c74659bfdc058328daa632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af370a0a35f84d55a781d16dde8f6010"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef61595ad26e45b18c0cd3e9abed4dab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d82fe389b67c42febf2dc87395ead953"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It',\n",
              " 'is',\n",
              " 'the',\n",
              " 'county',\n",
              " 'seat',\n",
              " 'of',\n",
              " 'Alfa',\n",
              " '##lf',\n",
              " '##a',\n",
              " 'County',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\",truncation=True, padding=True)\n",
        "\n",
        "t = tokenizer(my_df[\"sentence\"][0])\n",
        "\n",
        "tokenized_data = tokenizer.tokenize(my_df[\"sentence\"][0])\n",
        "tokenized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xT6eeUWJD06v"
      },
      "outputs": [],
      "source": [
        "def get_correct_labels(example):\n",
        "  labels_all = []\n",
        "  tokenized_info = []\n",
        "\n",
        "  for i in range(len(example)):\n",
        "    tokenized_data = tokenizer(example[\"sentence\"][i])   #1 sentence is tokenized\n",
        "\n",
        "    y = {\"input_ids\":[], \"token_type_ids\":[], \"attention_mask\":[]}     # for every sentence\n",
        "    y[\"input_ids\"] = tokenized_data[\"input_ids\"]\n",
        "    y[\"token_type_ids\"] = tokenized_data[\"token_type_ids\"]\n",
        "    y[\"attention_mask\"] = tokenized_data[\"attention_mask\"]\n",
        "\n",
        "    tokenized_info.append(y)\n",
        "\n",
        "    actual_label = example[\"pos\"][i]   # ground truth for 1 sentence\n",
        "    word_ids = tokenized_data.word_ids()\n",
        "    prev_id = None\n",
        "    new_label = []\n",
        "    \n",
        "    print(i)\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "      if word_idx== None:\n",
        "        new_label.append(-100)\n",
        "\n",
        "      elif word_idx != prev_id:\n",
        "        new_label.append(actual_label[word_idx])\n",
        "      \n",
        "      else:\n",
        "        new_label.append(actual_label[word_idx])\n",
        "      \n",
        "      prev_id = word_idx\n",
        "\n",
        "    tokenized_info[i][\"labels\"] = new_label\n",
        "    labels_all.append(new_label)\n",
        "\n",
        "    \n",
        "  return tokenized_info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VLuVmJ72D5E4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756eb01d-dc8c-4492-b2c6-c3324f1b1fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "24752\n",
            "24753\n",
            "24754\n",
            "24755\n",
            "24756\n",
            "24757\n",
            "24758\n",
            "24759\n",
            "24760\n",
            "24761\n",
            "24762\n",
            "24763\n",
            "24764\n",
            "24765\n",
            "24766\n",
            "24767\n",
            "24768\n",
            "24769\n",
            "24770\n",
            "24771\n",
            "24772\n",
            "24773\n",
            "24774\n",
            "24775\n",
            "24776\n",
            "24777\n",
            "24778\n",
            "24779\n",
            "24780\n",
            "24781\n",
            "24782\n",
            "24783\n",
            "24784\n",
            "24785\n",
            "24786\n",
            "24787\n",
            "24788\n",
            "24789\n",
            "24790\n",
            "24791\n",
            "24792\n",
            "24793\n",
            "24794\n",
            "24795\n",
            "24796\n",
            "24797\n",
            "24798\n",
            "24799\n",
            "24800\n",
            "24801\n",
            "24802\n",
            "24803\n",
            "24804\n",
            "24805\n",
            "24806\n",
            "24807\n",
            "24808\n",
            "24809\n",
            "24810\n",
            "24811\n",
            "24812\n",
            "24813\n",
            "24814\n",
            "24815\n",
            "24816\n",
            "24817\n",
            "24818\n",
            "24819\n",
            "24820\n",
            "24821\n",
            "24822\n",
            "24823\n",
            "24824\n",
            "24825\n",
            "24826\n",
            "24827\n",
            "24828\n",
            "24829\n",
            "24830\n",
            "24831\n",
            "24832\n",
            "24833\n",
            "24834\n",
            "24835\n",
            "24836\n",
            "24837\n",
            "24838\n",
            "24839\n",
            "24840\n",
            "24841\n",
            "24842\n",
            "24843\n",
            "24844\n",
            "24845\n",
            "24846\n",
            "24847\n",
            "24848\n",
            "24849\n",
            "24850\n",
            "24851\n",
            "24852\n",
            "24853\n",
            "24854\n",
            "24855\n",
            "24856\n",
            "24857\n",
            "24858\n",
            "24859\n",
            "24860\n",
            "24861\n",
            "24862\n",
            "24863\n",
            "24864\n",
            "24865\n",
            "24866\n",
            "24867\n",
            "24868\n",
            "24869\n",
            "24870\n",
            "24871\n",
            "24872\n",
            "24873\n",
            "24874\n",
            "24875\n",
            "24876\n",
            "24877\n",
            "24878\n",
            "24879\n",
            "24880\n",
            "24881\n",
            "24882\n",
            "24883\n",
            "24884\n",
            "24885\n",
            "24886\n",
            "24887\n",
            "24888\n",
            "24889\n",
            "24890\n",
            "24891\n",
            "24892\n",
            "24893\n",
            "24894\n",
            "24895\n",
            "24896\n",
            "24897\n",
            "24898\n",
            "24899\n",
            "24900\n",
            "24901\n",
            "24902\n",
            "24903\n",
            "24904\n",
            "24905\n",
            "24906\n",
            "24907\n",
            "24908\n",
            "24909\n",
            "24910\n",
            "24911\n",
            "24912\n",
            "24913\n",
            "24914\n",
            "24915\n",
            "24916\n",
            "24917\n",
            "24918\n",
            "24919\n",
            "24920\n",
            "24921\n",
            "24922\n",
            "24923\n",
            "24924\n",
            "24925\n",
            "24926\n",
            "24927\n",
            "24928\n",
            "24929\n",
            "24930\n",
            "24931\n",
            "24932\n",
            "24933\n",
            "24934\n",
            "24935\n",
            "24936\n",
            "24937\n",
            "24938\n",
            "24939\n",
            "24940\n",
            "24941\n",
            "24942\n",
            "24943\n",
            "24944\n",
            "24945\n",
            "24946\n",
            "24947\n",
            "24948\n",
            "24949\n",
            "24950\n",
            "24951\n",
            "24952\n",
            "24953\n",
            "24954\n",
            "24955\n",
            "24956\n",
            "24957\n",
            "24958\n",
            "24959\n",
            "24960\n",
            "24961\n",
            "24962\n",
            "24963\n",
            "24964\n",
            "24965\n",
            "24966\n",
            "24967\n",
            "24968\n",
            "24969\n",
            "24970\n",
            "24971\n",
            "24972\n",
            "24973\n",
            "24974\n",
            "24975\n",
            "24976\n",
            "24977\n",
            "24978\n",
            "24979\n",
            "24980\n",
            "24981\n",
            "24982\n",
            "24983\n",
            "24984\n",
            "24985\n",
            "24986\n",
            "24987\n",
            "24988\n",
            "24989\n",
            "24990\n",
            "24991\n",
            "24992\n",
            "24993\n",
            "24994\n",
            "24995\n",
            "24996\n",
            "24997\n",
            "24998\n",
            "24999\n",
            "25000\n",
            "25001\n",
            "25002\n",
            "25003\n",
            "25004\n",
            "25005\n",
            "25006\n",
            "25007\n",
            "25008\n",
            "25009\n",
            "25010\n",
            "25011\n",
            "25012\n",
            "25013\n",
            "25014\n",
            "25015\n",
            "25016\n",
            "25017\n",
            "25018\n",
            "25019\n",
            "25020\n",
            "25021\n",
            "25022\n",
            "25023\n",
            "25024\n",
            "25025\n",
            "25026\n",
            "25027\n",
            "25028\n",
            "25029\n",
            "25030\n",
            "25031\n",
            "25032\n",
            "25033\n",
            "25034\n",
            "25035\n",
            "25036\n",
            "25037\n",
            "25038\n",
            "25039\n",
            "25040\n",
            "25041\n",
            "25042\n",
            "25043\n",
            "25044\n",
            "25045\n",
            "25046\n",
            "25047\n",
            "25048\n",
            "25049\n",
            "25050\n",
            "25051\n",
            "25052\n",
            "25053\n",
            "25054\n",
            "25055\n",
            "25056\n",
            "25057\n",
            "25058\n",
            "25059\n",
            "25060\n",
            "25061\n",
            "25062\n",
            "25063\n",
            "25064\n",
            "25065\n",
            "25066\n",
            "25067\n",
            "25068\n",
            "25069\n",
            "25070\n",
            "25071\n",
            "25072\n",
            "25073\n",
            "25074\n",
            "25075\n",
            "25076\n",
            "25077\n",
            "25078\n",
            "25079\n",
            "25080\n",
            "25081\n",
            "25082\n",
            "25083\n",
            "25084\n",
            "25085\n",
            "25086\n",
            "25087\n",
            "25088\n",
            "25089\n",
            "25090\n",
            "25091\n",
            "25092\n",
            "25093\n",
            "25094\n",
            "25095\n",
            "25096\n",
            "25097\n",
            "25098\n",
            "25099\n",
            "25100\n",
            "25101\n",
            "25102\n",
            "25103\n",
            "25104\n",
            "25105\n",
            "25106\n",
            "25107\n",
            "25108\n",
            "25109\n",
            "25110\n",
            "25111\n",
            "25112\n",
            "25113\n",
            "25114\n",
            "25115\n",
            "25116\n",
            "25117\n",
            "25118\n",
            "25119\n",
            "25120\n",
            "25121\n",
            "25122\n",
            "25123\n",
            "25124\n",
            "25125\n",
            "25126\n",
            "25127\n",
            "25128\n",
            "25129\n",
            "25130\n",
            "25131\n",
            "25132\n",
            "25133\n",
            "25134\n",
            "25135\n",
            "25136\n",
            "25137\n",
            "25138\n",
            "25139\n",
            "25140\n",
            "25141\n",
            "25142\n",
            "25143\n",
            "25144\n",
            "25145\n",
            "25146\n",
            "25147\n",
            "25148\n",
            "25149\n",
            "25150\n",
            "25151\n",
            "25152\n",
            "25153\n",
            "25154\n",
            "25155\n",
            "25156\n",
            "25157\n",
            "25158\n",
            "25159\n",
            "25160\n",
            "25161\n",
            "25162\n",
            "25163\n",
            "25164\n",
            "25165\n",
            "25166\n",
            "25167\n",
            "25168\n",
            "25169\n",
            "25170\n",
            "25171\n",
            "25172\n",
            "25173\n",
            "25174\n",
            "25175\n",
            "25176\n",
            "25177\n",
            "25178\n",
            "25179\n",
            "25180\n",
            "25181\n",
            "25182\n",
            "25183\n",
            "25184\n",
            "25185\n",
            "25186\n",
            "25187\n",
            "25188\n",
            "25189\n",
            "25190\n",
            "25191\n",
            "25192\n",
            "25193\n",
            "25194\n",
            "25195\n",
            "25196\n",
            "25197\n",
            "25198\n",
            "25199\n",
            "25200\n",
            "25201\n",
            "25202\n",
            "25203\n",
            "25204\n",
            "25205\n",
            "25206\n",
            "25207\n",
            "25208\n",
            "25209\n",
            "25210\n",
            "25211\n",
            "25212\n",
            "25213\n",
            "25214\n",
            "25215\n",
            "25216\n",
            "25217\n",
            "25218\n",
            "25219\n",
            "25220\n",
            "25221\n",
            "25222\n",
            "25223\n",
            "25224\n",
            "25225\n",
            "25226\n",
            "25227\n",
            "25228\n",
            "25229\n",
            "25230\n",
            "25231\n",
            "25232\n",
            "25233\n",
            "25234\n",
            "25235\n",
            "25236\n",
            "25237\n",
            "25238\n",
            "25239\n",
            "25240\n",
            "25241\n",
            "25242\n",
            "25243\n",
            "25244\n",
            "25245\n",
            "25246\n",
            "25247\n",
            "25248\n",
            "25249\n",
            "25250\n",
            "25251\n",
            "25252\n",
            "25253\n",
            "25254\n",
            "25255\n",
            "25256\n",
            "25257\n",
            "25258\n",
            "25259\n",
            "25260\n",
            "25261\n",
            "25262\n",
            "25263\n",
            "25264\n",
            "25265\n",
            "25266\n",
            "25267\n",
            "25268\n",
            "25269\n",
            "25270\n",
            "25271\n",
            "25272\n",
            "25273\n",
            "25274\n",
            "25275\n",
            "25276\n",
            "25277\n",
            "25278\n",
            "25279\n",
            "25280\n",
            "25281\n",
            "25282\n",
            "25283\n",
            "25284\n",
            "25285\n",
            "25286\n",
            "25287\n",
            "25288\n",
            "25289\n",
            "25290\n",
            "25291\n",
            "25292\n",
            "25293\n",
            "25294\n",
            "25295\n",
            "25296\n",
            "25297\n",
            "25298\n",
            "25299\n",
            "25300\n",
            "25301\n",
            "25302\n",
            "25303\n",
            "25304\n",
            "25305\n",
            "25306\n",
            "25307\n",
            "25308\n",
            "25309\n",
            "25310\n",
            "25311\n",
            "25312\n",
            "25313\n",
            "25314\n",
            "25315\n",
            "25316\n",
            "25317\n",
            "25318\n",
            "25319\n",
            "25320\n",
            "25321\n",
            "25322\n",
            "25323\n",
            "25324\n",
            "25325\n",
            "25326\n",
            "25327\n",
            "25328\n",
            "25329\n",
            "25330\n",
            "25331\n",
            "25332\n",
            "25333\n",
            "25334\n",
            "25335\n",
            "25336\n",
            "25337\n",
            "25338\n",
            "25339\n",
            "25340\n",
            "25341\n",
            "25342\n",
            "25343\n",
            "25344\n",
            "25345\n",
            "25346\n",
            "25347\n",
            "25348\n",
            "25349\n",
            "25350\n",
            "25351\n",
            "25352\n",
            "25353\n",
            "25354\n",
            "25355\n",
            "25356\n",
            "25357\n",
            "25358\n",
            "25359\n",
            "25360\n",
            "25361\n",
            "25362\n",
            "25363\n",
            "25364\n",
            "25365\n",
            "25366\n",
            "25367\n",
            "25368\n",
            "25369\n",
            "25370\n",
            "25371\n",
            "25372\n",
            "25373\n",
            "25374\n",
            "25375\n",
            "25376\n",
            "25377\n",
            "25378\n",
            "25379\n",
            "25380\n",
            "25381\n",
            "25382\n",
            "25383\n",
            "25384\n",
            "25385\n",
            "25386\n",
            "25387\n",
            "25388\n",
            "25389\n",
            "25390\n",
            "25391\n",
            "25392\n",
            "25393\n",
            "25394\n",
            "25395\n",
            "25396\n",
            "25397\n",
            "25398\n",
            "25399\n",
            "25400\n",
            "25401\n",
            "25402\n",
            "25403\n",
            "25404\n",
            "25405\n",
            "25406\n",
            "25407\n",
            "25408\n",
            "25409\n",
            "25410\n",
            "25411\n",
            "25412\n",
            "25413\n",
            "25414\n",
            "25415\n",
            "25416\n",
            "25417\n",
            "25418\n",
            "25419\n",
            "25420\n",
            "25421\n",
            "25422\n",
            "25423\n",
            "25424\n",
            "25425\n",
            "25426\n",
            "25427\n",
            "25428\n",
            "25429\n",
            "25430\n",
            "25431\n",
            "25432\n",
            "25433\n",
            "25434\n",
            "25435\n",
            "25436\n",
            "25437\n",
            "25438\n",
            "25439\n",
            "25440\n",
            "25441\n",
            "25442\n",
            "25443\n",
            "25444\n",
            "25445\n",
            "25446\n",
            "25447\n",
            "25448\n",
            "25449\n",
            "25450\n",
            "25451\n",
            "25452\n",
            "25453\n",
            "25454\n",
            "25455\n",
            "25456\n",
            "25457\n",
            "25458\n",
            "25459\n",
            "25460\n",
            "25461\n",
            "25462\n",
            "25463\n",
            "25464\n",
            "25465\n",
            "25466\n",
            "25467\n",
            "25468\n",
            "25469\n",
            "25470\n",
            "25471\n",
            "25472\n",
            "25473\n",
            "25474\n",
            "25475\n",
            "25476\n",
            "25477\n",
            "25478\n",
            "25479\n",
            "25480\n",
            "25481\n",
            "25482\n",
            "25483\n",
            "25484\n",
            "25485\n",
            "25486\n",
            "25487\n",
            "25488\n",
            "25489\n",
            "25490\n",
            "25491\n",
            "25492\n",
            "25493\n",
            "25494\n",
            "25495\n",
            "25496\n",
            "25497\n",
            "25498\n",
            "25499\n",
            "25500\n",
            "25501\n",
            "25502\n",
            "25503\n",
            "25504\n",
            "25505\n",
            "25506\n",
            "25507\n",
            "25508\n",
            "25509\n",
            "25510\n",
            "25511\n",
            "25512\n",
            "25513\n",
            "25514\n",
            "25515\n",
            "25516\n",
            "25517\n",
            "25518\n",
            "25519\n",
            "25520\n",
            "25521\n",
            "25522\n",
            "25523\n",
            "25524\n",
            "25525\n",
            "25526\n",
            "25527\n",
            "25528\n",
            "25529\n",
            "25530\n",
            "25531\n",
            "25532\n",
            "25533\n",
            "25534\n",
            "25535\n",
            "25536\n",
            "25537\n",
            "25538\n",
            "25539\n",
            "25540\n",
            "25541\n",
            "25542\n",
            "25543\n",
            "25544\n",
            "25545\n",
            "25546\n",
            "25547\n",
            "25548\n",
            "25549\n",
            "25550\n",
            "25551\n",
            "25552\n",
            "25553\n",
            "25554\n",
            "25555\n",
            "25556\n",
            "25557\n",
            "25558\n",
            "25559\n",
            "25560\n",
            "25561\n",
            "25562\n",
            "25563\n",
            "25564\n",
            "25565\n",
            "25566\n",
            "25567\n",
            "25568\n",
            "25569\n",
            "25570\n",
            "25571\n",
            "25572\n",
            "25573\n",
            "25574\n",
            "25575\n",
            "25576\n",
            "25577\n",
            "25578\n",
            "25579\n",
            "25580\n",
            "25581\n",
            "25582\n",
            "25583\n",
            "25584\n",
            "25585\n",
            "25586\n",
            "25587\n",
            "25588\n",
            "25589\n",
            "25590\n",
            "25591\n",
            "25592\n",
            "25593\n",
            "25594\n",
            "25595\n",
            "25596\n",
            "25597\n",
            "25598\n",
            "25599\n",
            "25600\n",
            "25601\n",
            "25602\n",
            "25603\n",
            "25604\n",
            "25605\n",
            "25606\n",
            "25607\n",
            "25608\n",
            "25609\n",
            "25610\n",
            "25611\n",
            "25612\n",
            "25613\n",
            "25614\n",
            "25615\n",
            "25616\n",
            "25617\n",
            "25618\n",
            "25619\n",
            "25620\n",
            "25621\n",
            "25622\n",
            "25623\n",
            "25624\n",
            "25625\n",
            "25626\n",
            "25627\n",
            "25628\n",
            "25629\n",
            "25630\n",
            "25631\n",
            "25632\n",
            "25633\n",
            "25634\n",
            "25635\n",
            "25636\n",
            "25637\n",
            "25638\n",
            "25639\n",
            "25640\n",
            "25641\n",
            "25642\n",
            "25643\n",
            "25644\n",
            "25645\n",
            "25646\n",
            "25647\n",
            "25648\n",
            "25649\n",
            "25650\n",
            "25651\n",
            "25652\n",
            "25653\n",
            "25654\n",
            "25655\n",
            "25656\n",
            "25657\n",
            "25658\n",
            "25659\n",
            "25660\n",
            "25661\n",
            "25662\n",
            "25663\n",
            "25664\n",
            "25665\n",
            "25666\n",
            "25667\n",
            "25668\n",
            "25669\n",
            "25670\n",
            "25671\n",
            "25672\n",
            "25673\n",
            "25674\n",
            "25675\n",
            "25676\n",
            "25677\n",
            "25678\n",
            "25679\n",
            "25680\n",
            "25681\n",
            "25682\n",
            "25683\n",
            "25684\n",
            "25685\n",
            "25686\n",
            "25687\n",
            "25688\n",
            "25689\n",
            "25690\n",
            "25691\n",
            "25692\n",
            "25693\n",
            "25694\n",
            "25695\n",
            "25696\n",
            "25697\n",
            "25698\n",
            "25699\n",
            "25700\n",
            "25701\n",
            "25702\n",
            "25703\n",
            "25704\n",
            "25705\n",
            "25706\n",
            "25707\n",
            "25708\n",
            "25709\n",
            "25710\n",
            "25711\n",
            "25712\n",
            "25713\n",
            "25714\n",
            "25715\n",
            "25716\n",
            "25717\n",
            "25718\n",
            "25719\n",
            "25720\n",
            "25721\n",
            "25722\n",
            "25723\n",
            "25724\n",
            "25725\n",
            "25726\n",
            "25727\n",
            "25728\n",
            "25729\n",
            "25730\n",
            "25731\n",
            "25732\n",
            "25733\n",
            "25734\n",
            "25735\n",
            "25736\n",
            "25737\n",
            "25738\n",
            "25739\n",
            "25740\n",
            "25741\n",
            "25742\n",
            "25743\n",
            "25744\n",
            "25745\n",
            "25746\n",
            "25747\n",
            "25748\n",
            "25749\n",
            "25750\n",
            "25751\n",
            "25752\n",
            "25753\n",
            "25754\n",
            "25755\n",
            "25756\n",
            "25757\n",
            "25758\n",
            "25759\n",
            "25760\n",
            "25761\n",
            "25762\n",
            "25763\n",
            "25764\n",
            "25765\n",
            "25766\n",
            "25767\n",
            "25768\n",
            "25769\n",
            "25770\n",
            "25771\n",
            "25772\n",
            "25773\n",
            "25774\n",
            "25775\n",
            "25776\n",
            "25777\n",
            "25778\n",
            "25779\n",
            "25780\n",
            "25781\n",
            "25782\n",
            "25783\n",
            "25784\n",
            "25785\n",
            "25786\n",
            "25787\n",
            "25788\n",
            "25789\n",
            "25790\n",
            "25791\n",
            "25792\n",
            "25793\n",
            "25794\n",
            "25795\n",
            "25796\n",
            "25797\n",
            "25798\n",
            "25799\n",
            "25800\n",
            "25801\n",
            "25802\n",
            "25803\n",
            "25804\n",
            "25805\n",
            "25806\n",
            "25807\n",
            "25808\n",
            "25809\n",
            "25810\n",
            "25811\n",
            "25812\n",
            "25813\n",
            "25814\n",
            "25815\n",
            "25816\n",
            "25817\n",
            "25818\n",
            "25819\n",
            "25820\n",
            "25821\n",
            "25822\n",
            "25823\n",
            "25824\n",
            "25825\n",
            "25826\n",
            "25827\n",
            "25828\n",
            "25829\n",
            "25830\n",
            "25831\n",
            "25832\n",
            "25833\n",
            "25834\n",
            "25835\n",
            "25836\n",
            "25837\n",
            "25838\n",
            "25839\n",
            "25840\n",
            "25841\n",
            "25842\n",
            "25843\n",
            "25844\n",
            "25845\n",
            "25846\n",
            "25847\n",
            "25848\n",
            "25849\n",
            "25850\n",
            "25851\n",
            "25852\n",
            "25853\n",
            "25854\n",
            "25855\n",
            "25856\n",
            "25857\n",
            "25858\n",
            "25859\n",
            "25860\n",
            "25861\n",
            "25862\n",
            "25863\n",
            "25864\n",
            "25865\n",
            "25866\n",
            "25867\n",
            "25868\n",
            "25869\n",
            "25870\n",
            "25871\n",
            "25872\n",
            "25873\n",
            "25874\n",
            "25875\n",
            "25876\n",
            "25877\n",
            "25878\n",
            "25879\n",
            "25880\n",
            "25881\n",
            "25882\n",
            "25883\n",
            "25884\n",
            "25885\n",
            "25886\n",
            "25887\n",
            "25888\n",
            "25889\n",
            "25890\n",
            "25891\n",
            "25892\n",
            "25893\n",
            "25894\n",
            "25895\n",
            "25896\n",
            "25897\n",
            "25898\n",
            "25899\n",
            "25900\n",
            "25901\n",
            "25902\n",
            "25903\n",
            "25904\n",
            "25905\n",
            "25906\n",
            "25907\n",
            "25908\n",
            "25909\n",
            "25910\n",
            "25911\n",
            "25912\n",
            "25913\n",
            "25914\n",
            "25915\n",
            "25916\n",
            "25917\n",
            "25918\n",
            "25919\n",
            "25920\n",
            "25921\n",
            "25922\n",
            "25923\n",
            "25924\n",
            "25925\n",
            "25926\n",
            "25927\n",
            "25928\n",
            "25929\n",
            "25930\n",
            "25931\n",
            "25932\n",
            "25933\n",
            "25934\n",
            "25935\n",
            "25936\n",
            "25937\n",
            "25938\n",
            "25939\n",
            "25940\n",
            "25941\n",
            "25942\n",
            "25943\n",
            "25944\n",
            "25945\n",
            "25946\n",
            "25947\n",
            "25948\n",
            "25949\n",
            "25950\n",
            "25951\n",
            "25952\n",
            "25953\n",
            "25954\n",
            "25955\n",
            "25956\n",
            "25957\n",
            "25958\n",
            "25959\n",
            "25960\n",
            "25961\n",
            "25962\n",
            "25963\n",
            "25964\n",
            "25965\n",
            "25966\n",
            "25967\n",
            "25968\n",
            "25969\n",
            "25970\n",
            "25971\n",
            "25972\n",
            "25973\n",
            "25974\n",
            "25975\n",
            "25976\n",
            "25977\n",
            "25978\n",
            "25979\n",
            "25980\n",
            "25981\n",
            "25982\n",
            "25983\n",
            "25984\n",
            "25985\n",
            "25986\n",
            "25987\n",
            "25988\n",
            "25989\n",
            "25990\n",
            "25991\n",
            "25992\n",
            "25993\n",
            "25994\n",
            "25995\n",
            "25996\n",
            "25997\n",
            "25998\n",
            "25999\n",
            "26000\n",
            "26001\n",
            "26002\n",
            "26003\n",
            "26004\n",
            "26005\n",
            "26006\n",
            "26007\n",
            "26008\n",
            "26009\n",
            "26010\n",
            "26011\n",
            "26012\n",
            "26013\n",
            "26014\n",
            "26015\n",
            "26016\n",
            "26017\n",
            "26018\n",
            "26019\n",
            "26020\n",
            "26021\n",
            "26022\n",
            "26023\n",
            "26024\n",
            "26025\n",
            "26026\n",
            "26027\n",
            "26028\n",
            "26029\n",
            "26030\n",
            "26031\n",
            "26032\n",
            "26033\n",
            "26034\n",
            "26035\n",
            "26036\n",
            "26037\n",
            "26038\n",
            "26039\n",
            "26040\n",
            "26041\n",
            "26042\n",
            "26043\n",
            "26044\n",
            "26045\n",
            "26046\n",
            "26047\n",
            "26048\n",
            "26049\n",
            "26050\n",
            "26051\n",
            "26052\n",
            "26053\n",
            "26054\n",
            "26055\n",
            "26056\n",
            "26057\n",
            "26058\n",
            "26059\n",
            "26060\n",
            "26061\n",
            "26062\n",
            "26063\n",
            "26064\n",
            "26065\n",
            "26066\n",
            "26067\n",
            "26068\n",
            "26069\n",
            "26070\n",
            "26071\n",
            "26072\n",
            "26073\n",
            "26074\n",
            "26075\n",
            "26076\n",
            "26077\n",
            "26078\n",
            "26079\n",
            "26080\n",
            "26081\n",
            "26082\n",
            "26083\n",
            "26084\n",
            "26085\n",
            "26086\n",
            "26087\n",
            "26088\n",
            "26089\n",
            "26090\n",
            "26091\n",
            "26092\n",
            "26093\n",
            "26094\n",
            "26095\n",
            "26096\n",
            "26097\n",
            "26098\n",
            "26099\n",
            "26100\n",
            "26101\n",
            "26102\n",
            "26103\n",
            "26104\n",
            "26105\n",
            "26106\n",
            "26107\n",
            "26108\n",
            "26109\n",
            "26110\n",
            "26111\n",
            "26112\n",
            "26113\n",
            "26114\n",
            "26115\n",
            "26116\n",
            "26117\n",
            "26118\n",
            "26119\n",
            "26120\n",
            "26121\n",
            "26122\n",
            "26123\n",
            "26124\n",
            "26125\n",
            "26126\n",
            "26127\n",
            "26128\n",
            "26129\n",
            "26130\n",
            "26131\n",
            "26132\n",
            "26133\n",
            "26134\n",
            "26135\n",
            "26136\n",
            "26137\n",
            "26138\n",
            "26139\n",
            "26140\n",
            "26141\n",
            "26142\n",
            "26143\n",
            "26144\n",
            "26145\n",
            "26146\n",
            "26147\n",
            "26148\n",
            "26149\n",
            "26150\n",
            "26151\n",
            "26152\n",
            "26153\n",
            "26154\n",
            "26155\n",
            "26156\n",
            "26157\n",
            "26158\n",
            "26159\n",
            "26160\n",
            "26161\n",
            "26162\n",
            "26163\n",
            "26164\n",
            "26165\n",
            "26166\n",
            "26167\n",
            "26168\n",
            "26169\n",
            "26170\n",
            "26171\n",
            "26172\n",
            "26173\n",
            "26174\n",
            "26175\n",
            "26176\n",
            "26177\n",
            "26178\n",
            "26179\n",
            "26180\n",
            "26181\n",
            "26182\n",
            "26183\n",
            "26184\n",
            "26185\n",
            "26186\n",
            "26187\n",
            "26188\n",
            "26189\n",
            "26190\n",
            "26191\n",
            "26192\n",
            "26193\n",
            "26194\n",
            "26195\n",
            "26196\n",
            "26197\n",
            "26198\n",
            "26199\n",
            "26200\n",
            "26201\n",
            "26202\n",
            "26203\n",
            "26204\n",
            "26205\n",
            "26206\n",
            "26207\n",
            "26208\n",
            "26209\n",
            "26210\n",
            "26211\n",
            "26212\n",
            "26213\n",
            "26214\n",
            "26215\n",
            "26216\n",
            "26217\n",
            "26218\n",
            "26219\n",
            "26220\n",
            "26221\n",
            "26222\n",
            "26223\n",
            "26224\n",
            "26225\n",
            "26226\n",
            "26227\n",
            "26228\n",
            "26229\n",
            "26230\n",
            "26231\n",
            "26232\n",
            "26233\n",
            "26234\n",
            "26235\n",
            "26236\n",
            "26237\n",
            "26238\n",
            "26239\n",
            "26240\n",
            "26241\n",
            "26242\n",
            "26243\n",
            "26244\n",
            "26245\n",
            "26246\n",
            "26247\n",
            "26248\n",
            "26249\n",
            "26250\n",
            "26251\n",
            "26252\n",
            "26253\n",
            "26254\n",
            "26255\n",
            "26256\n",
            "26257\n",
            "26258\n",
            "26259\n",
            "26260\n",
            "26261\n",
            "26262\n",
            "26263\n",
            "26264\n",
            "26265\n",
            "26266\n",
            "26267\n",
            "26268\n",
            "26269\n",
            "26270\n",
            "26271\n",
            "26272\n",
            "26273\n",
            "26274\n",
            "26275\n",
            "26276\n",
            "26277\n",
            "26278\n",
            "26279\n",
            "26280\n",
            "26281\n",
            "26282\n",
            "26283\n",
            "26284\n",
            "26285\n",
            "26286\n",
            "26287\n",
            "26288\n",
            "26289\n",
            "26290\n",
            "26291\n",
            "26292\n",
            "26293\n",
            "26294\n",
            "26295\n",
            "26296\n",
            "26297\n",
            "26298\n",
            "26299\n",
            "26300\n",
            "26301\n",
            "26302\n",
            "26303\n",
            "26304\n",
            "26305\n",
            "26306\n",
            "26307\n",
            "26308\n",
            "26309\n",
            "26310\n",
            "26311\n",
            "26312\n",
            "26313\n",
            "26314\n",
            "26315\n",
            "26316\n",
            "26317\n",
            "26318\n",
            "26319\n",
            "26320\n",
            "26321\n",
            "26322\n",
            "26323\n",
            "26324\n",
            "26325\n",
            "26326\n",
            "26327\n",
            "26328\n",
            "26329\n",
            "26330\n",
            "26331\n",
            "26332\n",
            "26333\n",
            "26334\n",
            "26335\n",
            "26336\n",
            "26337\n",
            "26338\n",
            "26339\n",
            "26340\n",
            "26341\n",
            "26342\n",
            "26343\n",
            "26344\n",
            "26345\n",
            "26346\n",
            "26347\n",
            "26348\n",
            "26349\n",
            "26350\n",
            "26351\n",
            "26352\n",
            "26353\n",
            "26354\n",
            "26355\n",
            "26356\n",
            "26357\n",
            "26358\n",
            "26359\n",
            "26360\n",
            "26361\n",
            "26362\n",
            "26363\n",
            "26364\n",
            "26365\n",
            "26366\n",
            "26367\n",
            "26368\n",
            "26369\n",
            "26370\n",
            "26371\n",
            "26372\n",
            "26373\n",
            "26374\n",
            "26375\n",
            "26376\n",
            "26377\n",
            "26378\n",
            "26379\n",
            "26380\n",
            "26381\n",
            "26382\n",
            "26383\n",
            "26384\n",
            "26385\n",
            "26386\n",
            "26387\n",
            "26388\n",
            "26389\n",
            "26390\n",
            "26391\n",
            "26392\n",
            "26393\n",
            "26394\n",
            "26395\n",
            "26396\n",
            "26397\n",
            "26398\n",
            "26399\n",
            "26400\n",
            "26401\n",
            "26402\n",
            "26403\n",
            "26404\n",
            "26405\n",
            "26406\n",
            "26407\n",
            "26408\n",
            "26409\n",
            "26410\n",
            "26411\n",
            "26412\n",
            "26413\n",
            "26414\n",
            "26415\n",
            "26416\n",
            "26417\n",
            "26418\n",
            "26419\n",
            "26420\n",
            "26421\n",
            "26422\n",
            "26423\n",
            "26424\n",
            "26425\n",
            "26426\n",
            "26427\n",
            "26428\n",
            "26429\n",
            "26430\n",
            "26431\n",
            "26432\n",
            "26433\n",
            "26434\n",
            "26435\n",
            "26436\n",
            "26437\n",
            "26438\n",
            "26439\n",
            "26440\n",
            "26441\n",
            "26442\n",
            "26443\n",
            "26444\n",
            "26445\n",
            "26446\n",
            "26447\n",
            "26448\n",
            "26449\n",
            "26450\n",
            "26451\n",
            "26452\n",
            "26453\n",
            "26454\n",
            "26455\n",
            "26456\n",
            "26457\n",
            "26458\n",
            "26459\n",
            "26460\n",
            "26461\n",
            "26462\n",
            "26463\n",
            "26464\n",
            "26465\n",
            "26466\n",
            "26467\n",
            "26468\n",
            "26469\n",
            "26470\n",
            "26471\n",
            "26472\n",
            "26473\n",
            "26474\n",
            "26475\n",
            "26476\n",
            "26477\n",
            "26478\n",
            "26479\n",
            "26480\n",
            "26481\n",
            "26482\n",
            "26483\n",
            "26484\n",
            "26485\n",
            "26486\n",
            "26487\n",
            "26488\n",
            "26489\n",
            "26490\n",
            "26491\n",
            "26492\n",
            "26493\n",
            "26494\n",
            "26495\n",
            "26496\n",
            "26497\n",
            "26498\n",
            "26499\n",
            "26500\n",
            "26501\n",
            "26502\n",
            "26503\n",
            "26504\n",
            "26505\n",
            "26506\n",
            "26507\n",
            "26508\n",
            "26509\n",
            "26510\n",
            "26511\n",
            "26512\n",
            "26513\n",
            "26514\n",
            "26515\n",
            "26516\n",
            "26517\n",
            "26518\n",
            "26519\n",
            "26520\n",
            "26521\n",
            "26522\n",
            "26523\n",
            "26524\n",
            "26525\n",
            "26526\n",
            "26527\n",
            "26528\n",
            "26529\n",
            "26530\n",
            "26531\n",
            "26532\n",
            "26533\n",
            "26534\n",
            "26535\n",
            "26536\n",
            "26537\n",
            "26538\n",
            "26539\n",
            "26540\n",
            "26541\n",
            "26542\n",
            "26543\n",
            "26544\n",
            "26545\n",
            "26546\n",
            "26547\n",
            "26548\n",
            "26549\n",
            "26550\n",
            "26551\n",
            "26552\n",
            "26553\n",
            "26554\n",
            "26555\n",
            "26556\n",
            "26557\n",
            "26558\n",
            "26559\n",
            "26560\n",
            "26561\n",
            "26562\n",
            "26563\n",
            "26564\n",
            "26565\n",
            "26566\n",
            "26567\n",
            "26568\n",
            "26569\n",
            "26570\n",
            "26571\n",
            "26572\n",
            "26573\n",
            "26574\n",
            "26575\n",
            "26576\n",
            "26577\n",
            "26578\n",
            "26579\n",
            "26580\n",
            "26581\n",
            "26582\n",
            "26583\n",
            "26584\n",
            "26585\n",
            "26586\n",
            "26587\n",
            "26588\n",
            "26589\n",
            "26590\n",
            "26591\n",
            "26592\n",
            "26593\n",
            "26594\n",
            "26595\n",
            "26596\n",
            "26597\n",
            "26598\n",
            "26599\n",
            "26600\n",
            "26601\n",
            "26602\n",
            "26603\n",
            "26604\n",
            "26605\n",
            "26606\n",
            "26607\n",
            "26608\n",
            "26609\n",
            "26610\n",
            "26611\n",
            "26612\n",
            "26613\n",
            "26614\n",
            "26615\n",
            "26616\n",
            "26617\n",
            "26618\n",
            "26619\n",
            "26620\n",
            "26621\n",
            "26622\n",
            "26623\n",
            "26624\n",
            "26625\n",
            "26626\n",
            "26627\n",
            "26628\n",
            "26629\n",
            "26630\n",
            "26631\n",
            "26632\n",
            "26633\n",
            "26634\n",
            "26635\n",
            "26636\n",
            "26637\n",
            "26638\n",
            "26639\n",
            "26640\n",
            "26641\n",
            "26642\n",
            "26643\n",
            "26644\n",
            "26645\n",
            "26646\n",
            "26647\n",
            "26648\n",
            "26649\n",
            "26650\n",
            "26651\n",
            "26652\n",
            "26653\n",
            "26654\n",
            "26655\n",
            "26656\n",
            "26657\n",
            "26658\n",
            "26659\n",
            "26660\n",
            "26661\n",
            "26662\n",
            "26663\n",
            "26664\n",
            "26665\n",
            "26666\n",
            "26667\n",
            "26668\n",
            "26669\n",
            "26670\n",
            "26671\n",
            "26672\n",
            "26673\n",
            "26674\n",
            "26675\n",
            "26676\n",
            "26677\n",
            "26678\n",
            "26679\n",
            "26680\n",
            "26681\n",
            "26682\n",
            "26683\n",
            "26684\n",
            "26685\n",
            "26686\n",
            "26687\n",
            "26688\n",
            "26689\n",
            "26690\n",
            "26691\n",
            "26692\n",
            "26693\n",
            "26694\n",
            "26695\n",
            "26696\n",
            "26697\n",
            "26698\n",
            "26699\n",
            "26700\n",
            "26701\n",
            "26702\n",
            "26703\n",
            "26704\n",
            "26705\n",
            "26706\n",
            "26707\n",
            "26708\n",
            "26709\n",
            "26710\n",
            "26711\n",
            "26712\n",
            "26713\n",
            "26714\n",
            "26715\n",
            "26716\n",
            "26717\n",
            "26718\n",
            "26719\n",
            "26720\n",
            "26721\n",
            "26722\n",
            "26723\n",
            "26724\n",
            "26725\n",
            "26726\n",
            "26727\n",
            "26728\n",
            "26729\n",
            "26730\n",
            "26731\n",
            "26732\n",
            "26733\n",
            "26734\n",
            "26735\n",
            "26736\n",
            "26737\n",
            "26738\n",
            "26739\n",
            "26740\n",
            "26741\n",
            "26742\n",
            "26743\n",
            "26744\n",
            "26745\n",
            "26746\n",
            "26747\n",
            "26748\n",
            "26749\n",
            "26750\n",
            "26751\n",
            "26752\n",
            "26753\n",
            "26754\n",
            "26755\n",
            "26756\n",
            "26757\n",
            "26758\n",
            "26759\n",
            "26760\n",
            "26761\n",
            "26762\n",
            "26763\n",
            "26764\n",
            "26765\n",
            "26766\n",
            "26767\n",
            "26768\n",
            "26769\n",
            "26770\n",
            "26771\n",
            "26772\n",
            "26773\n",
            "26774\n",
            "26775\n",
            "26776\n",
            "26777\n",
            "26778\n",
            "26779\n",
            "26780\n",
            "26781\n",
            "26782\n",
            "26783\n",
            "26784\n",
            "26785\n",
            "26786\n",
            "26787\n",
            "26788\n",
            "26789\n",
            "26790\n",
            "26791\n",
            "26792\n",
            "26793\n",
            "26794\n",
            "26795\n",
            "26796\n",
            "26797\n",
            "26798\n",
            "26799\n",
            "26800\n",
            "26801\n",
            "26802\n",
            "26803\n",
            "26804\n",
            "26805\n",
            "26806\n",
            "26807\n",
            "26808\n",
            "26809\n",
            "26810\n",
            "26811\n",
            "26812\n",
            "26813\n",
            "26814\n",
            "26815\n",
            "26816\n",
            "26817\n",
            "26818\n",
            "26819\n",
            "26820\n",
            "26821\n",
            "26822\n",
            "26823\n",
            "26824\n",
            "26825\n",
            "26826\n",
            "26827\n",
            "26828\n",
            "26829\n",
            "26830\n",
            "26831\n",
            "26832\n",
            "26833\n",
            "26834\n",
            "26835\n",
            "26836\n",
            "26837\n",
            "26838\n",
            "26839\n",
            "26840\n",
            "26841\n",
            "26842\n",
            "26843\n",
            "26844\n",
            "26845\n",
            "26846\n",
            "26847\n",
            "26848\n",
            "26849\n",
            "26850\n",
            "26851\n",
            "26852\n",
            "26853\n",
            "26854\n",
            "26855\n",
            "26856\n",
            "26857\n",
            "26858\n",
            "26859\n",
            "26860\n",
            "26861\n",
            "26862\n",
            "26863\n",
            "26864\n",
            "26865\n",
            "26866\n",
            "26867\n",
            "26868\n",
            "26869\n",
            "26870\n",
            "26871\n",
            "26872\n",
            "26873\n",
            "26874\n",
            "26875\n",
            "26876\n",
            "26877\n",
            "26878\n",
            "26879\n",
            "26880\n",
            "26881\n",
            "26882\n",
            "26883\n",
            "26884\n",
            "26885\n",
            "26886\n",
            "26887\n",
            "26888\n",
            "26889\n",
            "26890\n",
            "26891\n",
            "26892\n",
            "26893\n",
            "26894\n",
            "26895\n",
            "26896\n",
            "26897\n",
            "26898\n",
            "26899\n",
            "26900\n",
            "26901\n",
            "26902\n",
            "26903\n",
            "26904\n",
            "26905\n",
            "26906\n",
            "26907\n",
            "26908\n",
            "26909\n",
            "26910\n",
            "26911\n",
            "26912\n",
            "26913\n",
            "26914\n",
            "26915\n",
            "26916\n",
            "26917\n",
            "26918\n",
            "26919\n",
            "26920\n",
            "26921\n",
            "26922\n",
            "26923\n",
            "26924\n",
            "26925\n",
            "26926\n",
            "26927\n",
            "26928\n",
            "26929\n",
            "26930\n",
            "26931\n",
            "26932\n",
            "26933\n",
            "26934\n",
            "26935\n",
            "26936\n",
            "26937\n",
            "26938\n",
            "26939\n",
            "26940\n",
            "26941\n",
            "26942\n",
            "26943\n",
            "26944\n",
            "26945\n",
            "26946\n",
            "26947\n",
            "26948\n",
            "26949\n",
            "26950\n",
            "26951\n",
            "26952\n",
            "26953\n",
            "26954\n",
            "26955\n",
            "26956\n",
            "26957\n",
            "26958\n",
            "26959\n",
            "26960\n",
            "26961\n",
            "26962\n",
            "26963\n",
            "26964\n",
            "26965\n",
            "26966\n",
            "26967\n",
            "26968\n",
            "26969\n",
            "26970\n",
            "26971\n",
            "26972\n",
            "26973\n",
            "26974\n",
            "26975\n",
            "26976\n",
            "26977\n",
            "26978\n",
            "26979\n",
            "26980\n",
            "26981\n",
            "26982\n",
            "26983\n",
            "26984\n",
            "26985\n",
            "26986\n",
            "26987\n",
            "26988\n",
            "26989\n",
            "26990\n",
            "26991\n",
            "26992\n",
            "26993\n",
            "26994\n",
            "26995\n",
            "26996\n",
            "26997\n",
            "26998\n",
            "26999\n",
            "27000\n",
            "27001\n",
            "27002\n",
            "27003\n",
            "27004\n",
            "27005\n",
            "27006\n",
            "27007\n",
            "27008\n",
            "27009\n",
            "27010\n",
            "27011\n",
            "27012\n",
            "27013\n",
            "27014\n",
            "27015\n",
            "27016\n",
            "27017\n",
            "27018\n",
            "27019\n",
            "27020\n",
            "27021\n",
            "27022\n",
            "27023\n",
            "27024\n",
            "27025\n",
            "27026\n",
            "27027\n",
            "27028\n",
            "27029\n",
            "27030\n",
            "27031\n",
            "27032\n",
            "27033\n",
            "27034\n",
            "27035\n",
            "27036\n",
            "27037\n",
            "27038\n",
            "27039\n",
            "27040\n",
            "27041\n",
            "27042\n",
            "27043\n",
            "27044\n",
            "27045\n",
            "27046\n",
            "27047\n",
            "27048\n",
            "27049\n",
            "27050\n",
            "27051\n",
            "27052\n",
            "27053\n",
            "27054\n",
            "27055\n",
            "27056\n",
            "27057\n",
            "27058\n",
            "27059\n",
            "27060\n",
            "27061\n",
            "27062\n",
            "27063\n",
            "27064\n",
            "27065\n",
            "27066\n",
            "27067\n",
            "27068\n",
            "27069\n",
            "27070\n",
            "27071\n",
            "27072\n",
            "27073\n",
            "27074\n",
            "27075\n",
            "27076\n",
            "27077\n",
            "27078\n",
            "27079\n",
            "27080\n",
            "27081\n",
            "27082\n",
            "27083\n",
            "27084\n",
            "27085\n",
            "27086\n",
            "27087\n",
            "27088\n",
            "27089\n",
            "27090\n",
            "27091\n",
            "27092\n",
            "27093\n",
            "27094\n",
            "27095\n",
            "27096\n",
            "27097\n",
            "27098\n",
            "27099\n",
            "27100\n",
            "27101\n",
            "27102\n",
            "27103\n",
            "27104\n",
            "27105\n",
            "27106\n",
            "27107\n",
            "27108\n",
            "27109\n",
            "27110\n",
            "27111\n",
            "27112\n",
            "27113\n",
            "27114\n",
            "27115\n",
            "27116\n",
            "27117\n",
            "27118\n",
            "27119\n",
            "27120\n",
            "27121\n",
            "27122\n",
            "27123\n",
            "27124\n",
            "27125\n",
            "27126\n",
            "27127\n",
            "27128\n",
            "27129\n",
            "27130\n",
            "27131\n",
            "27132\n",
            "27133\n",
            "27134\n",
            "27135\n",
            "27136\n",
            "27137\n",
            "27138\n",
            "27139\n",
            "27140\n",
            "27141\n",
            "27142\n",
            "27143\n",
            "27144\n",
            "27145\n",
            "27146\n",
            "27147\n",
            "27148\n",
            "27149\n",
            "27150\n",
            "27151\n",
            "27152\n",
            "27153\n",
            "27154\n",
            "27155\n",
            "27156\n",
            "27157\n",
            "27158\n",
            "27159\n",
            "27160\n",
            "27161\n",
            "27162\n",
            "27163\n",
            "27164\n",
            "27165\n",
            "27166\n",
            "27167\n",
            "27168\n",
            "27169\n",
            "27170\n",
            "27171\n",
            "27172\n",
            "27173\n",
            "27174\n",
            "27175\n",
            "27176\n",
            "27177\n",
            "27178\n",
            "27179\n",
            "27180\n",
            "27181\n",
            "27182\n",
            "27183\n",
            "27184\n",
            "27185\n",
            "27186\n",
            "27187\n",
            "27188\n",
            "27189\n",
            "27190\n",
            "27191\n",
            "27192\n",
            "27193\n",
            "27194\n",
            "27195\n",
            "27196\n",
            "27197\n",
            "27198\n",
            "27199\n",
            "27200\n",
            "27201\n",
            "27202\n",
            "27203\n",
            "27204\n",
            "27205\n",
            "27206\n",
            "27207\n",
            "27208\n",
            "27209\n",
            "27210\n",
            "27211\n",
            "27212\n",
            "27213\n",
            "27214\n",
            "27215\n",
            "27216\n",
            "27217\n",
            "27218\n",
            "27219\n",
            "27220\n",
            "27221\n",
            "27222\n",
            "27223\n",
            "27224\n",
            "27225\n",
            "27226\n",
            "27227\n",
            "27228\n",
            "27229\n",
            "27230\n",
            "27231\n",
            "27232\n",
            "27233\n",
            "27234\n",
            "27235\n",
            "27236\n",
            "27237\n",
            "27238\n",
            "27239\n",
            "27240\n",
            "27241\n",
            "27242\n",
            "27243\n",
            "27244\n",
            "27245\n",
            "27246\n",
            "27247\n",
            "27248\n",
            "27249\n",
            "27250\n",
            "27251\n",
            "27252\n",
            "27253\n",
            "27254\n",
            "27255\n",
            "27256\n",
            "27257\n",
            "27258\n",
            "27259\n",
            "27260\n",
            "27261\n",
            "27262\n",
            "27263\n",
            "27264\n",
            "27265\n",
            "27266\n",
            "27267\n",
            "27268\n",
            "27269\n",
            "27270\n",
            "27271\n",
            "27272\n",
            "27273\n",
            "27274\n",
            "27275\n",
            "27276\n",
            "27277\n",
            "27278\n",
            "27279\n",
            "27280\n",
            "27281\n",
            "27282\n",
            "27283\n",
            "27284\n",
            "27285\n",
            "27286\n",
            "27287\n",
            "27288\n",
            "27289\n",
            "27290\n",
            "27291\n",
            "27292\n",
            "27293\n",
            "27294\n",
            "27295\n",
            "27296\n",
            "27297\n",
            "27298\n",
            "27299\n",
            "27300\n",
            "27301\n",
            "27302\n",
            "27303\n",
            "27304\n",
            "27305\n",
            "27306\n",
            "27307\n",
            "27308\n",
            "27309\n",
            "27310\n",
            "27311\n",
            "27312\n",
            "27313\n",
            "27314\n",
            "27315\n",
            "27316\n",
            "27317\n",
            "27318\n",
            "27319\n",
            "27320\n",
            "27321\n",
            "27322\n",
            "27323\n",
            "27324\n",
            "27325\n",
            "27326\n",
            "27327\n",
            "27328\n",
            "27329\n",
            "27330\n",
            "27331\n",
            "27332\n",
            "27333\n",
            "27334\n",
            "27335\n",
            "27336\n",
            "27337\n",
            "27338\n",
            "27339\n",
            "27340\n",
            "27341\n",
            "27342\n",
            "27343\n",
            "27344\n",
            "27345\n",
            "27346\n",
            "27347\n",
            "27348\n",
            "27349\n",
            "27350\n",
            "27351\n",
            "27352\n",
            "27353\n",
            "27354\n",
            "27355\n",
            "27356\n",
            "27357\n",
            "27358\n",
            "27359\n",
            "27360\n",
            "27361\n",
            "27362\n",
            "27363\n",
            "27364\n",
            "27365\n",
            "27366\n",
            "27367\n",
            "27368\n",
            "27369\n",
            "27370\n",
            "27371\n",
            "27372\n",
            "27373\n",
            "27374\n",
            "27375\n",
            "27376\n",
            "27377\n",
            "27378\n",
            "27379\n",
            "27380\n",
            "27381\n",
            "27382\n",
            "27383\n",
            "27384\n",
            "27385\n",
            "27386\n",
            "27387\n",
            "27388\n",
            "27389\n",
            "27390\n",
            "27391\n",
            "27392\n",
            "27393\n",
            "27394\n",
            "27395\n",
            "27396\n",
            "27397\n",
            "27398\n",
            "27399\n",
            "27400\n",
            "27401\n",
            "27402\n",
            "27403\n",
            "27404\n",
            "27405\n",
            "27406\n",
            "27407\n",
            "27408\n",
            "27409\n",
            "27410\n",
            "27411\n",
            "27412\n",
            "27413\n",
            "27414\n",
            "27415\n",
            "27416\n",
            "27417\n",
            "27418\n",
            "27419\n",
            "27420\n",
            "27421\n",
            "27422\n",
            "27423\n",
            "27424\n",
            "27425\n",
            "27426\n",
            "27427\n",
            "27428\n",
            "27429\n",
            "27430\n",
            "27431\n",
            "27432\n",
            "27433\n",
            "27434\n",
            "27435\n",
            "27436\n",
            "27437\n",
            "27438\n",
            "27439\n",
            "27440\n",
            "27441\n",
            "27442\n",
            "27443\n",
            "27444\n",
            "27445\n",
            "27446\n",
            "27447\n",
            "27448\n",
            "27449\n",
            "27450\n",
            "27451\n",
            "27452\n",
            "27453\n",
            "27454\n",
            "27455\n",
            "27456\n",
            "27457\n",
            "27458\n",
            "27459\n",
            "27460\n",
            "27461\n",
            "27462\n",
            "27463\n",
            "27464\n",
            "27465\n",
            "27466\n",
            "27467\n",
            "27468\n",
            "27469\n",
            "27470\n",
            "27471\n",
            "27472\n",
            "27473\n",
            "27474\n",
            "27475\n",
            "27476\n",
            "27477\n",
            "27478\n",
            "27479\n",
            "27480\n",
            "27481\n",
            "27482\n",
            "27483\n",
            "27484\n",
            "27485\n",
            "27486\n",
            "27487\n",
            "27488\n",
            "27489\n",
            "27490\n",
            "27491\n",
            "27492\n",
            "27493\n",
            "27494\n",
            "27495\n",
            "27496\n",
            "27497\n",
            "27498\n",
            "27499\n",
            "27500\n",
            "27501\n",
            "27502\n",
            "27503\n",
            "27504\n",
            "27505\n",
            "27506\n",
            "27507\n",
            "27508\n",
            "27509\n",
            "27510\n",
            "27511\n",
            "27512\n",
            "27513\n",
            "27514\n",
            "27515\n",
            "27516\n",
            "27517\n",
            "27518\n",
            "27519\n",
            "27520\n",
            "27521\n",
            "27522\n",
            "27523\n",
            "27524\n",
            "27525\n",
            "27526\n",
            "27527\n",
            "27528\n",
            "27529\n",
            "27530\n",
            "27531\n",
            "27532\n",
            "27533\n",
            "27534\n",
            "27535\n",
            "27536\n",
            "27537\n",
            "27538\n",
            "27539\n",
            "27540\n",
            "27541\n",
            "27542\n",
            "27543\n",
            "27544\n",
            "27545\n",
            "27546\n",
            "27547\n",
            "27548\n",
            "27549\n",
            "27550\n",
            "27551\n",
            "27552\n",
            "27553\n",
            "27554\n",
            "27555\n",
            "27556\n",
            "27557\n",
            "27558\n",
            "27559\n",
            "27560\n",
            "27561\n",
            "27562\n",
            "27563\n",
            "27564\n",
            "27565\n",
            "27566\n",
            "27567\n",
            "27568\n",
            "27569\n",
            "27570\n",
            "27571\n",
            "27572\n",
            "27573\n",
            "27574\n",
            "27575\n",
            "27576\n",
            "27577\n",
            "27578\n",
            "27579\n",
            "27580\n",
            "27581\n",
            "27582\n",
            "27583\n",
            "27584\n",
            "27585\n",
            "27586\n",
            "27587\n",
            "27588\n",
            "27589\n",
            "27590\n",
            "27591\n",
            "27592\n",
            "27593\n",
            "27594\n",
            "27595\n",
            "27596\n",
            "27597\n",
            "27598\n",
            "27599\n",
            "27600\n",
            "27601\n",
            "27602\n",
            "27603\n",
            "27604\n",
            "27605\n",
            "27606\n",
            "27607\n",
            "27608\n",
            "27609\n",
            "27610\n",
            "27611\n",
            "27612\n",
            "27613\n",
            "27614\n",
            "27615\n",
            "27616\n",
            "27617\n",
            "27618\n",
            "27619\n",
            "27620\n",
            "27621\n",
            "27622\n",
            "27623\n",
            "27624\n",
            "27625\n",
            "27626\n",
            "27627\n",
            "27628\n",
            "27629\n",
            "27630\n",
            "27631\n",
            "27632\n",
            "27633\n",
            "27634\n",
            "27635\n",
            "27636\n",
            "27637\n",
            "27638\n",
            "27639\n",
            "27640\n",
            "27641\n",
            "27642\n",
            "27643\n",
            "27644\n",
            "27645\n",
            "27646\n",
            "27647\n",
            "27648\n",
            "27649\n",
            "27650\n",
            "27651\n",
            "27652\n",
            "27653\n",
            "27654\n",
            "27655\n",
            "27656\n",
            "27657\n",
            "27658\n",
            "27659\n",
            "27660\n",
            "27661\n",
            "27662\n",
            "27663\n",
            "27664\n",
            "27665\n",
            "27666\n",
            "27667\n",
            "27668\n",
            "27669\n",
            "27670\n",
            "27671\n",
            "27672\n",
            "27673\n",
            "27674\n",
            "27675\n",
            "27676\n",
            "27677\n",
            "27678\n",
            "27679\n",
            "27680\n",
            "27681\n",
            "27682\n",
            "27683\n",
            "27684\n",
            "27685\n",
            "27686\n",
            "27687\n",
            "27688\n",
            "27689\n",
            "27690\n",
            "27691\n",
            "27692\n",
            "27693\n",
            "27694\n",
            "27695\n",
            "27696\n",
            "27697\n",
            "27698\n",
            "27699\n",
            "27700\n",
            "27701\n",
            "27702\n",
            "27703\n",
            "27704\n",
            "27705\n",
            "27706\n",
            "27707\n",
            "27708\n",
            "27709\n",
            "27710\n",
            "27711\n",
            "27712\n",
            "27713\n",
            "27714\n",
            "27715\n",
            "27716\n",
            "27717\n",
            "27718\n",
            "27719\n",
            "27720\n",
            "27721\n",
            "27722\n",
            "27723\n",
            "27724\n",
            "27725\n",
            "27726\n",
            "27727\n",
            "27728\n",
            "27729\n",
            "27730\n",
            "27731\n",
            "27732\n",
            "27733\n",
            "27734\n",
            "27735\n",
            "27736\n",
            "27737\n",
            "27738\n",
            "27739\n",
            "27740\n",
            "27741\n",
            "27742\n",
            "27743\n",
            "27744\n",
            "27745\n",
            "27746\n",
            "27747\n",
            "27748\n",
            "27749\n",
            "27750\n",
            "27751\n",
            "27752\n",
            "27753\n",
            "27754\n",
            "27755\n",
            "27756\n",
            "27757\n",
            "27758\n",
            "27759\n",
            "27760\n",
            "27761\n",
            "27762\n",
            "27763\n",
            "27764\n",
            "27765\n",
            "27766\n",
            "27767\n",
            "27768\n",
            "27769\n",
            "27770\n",
            "27771\n",
            "27772\n",
            "27773\n",
            "27774\n",
            "27775\n",
            "27776\n",
            "27777\n",
            "27778\n",
            "27779\n",
            "27780\n",
            "27781\n",
            "27782\n",
            "27783\n",
            "27784\n",
            "27785\n",
            "27786\n",
            "27787\n",
            "27788\n",
            "27789\n",
            "27790\n",
            "27791\n",
            "27792\n",
            "27793\n",
            "27794\n",
            "27795\n",
            "27796\n",
            "27797\n",
            "27798\n",
            "27799\n",
            "27800\n",
            "27801\n",
            "27802\n",
            "27803\n",
            "27804\n",
            "27805\n",
            "27806\n",
            "27807\n",
            "27808\n",
            "27809\n",
            "27810\n",
            "27811\n",
            "27812\n",
            "27813\n",
            "27814\n",
            "27815\n",
            "27816\n",
            "27817\n",
            "27818\n",
            "27819\n",
            "27820\n",
            "27821\n",
            "27822\n",
            "27823\n",
            "27824\n",
            "27825\n",
            "27826\n",
            "27827\n",
            "27828\n",
            "27829\n",
            "27830\n",
            "27831\n",
            "27832\n",
            "27833\n",
            "27834\n",
            "27835\n",
            "27836\n",
            "27837\n",
            "27838\n",
            "27839\n",
            "27840\n",
            "27841\n",
            "27842\n",
            "27843\n",
            "27844\n",
            "27845\n",
            "27846\n",
            "27847\n",
            "27848\n",
            "27849\n",
            "27850\n",
            "27851\n",
            "27852\n",
            "27853\n",
            "27854\n",
            "27855\n",
            "27856\n",
            "27857\n",
            "27858\n",
            "27859\n",
            "27860\n",
            "27861\n",
            "27862\n",
            "27863\n",
            "27864\n",
            "27865\n",
            "27866\n",
            "27867\n",
            "27868\n",
            "27869\n",
            "27870\n",
            "27871\n",
            "27872\n",
            "27873\n",
            "27874\n",
            "27875\n",
            "27876\n",
            "27877\n",
            "27878\n",
            "27879\n",
            "27880\n",
            "27881\n",
            "27882\n",
            "27883\n",
            "27884\n",
            "27885\n",
            "27886\n",
            "27887\n",
            "27888\n",
            "27889\n",
            "27890\n",
            "27891\n",
            "27892\n",
            "27893\n",
            "27894\n",
            "27895\n",
            "27896\n",
            "27897\n",
            "27898\n",
            "27899\n",
            "27900\n",
            "27901\n",
            "27902\n",
            "27903\n",
            "27904\n",
            "27905\n",
            "27906\n",
            "27907\n",
            "27908\n",
            "27909\n",
            "27910\n",
            "27911\n",
            "27912\n",
            "27913\n",
            "27914\n",
            "27915\n",
            "27916\n",
            "27917\n",
            "27918\n",
            "27919\n",
            "27920\n",
            "27921\n",
            "27922\n",
            "27923\n",
            "27924\n",
            "27925\n",
            "27926\n",
            "27927\n",
            "27928\n",
            "27929\n",
            "27930\n",
            "27931\n",
            "27932\n",
            "27933\n",
            "27934\n",
            "27935\n",
            "27936\n",
            "27937\n",
            "27938\n",
            "27939\n",
            "27940\n",
            "27941\n",
            "27942\n",
            "27943\n",
            "27944\n",
            "27945\n",
            "27946\n",
            "27947\n",
            "27948\n",
            "27949\n",
            "27950\n",
            "27951\n",
            "27952\n",
            "27953\n",
            "27954\n",
            "27955\n",
            "27956\n",
            "27957\n",
            "27958\n",
            "27959\n",
            "27960\n",
            "27961\n",
            "27962\n",
            "27963\n",
            "27964\n",
            "27965\n",
            "27966\n",
            "27967\n",
            "27968\n",
            "27969\n",
            "27970\n",
            "27971\n",
            "27972\n",
            "27973\n",
            "27974\n",
            "27975\n",
            "27976\n",
            "27977\n",
            "27978\n",
            "27979\n",
            "27980\n",
            "27981\n",
            "27982\n",
            "27983\n",
            "27984\n",
            "27985\n",
            "27986\n",
            "27987\n",
            "27988\n",
            "27989\n",
            "27990\n",
            "27991\n",
            "27992\n",
            "27993\n",
            "27994\n",
            "27995\n",
            "27996\n",
            "27997\n",
            "27998\n",
            "27999\n",
            "28000\n",
            "28001\n",
            "28002\n",
            "28003\n",
            "28004\n",
            "28005\n",
            "28006\n",
            "28007\n",
            "28008\n",
            "28009\n",
            "28010\n",
            "28011\n",
            "28012\n",
            "28013\n",
            "28014\n",
            "28015\n",
            "28016\n",
            "28017\n",
            "28018\n",
            "28019\n",
            "28020\n",
            "28021\n",
            "28022\n",
            "28023\n",
            "28024\n",
            "28025\n",
            "28026\n",
            "28027\n",
            "28028\n",
            "28029\n",
            "28030\n",
            "28031\n",
            "28032\n",
            "28033\n",
            "28034\n",
            "28035\n",
            "28036\n",
            "28037\n",
            "28038\n",
            "28039\n",
            "28040\n",
            "28041\n",
            "28042\n",
            "28043\n",
            "28044\n",
            "28045\n",
            "28046\n",
            "28047\n",
            "28048\n",
            "28049\n",
            "28050\n",
            "28051\n",
            "28052\n",
            "28053\n",
            "28054\n",
            "28055\n",
            "28056\n",
            "28057\n",
            "28058\n",
            "28059\n",
            "28060\n",
            "28061\n",
            "28062\n",
            "28063\n",
            "28064\n",
            "28065\n",
            "28066\n",
            "28067\n",
            "28068\n",
            "28069\n",
            "28070\n",
            "28071\n",
            "28072\n",
            "28073\n",
            "28074\n",
            "28075\n",
            "28076\n",
            "28077\n",
            "28078\n",
            "28079\n",
            "28080\n",
            "28081\n",
            "28082\n",
            "28083\n",
            "28084\n",
            "28085\n",
            "28086\n",
            "28087\n",
            "28088\n",
            "28089\n",
            "28090\n",
            "28091\n",
            "28092\n",
            "28093\n",
            "28094\n",
            "28095\n",
            "28096\n",
            "28097\n",
            "28098\n",
            "28099\n",
            "28100\n",
            "28101\n",
            "28102\n",
            "28103\n",
            "28104\n",
            "28105\n",
            "28106\n",
            "28107\n",
            "28108\n",
            "28109\n",
            "28110\n",
            "28111\n",
            "28112\n",
            "28113\n",
            "28114\n",
            "28115\n",
            "28116\n",
            "28117\n",
            "28118\n",
            "28119\n",
            "28120\n",
            "28121\n",
            "28122\n",
            "28123\n",
            "28124\n",
            "28125\n",
            "28126\n",
            "28127\n",
            "28128\n",
            "28129\n",
            "28130\n",
            "28131\n",
            "28132\n",
            "28133\n",
            "28134\n",
            "28135\n",
            "28136\n",
            "28137\n",
            "28138\n",
            "28139\n",
            "28140\n",
            "28141\n",
            "28142\n",
            "28143\n",
            "28144\n",
            "28145\n",
            "28146\n",
            "28147\n",
            "28148\n",
            "28149\n",
            "28150\n",
            "28151\n",
            "28152\n",
            "28153\n",
            "28154\n",
            "28155\n",
            "28156\n",
            "28157\n",
            "28158\n",
            "28159\n",
            "28160\n",
            "28161\n",
            "28162\n",
            "28163\n",
            "28164\n",
            "28165\n",
            "28166\n",
            "28167\n",
            "28168\n",
            "28169\n",
            "28170\n",
            "28171\n",
            "28172\n",
            "28173\n",
            "28174\n",
            "28175\n",
            "28176\n",
            "28177\n",
            "28178\n",
            "28179\n",
            "28180\n",
            "28181\n",
            "28182\n",
            "28183\n",
            "28184\n",
            "28185\n",
            "28186\n",
            "28187\n",
            "28188\n",
            "28189\n",
            "28190\n",
            "28191\n",
            "28192\n",
            "28193\n",
            "28194\n",
            "28195\n",
            "28196\n",
            "28197\n",
            "28198\n",
            "28199\n",
            "28200\n",
            "28201\n",
            "28202\n",
            "28203\n",
            "28204\n",
            "28205\n",
            "28206\n",
            "28207\n",
            "28208\n",
            "28209\n",
            "28210\n",
            "28211\n",
            "28212\n",
            "28213\n",
            "28214\n",
            "28215\n",
            "28216\n",
            "28217\n",
            "28218\n",
            "28219\n",
            "28220\n",
            "28221\n",
            "28222\n",
            "28223\n",
            "28224\n",
            "28225\n",
            "28226\n",
            "28227\n",
            "28228\n",
            "28229\n",
            "28230\n",
            "28231\n",
            "28232\n",
            "28233\n",
            "28234\n",
            "28235\n",
            "28236\n",
            "28237\n",
            "28238\n",
            "28239\n",
            "28240\n",
            "28241\n",
            "28242\n",
            "28243\n",
            "28244\n",
            "28245\n",
            "28246\n",
            "28247\n",
            "28248\n",
            "28249\n",
            "28250\n",
            "28251\n",
            "28252\n",
            "28253\n",
            "28254\n",
            "28255\n",
            "28256\n",
            "28257\n",
            "28258\n",
            "28259\n",
            "28260\n",
            "28261\n",
            "28262\n",
            "28263\n",
            "28264\n",
            "28265\n",
            "28266\n",
            "28267\n",
            "28268\n",
            "28269\n",
            "28270\n",
            "28271\n",
            "28272\n",
            "28273\n",
            "28274\n",
            "28275\n",
            "28276\n",
            "28277\n",
            "28278\n",
            "28279\n",
            "28280\n",
            "28281\n",
            "28282\n",
            "28283\n",
            "28284\n",
            "28285\n",
            "28286\n",
            "28287\n",
            "28288\n",
            "28289\n",
            "28290\n",
            "28291\n",
            "28292\n",
            "28293\n",
            "28294\n",
            "28295\n",
            "28296\n",
            "28297\n",
            "28298\n",
            "28299\n",
            "28300\n",
            "28301\n",
            "28302\n",
            "28303\n",
            "28304\n",
            "28305\n",
            "28306\n",
            "28307\n",
            "28308\n",
            "28309\n",
            "28310\n",
            "28311\n",
            "28312\n",
            "28313\n",
            "28314\n",
            "28315\n",
            "28316\n",
            "28317\n",
            "28318\n",
            "28319\n",
            "28320\n",
            "28321\n",
            "28322\n",
            "28323\n",
            "28324\n",
            "28325\n",
            "28326\n",
            "28327\n",
            "28328\n",
            "28329\n",
            "28330\n",
            "28331\n",
            "28332\n",
            "28333\n",
            "28334\n",
            "28335\n",
            "28336\n",
            "28337\n",
            "28338\n",
            "28339\n",
            "28340\n",
            "28341\n",
            "28342\n",
            "28343\n",
            "28344\n",
            "28345\n",
            "28346\n",
            "28347\n",
            "28348\n",
            "28349\n",
            "28350\n",
            "28351\n",
            "28352\n",
            "28353\n",
            "28354\n",
            "28355\n",
            "28356\n",
            "28357\n",
            "28358\n",
            "28359\n",
            "28360\n",
            "28361\n",
            "28362\n",
            "28363\n",
            "28364\n",
            "28365\n",
            "28366\n",
            "28367\n",
            "28368\n",
            "28369\n",
            "28370\n",
            "28371\n",
            "28372\n",
            "28373\n",
            "28374\n",
            "28375\n",
            "28376\n",
            "28377\n",
            "28378\n",
            "28379\n",
            "28380\n",
            "28381\n",
            "28382\n",
            "28383\n",
            "28384\n",
            "28385\n",
            "28386\n",
            "28387\n",
            "28388\n",
            "28389\n",
            "28390\n",
            "28391\n",
            "28392\n",
            "28393\n",
            "28394\n",
            "28395\n",
            "28396\n",
            "28397\n",
            "28398\n",
            "28399\n",
            "28400\n",
            "28401\n",
            "28402\n",
            "28403\n",
            "28404\n",
            "28405\n",
            "28406\n",
            "28407\n",
            "28408\n",
            "28409\n",
            "28410\n",
            "28411\n",
            "28412\n",
            "28413\n",
            "28414\n",
            "28415\n",
            "28416\n",
            "28417\n",
            "28418\n",
            "28419\n",
            "28420\n",
            "28421\n",
            "28422\n",
            "28423\n",
            "28424\n",
            "28425\n",
            "28426\n",
            "28427\n",
            "28428\n",
            "28429\n",
            "28430\n",
            "28431\n",
            "28432\n",
            "28433\n",
            "28434\n",
            "28435\n",
            "28436\n",
            "28437\n",
            "28438\n",
            "28439\n",
            "28440\n",
            "28441\n",
            "28442\n",
            "28443\n",
            "28444\n",
            "28445\n",
            "28446\n",
            "28447\n",
            "28448\n",
            "28449\n",
            "28450\n",
            "28451\n",
            "28452\n",
            "28453\n",
            "28454\n",
            "28455\n",
            "28456\n",
            "28457\n",
            "28458\n",
            "28459\n",
            "28460\n",
            "28461\n",
            "28462\n",
            "28463\n",
            "28464\n",
            "28465\n",
            "28466\n",
            "28467\n",
            "28468\n",
            "28469\n",
            "28470\n",
            "28471\n",
            "28472\n",
            "28473\n",
            "28474\n",
            "28475\n",
            "28476\n",
            "28477\n",
            "28478\n",
            "28479\n",
            "28480\n",
            "28481\n",
            "28482\n",
            "28483\n",
            "28484\n",
            "28485\n",
            "28486\n",
            "28487\n",
            "28488\n",
            "28489\n",
            "28490\n",
            "28491\n",
            "28492\n",
            "28493\n",
            "28494\n",
            "28495\n",
            "28496\n",
            "28497\n",
            "28498\n",
            "28499\n",
            "28500\n",
            "28501\n",
            "28502\n",
            "28503\n",
            "28504\n",
            "28505\n",
            "28506\n",
            "28507\n",
            "28508\n",
            "28509\n",
            "28510\n",
            "28511\n",
            "28512\n",
            "28513\n",
            "28514\n",
            "28515\n",
            "28516\n",
            "28517\n",
            "28518\n",
            "28519\n",
            "28520\n",
            "28521\n",
            "28522\n",
            "28523\n",
            "28524\n",
            "28525\n",
            "28526\n",
            "28527\n",
            "28528\n",
            "28529\n",
            "28530\n",
            "28531\n",
            "28532\n",
            "28533\n",
            "28534\n",
            "28535\n",
            "28536\n",
            "28537\n",
            "28538\n",
            "28539\n",
            "28540\n",
            "28541\n",
            "28542\n",
            "28543\n",
            "28544\n",
            "28545\n",
            "28546\n",
            "28547\n",
            "28548\n",
            "28549\n",
            "28550\n",
            "28551\n",
            "28552\n",
            "28553\n",
            "28554\n",
            "28555\n",
            "28556\n",
            "28557\n",
            "28558\n",
            "28559\n",
            "28560\n",
            "28561\n",
            "28562\n",
            "28563\n",
            "28564\n",
            "28565\n",
            "28566\n",
            "28567\n",
            "28568\n",
            "28569\n",
            "28570\n",
            "28571\n",
            "28572\n",
            "28573\n",
            "28574\n",
            "28575\n",
            "28576\n",
            "28577\n",
            "28578\n",
            "28579\n",
            "28580\n",
            "28581\n",
            "28582\n",
            "28583\n",
            "28584\n",
            "28585\n",
            "28586\n",
            "28587\n",
            "28588\n",
            "28589\n",
            "28590\n",
            "28591\n",
            "28592\n",
            "28593\n",
            "28594\n",
            "28595\n",
            "28596\n",
            "28597\n",
            "28598\n",
            "28599\n",
            "28600\n",
            "28601\n",
            "28602\n",
            "28603\n",
            "28604\n",
            "28605\n",
            "28606\n",
            "28607\n",
            "28608\n",
            "28609\n",
            "28610\n",
            "28611\n",
            "28612\n",
            "28613\n",
            "28614\n",
            "28615\n",
            "28616\n",
            "28617\n",
            "28618\n",
            "28619\n",
            "28620\n",
            "28621\n",
            "28622\n",
            "28623\n",
            "28624\n",
            "28625\n",
            "28626\n",
            "28627\n",
            "28628\n",
            "28629\n",
            "28630\n",
            "28631\n",
            "28632\n",
            "28633\n",
            "28634\n",
            "28635\n",
            "28636\n",
            "28637\n",
            "28638\n",
            "28639\n",
            "28640\n",
            "28641\n",
            "28642\n",
            "28643\n",
            "28644\n",
            "28645\n",
            "28646\n",
            "28647\n",
            "28648\n",
            "28649\n",
            "28650\n",
            "28651\n",
            "28652\n",
            "28653\n",
            "28654\n",
            "28655\n",
            "28656\n",
            "28657\n",
            "28658\n",
            "28659\n",
            "28660\n",
            "28661\n",
            "28662\n",
            "28663\n",
            "28664\n",
            "28665\n",
            "28666\n",
            "28667\n",
            "28668\n",
            "28669\n",
            "28670\n",
            "28671\n",
            "28672\n",
            "28673\n",
            "28674\n",
            "28675\n",
            "28676\n",
            "28677\n",
            "28678\n",
            "28679\n",
            "28680\n",
            "28681\n",
            "28682\n",
            "28683\n",
            "28684\n",
            "28685\n",
            "28686\n",
            "28687\n",
            "28688\n",
            "28689\n",
            "28690\n",
            "28691\n",
            "28692\n",
            "28693\n",
            "28694\n",
            "28695\n",
            "28696\n",
            "28697\n",
            "28698\n",
            "28699\n",
            "28700\n",
            "28701\n",
            "28702\n",
            "28703\n",
            "28704\n",
            "28705\n",
            "28706\n",
            "28707\n",
            "28708\n",
            "28709\n",
            "28710\n",
            "28711\n",
            "28712\n",
            "28713\n",
            "28714\n",
            "28715\n",
            "28716\n",
            "28717\n",
            "28718\n",
            "28719\n",
            "28720\n",
            "28721\n",
            "28722\n",
            "28723\n",
            "28724\n",
            "28725\n",
            "28726\n",
            "28727\n",
            "28728\n",
            "28729\n",
            "28730\n",
            "28731\n",
            "28732\n",
            "28733\n",
            "28734\n",
            "28735\n",
            "28736\n",
            "28737\n",
            "28738\n",
            "28739\n",
            "28740\n",
            "28741\n",
            "28742\n",
            "28743\n",
            "28744\n",
            "28745\n",
            "28746\n",
            "28747\n",
            "28748\n",
            "28749\n",
            "28750\n",
            "28751\n",
            "28752\n",
            "28753\n",
            "28754\n",
            "28755\n",
            "28756\n",
            "28757\n",
            "28758\n",
            "28759\n",
            "28760\n",
            "28761\n",
            "28762\n",
            "28763\n",
            "28764\n",
            "28765\n",
            "28766\n",
            "28767\n",
            "28768\n",
            "28769\n",
            "28770\n",
            "28771\n",
            "28772\n",
            "28773\n",
            "28774\n",
            "28775\n",
            "28776\n",
            "28777\n",
            "28778\n",
            "28779\n",
            "28780\n",
            "28781\n",
            "28782\n",
            "28783\n",
            "28784\n",
            "28785\n",
            "28786\n",
            "28787\n",
            "28788\n",
            "28789\n",
            "28790\n",
            "28791\n",
            "28792\n",
            "28793\n",
            "28794\n",
            "28795\n",
            "28796\n",
            "28797\n",
            "28798\n",
            "28799\n",
            "28800\n",
            "28801\n",
            "28802\n",
            "28803\n",
            "28804\n",
            "28805\n",
            "28806\n",
            "28807\n",
            "28808\n",
            "28809\n",
            "28810\n",
            "28811\n",
            "28812\n",
            "28813\n",
            "28814\n",
            "28815\n",
            "28816\n",
            "28817\n",
            "28818\n",
            "28819\n",
            "28820\n",
            "28821\n",
            "28822\n",
            "28823\n",
            "28824\n",
            "28825\n",
            "28826\n",
            "28827\n",
            "28828\n",
            "28829\n",
            "28830\n",
            "28831\n",
            "28832\n",
            "28833\n",
            "28834\n",
            "28835\n",
            "28836\n",
            "28837\n",
            "28838\n",
            "28839\n",
            "28840\n",
            "28841\n",
            "28842\n",
            "28843\n",
            "28844\n",
            "28845\n",
            "28846\n",
            "28847\n",
            "28848\n",
            "28849\n",
            "28850\n",
            "28851\n",
            "28852\n",
            "28853\n",
            "28854\n",
            "28855\n",
            "28856\n",
            "28857\n",
            "28858\n",
            "28859\n",
            "28860\n",
            "28861\n",
            "28862\n",
            "28863\n",
            "28864\n",
            "28865\n",
            "28866\n",
            "28867\n",
            "28868\n",
            "28869\n",
            "28870\n",
            "28871\n",
            "28872\n",
            "28873\n",
            "28874\n",
            "28875\n",
            "28876\n",
            "28877\n",
            "28878\n",
            "28879\n",
            "28880\n",
            "28881\n",
            "28882\n",
            "28883\n",
            "28884\n",
            "28885\n",
            "28886\n",
            "28887\n",
            "28888\n",
            "28889\n",
            "28890\n",
            "28891\n",
            "28892\n",
            "28893\n",
            "28894\n",
            "28895\n",
            "28896\n",
            "28897\n",
            "28898\n",
            "28899\n",
            "28900\n",
            "28901\n",
            "28902\n",
            "28903\n",
            "28904\n",
            "28905\n",
            "28906\n",
            "28907\n",
            "28908\n",
            "28909\n",
            "28910\n",
            "28911\n",
            "28912\n",
            "28913\n",
            "28914\n",
            "28915\n",
            "28916\n",
            "28917\n",
            "28918\n",
            "28919\n",
            "28920\n",
            "28921\n",
            "28922\n",
            "28923\n",
            "28924\n",
            "28925\n",
            "28926\n",
            "28927\n",
            "28928\n",
            "28929\n",
            "28930\n",
            "28931\n",
            "28932\n",
            "28933\n",
            "28934\n",
            "28935\n",
            "28936\n",
            "28937\n",
            "28938\n",
            "28939\n",
            "28940\n",
            "28941\n",
            "28942\n",
            "28943\n",
            "28944\n",
            "28945\n",
            "28946\n",
            "28947\n",
            "28948\n",
            "28949\n",
            "28950\n",
            "28951\n",
            "28952\n",
            "28953\n",
            "28954\n",
            "28955\n",
            "28956\n",
            "28957\n",
            "28958\n",
            "28959\n",
            "28960\n",
            "28961\n",
            "28962\n",
            "28963\n",
            "28964\n",
            "28965\n",
            "28966\n",
            "28967\n",
            "28968\n",
            "28969\n",
            "28970\n",
            "28971\n",
            "28972\n",
            "28973\n",
            "28974\n",
            "28975\n",
            "28976\n",
            "28977\n",
            "28978\n",
            "28979\n",
            "28980\n",
            "28981\n",
            "28982\n",
            "28983\n",
            "28984\n",
            "28985\n",
            "28986\n",
            "28987\n",
            "28988\n",
            "28989\n",
            "28990\n",
            "28991\n",
            "28992\n",
            "28993\n",
            "28994\n",
            "28995\n",
            "28996\n",
            "28997\n",
            "28998\n",
            "28999\n",
            "29000\n",
            "29001\n",
            "29002\n",
            "29003\n",
            "29004\n",
            "29005\n",
            "29006\n",
            "29007\n",
            "29008\n",
            "29009\n",
            "29010\n",
            "29011\n",
            "29012\n",
            "29013\n",
            "29014\n",
            "29015\n",
            "29016\n",
            "29017\n",
            "29018\n",
            "29019\n",
            "29020\n",
            "29021\n",
            "29022\n",
            "29023\n",
            "29024\n",
            "29025\n",
            "29026\n",
            "29027\n",
            "29028\n",
            "29029\n",
            "29030\n",
            "29031\n",
            "29032\n",
            "29033\n",
            "29034\n",
            "29035\n",
            "29036\n",
            "29037\n",
            "29038\n",
            "29039\n",
            "29040\n",
            "29041\n",
            "29042\n",
            "29043\n",
            "29044\n",
            "29045\n",
            "29046\n",
            "29047\n",
            "29048\n",
            "29049\n",
            "29050\n",
            "29051\n",
            "29052\n",
            "29053\n",
            "29054\n",
            "29055\n",
            "29056\n",
            "29057\n",
            "29058\n",
            "29059\n",
            "29060\n",
            "29061\n",
            "29062\n",
            "29063\n",
            "29064\n",
            "29065\n",
            "29066\n",
            "29067\n",
            "29068\n",
            "29069\n",
            "29070\n",
            "29071\n",
            "29072\n",
            "29073\n",
            "29074\n",
            "29075\n",
            "29076\n",
            "29077\n",
            "29078\n",
            "29079\n",
            "29080\n",
            "29081\n",
            "29082\n",
            "29083\n",
            "29084\n",
            "29085\n",
            "29086\n",
            "29087\n",
            "29088\n",
            "29089\n",
            "29090\n",
            "29091\n",
            "29092\n",
            "29093\n",
            "29094\n",
            "29095\n",
            "29096\n",
            "29097\n",
            "29098\n",
            "29099\n",
            "29100\n",
            "29101\n",
            "29102\n",
            "29103\n",
            "29104\n",
            "29105\n",
            "29106\n",
            "29107\n",
            "29108\n",
            "29109\n",
            "29110\n",
            "29111\n",
            "29112\n",
            "29113\n",
            "29114\n",
            "29115\n",
            "29116\n",
            "29117\n",
            "29118\n",
            "29119\n",
            "29120\n",
            "29121\n",
            "29122\n",
            "29123\n",
            "29124\n",
            "29125\n",
            "29126\n",
            "29127\n",
            "29128\n",
            "29129\n",
            "29130\n",
            "29131\n",
            "29132\n",
            "29133\n",
            "29134\n",
            "29135\n",
            "29136\n",
            "29137\n",
            "29138\n",
            "29139\n",
            "29140\n",
            "29141\n",
            "29142\n",
            "29143\n",
            "29144\n",
            "29145\n",
            "29146\n",
            "29147\n",
            "29148\n",
            "29149\n",
            "29150\n",
            "29151\n",
            "29152\n",
            "29153\n",
            "29154\n",
            "29155\n",
            "29156\n",
            "29157\n",
            "29158\n",
            "29159\n",
            "29160\n",
            "29161\n",
            "29162\n",
            "29163\n",
            "29164\n",
            "29165\n",
            "29166\n",
            "29167\n",
            "29168\n",
            "29169\n",
            "29170\n",
            "29171\n",
            "29172\n",
            "29173\n",
            "29174\n",
            "29175\n",
            "29176\n",
            "29177\n",
            "29178\n",
            "29179\n",
            "29180\n",
            "29181\n",
            "29182\n",
            "29183\n",
            "29184\n",
            "29185\n",
            "29186\n",
            "29187\n",
            "29188\n",
            "29189\n",
            "29190\n",
            "29191\n",
            "29192\n",
            "29193\n",
            "29194\n",
            "29195\n",
            "29196\n",
            "29197\n",
            "29198\n",
            "29199\n",
            "29200\n",
            "29201\n",
            "29202\n",
            "29203\n",
            "29204\n",
            "29205\n",
            "29206\n",
            "29207\n",
            "29208\n",
            "29209\n",
            "29210\n",
            "29211\n",
            "29212\n",
            "29213\n",
            "29214\n",
            "29215\n",
            "29216\n",
            "29217\n",
            "29218\n",
            "29219\n",
            "29220\n",
            "29221\n",
            "29222\n",
            "29223\n",
            "29224\n",
            "29225\n",
            "29226\n",
            "29227\n",
            "29228\n",
            "29229\n",
            "29230\n",
            "29231\n",
            "29232\n",
            "29233\n",
            "29234\n",
            "29235\n",
            "29236\n",
            "29237\n",
            "29238\n",
            "29239\n",
            "29240\n",
            "29241\n",
            "29242\n",
            "29243\n",
            "29244\n",
            "29245\n",
            "29246\n",
            "29247\n",
            "29248\n",
            "29249\n",
            "29250\n",
            "29251\n",
            "29252\n",
            "29253\n",
            "29254\n",
            "29255\n",
            "29256\n",
            "29257\n",
            "29258\n",
            "29259\n",
            "29260\n",
            "29261\n",
            "29262\n",
            "29263\n",
            "29264\n",
            "29265\n",
            "29266\n",
            "29267\n",
            "29268\n",
            "29269\n",
            "29270\n",
            "29271\n",
            "29272\n",
            "29273\n",
            "29274\n",
            "29275\n",
            "29276\n",
            "29277\n",
            "29278\n",
            "29279\n",
            "29280\n",
            "29281\n",
            "29282\n",
            "29283\n",
            "29284\n",
            "29285\n",
            "29286\n",
            "29287\n",
            "29288\n",
            "29289\n",
            "29290\n",
            "29291\n",
            "29292\n",
            "29293\n",
            "29294\n",
            "29295\n",
            "29296\n",
            "29297\n",
            "29298\n",
            "29299\n",
            "29300\n",
            "29301\n",
            "29302\n",
            "29303\n",
            "29304\n",
            "29305\n",
            "29306\n",
            "29307\n",
            "29308\n",
            "29309\n",
            "29310\n",
            "29311\n",
            "29312\n",
            "29313\n",
            "29314\n",
            "29315\n",
            "29316\n",
            "29317\n",
            "29318\n",
            "29319\n",
            "29320\n",
            "29321\n",
            "29322\n",
            "29323\n",
            "29324\n",
            "29325\n",
            "29326\n",
            "29327\n",
            "29328\n",
            "29329\n",
            "29330\n",
            "29331\n",
            "29332\n",
            "29333\n",
            "29334\n",
            "29335\n",
            "29336\n",
            "29337\n",
            "29338\n",
            "29339\n",
            "29340\n",
            "29341\n",
            "29342\n",
            "29343\n",
            "29344\n",
            "29345\n",
            "29346\n",
            "29347\n",
            "29348\n",
            "29349\n",
            "29350\n",
            "29351\n",
            "29352\n",
            "29353\n",
            "29354\n",
            "29355\n",
            "29356\n",
            "29357\n",
            "29358\n",
            "29359\n",
            "29360\n",
            "29361\n",
            "29362\n",
            "29363\n",
            "29364\n",
            "29365\n",
            "29366\n",
            "29367\n",
            "29368\n",
            "29369\n",
            "29370\n",
            "29371\n",
            "29372\n",
            "29373\n",
            "29374\n",
            "29375\n",
            "29376\n",
            "29377\n",
            "29378\n",
            "29379\n",
            "29380\n",
            "29381\n",
            "29382\n",
            "29383\n",
            "29384\n",
            "29385\n",
            "29386\n",
            "29387\n",
            "29388\n",
            "29389\n",
            "29390\n",
            "29391\n",
            "29392\n",
            "29393\n",
            "29394\n",
            "29395\n",
            "29396\n",
            "29397\n",
            "29398\n",
            "29399\n",
            "29400\n",
            "29401\n",
            "29402\n",
            "29403\n",
            "29404\n",
            "29405\n",
            "29406\n",
            "29407\n",
            "29408\n",
            "29409\n",
            "29410\n",
            "29411\n",
            "29412\n",
            "29413\n",
            "29414\n",
            "29415\n",
            "29416\n",
            "29417\n",
            "29418\n",
            "29419\n",
            "29420\n",
            "29421\n",
            "29422\n",
            "29423\n",
            "29424\n",
            "29425\n",
            "29426\n",
            "29427\n",
            "29428\n",
            "29429\n",
            "29430\n",
            "29431\n",
            "29432\n",
            "29433\n",
            "29434\n",
            "29435\n",
            "29436\n",
            "29437\n",
            "29438\n",
            "29439\n",
            "29440\n",
            "29441\n",
            "29442\n",
            "29443\n",
            "29444\n",
            "29445\n",
            "29446\n",
            "29447\n",
            "29448\n",
            "29449\n",
            "29450\n",
            "29451\n",
            "29452\n",
            "29453\n",
            "29454\n",
            "29455\n",
            "29456\n",
            "29457\n",
            "29458\n",
            "29459\n",
            "29460\n",
            "29461\n",
            "29462\n",
            "29463\n",
            "29464\n",
            "29465\n",
            "29466\n",
            "29467\n",
            "29468\n",
            "29469\n",
            "29470\n",
            "29471\n",
            "29472\n",
            "29473\n",
            "29474\n",
            "29475\n",
            "29476\n",
            "29477\n",
            "29478\n",
            "29479\n",
            "29480\n",
            "29481\n",
            "29482\n",
            "29483\n",
            "29484\n",
            "29485\n",
            "29486\n",
            "29487\n",
            "29488\n",
            "29489\n",
            "29490\n",
            "29491\n",
            "29492\n",
            "29493\n",
            "29494\n",
            "29495\n",
            "29496\n",
            "29497\n",
            "29498\n",
            "29499\n",
            "29500\n",
            "29501\n",
            "29502\n",
            "29503\n",
            "29504\n",
            "29505\n",
            "29506\n",
            "29507\n",
            "29508\n",
            "29509\n",
            "29510\n",
            "29511\n",
            "29512\n",
            "29513\n",
            "29514\n",
            "29515\n",
            "29516\n",
            "29517\n",
            "29518\n",
            "29519\n",
            "29520\n",
            "29521\n",
            "29522\n",
            "29523\n",
            "29524\n",
            "29525\n",
            "29526\n",
            "29527\n",
            "29528\n",
            "29529\n",
            "29530\n",
            "29531\n",
            "29532\n",
            "29533\n",
            "29534\n",
            "29535\n",
            "29536\n",
            "29537\n",
            "29538\n",
            "29539\n",
            "29540\n",
            "29541\n",
            "29542\n",
            "29543\n",
            "29544\n",
            "29545\n",
            "29546\n",
            "29547\n",
            "29548\n",
            "29549\n",
            "29550\n",
            "29551\n",
            "29552\n",
            "29553\n",
            "29554\n",
            "29555\n",
            "29556\n",
            "29557\n",
            "29558\n",
            "29559\n",
            "29560\n",
            "29561\n",
            "29562\n",
            "29563\n",
            "29564\n",
            "29565\n",
            "29566\n",
            "29567\n",
            "29568\n",
            "29569\n",
            "29570\n",
            "29571\n",
            "29572\n",
            "29573\n",
            "29574\n",
            "29575\n",
            "29576\n",
            "29577\n",
            "29578\n",
            "29579\n",
            "29580\n",
            "29581\n",
            "29582\n",
            "29583\n",
            "29584\n",
            "29585\n",
            "29586\n",
            "29587\n",
            "29588\n",
            "29589\n",
            "29590\n",
            "29591\n",
            "29592\n",
            "29593\n",
            "29594\n",
            "29595\n",
            "29596\n",
            "29597\n",
            "29598\n",
            "29599\n",
            "29600\n",
            "29601\n",
            "29602\n",
            "29603\n",
            "29604\n",
            "29605\n",
            "29606\n",
            "29607\n",
            "29608\n",
            "29609\n",
            "29610\n",
            "29611\n",
            "29612\n",
            "29613\n",
            "29614\n",
            "29615\n",
            "29616\n",
            "29617\n",
            "29618\n",
            "29619\n",
            "29620\n",
            "29621\n",
            "29622\n",
            "29623\n",
            "29624\n",
            "29625\n",
            "29626\n",
            "29627\n",
            "29628\n",
            "29629\n",
            "29630\n",
            "29631\n",
            "29632\n",
            "29633\n",
            "29634\n",
            "29635\n",
            "29636\n",
            "29637\n",
            "29638\n",
            "29639\n",
            "29640\n",
            "29641\n",
            "29642\n",
            "29643\n",
            "29644\n",
            "29645\n",
            "29646\n",
            "29647\n",
            "29648\n",
            "29649\n",
            "29650\n",
            "29651\n",
            "29652\n",
            "29653\n",
            "29654\n",
            "29655\n",
            "29656\n",
            "29657\n",
            "29658\n",
            "29659\n",
            "29660\n",
            "29661\n",
            "29662\n",
            "29663\n",
            "29664\n",
            "29665\n",
            "29666\n",
            "29667\n",
            "29668\n",
            "29669\n",
            "29670\n",
            "29671\n",
            "29672\n",
            "29673\n",
            "29674\n",
            "29675\n",
            "29676\n",
            "29677\n",
            "29678\n",
            "29679\n",
            "29680\n",
            "29681\n",
            "29682\n",
            "29683\n",
            "29684\n",
            "29685\n",
            "29686\n",
            "29687\n",
            "29688\n",
            "29689\n",
            "29690\n",
            "29691\n",
            "29692\n",
            "29693\n",
            "29694\n",
            "29695\n",
            "29696\n",
            "29697\n",
            "29698\n",
            "29699\n",
            "29700\n",
            "29701\n",
            "29702\n",
            "29703\n",
            "29704\n",
            "29705\n",
            "29706\n",
            "29707\n",
            "29708\n",
            "29709\n",
            "29710\n",
            "29711\n",
            "29712\n",
            "29713\n",
            "29714\n",
            "29715\n",
            "29716\n",
            "29717\n",
            "29718\n",
            "29719\n",
            "29720\n",
            "29721\n",
            "29722\n",
            "29723\n",
            "29724\n",
            "29725\n",
            "29726\n",
            "29727\n",
            "29728\n",
            "29729\n",
            "29730\n",
            "29731\n",
            "29732\n",
            "29733\n",
            "29734\n",
            "29735\n",
            "29736\n",
            "29737\n",
            "29738\n",
            "29739\n",
            "29740\n",
            "29741\n",
            "29742\n",
            "29743\n",
            "29744\n",
            "29745\n",
            "29746\n",
            "29747\n",
            "29748\n",
            "29749\n",
            "29750\n",
            "29751\n"
          ]
        }
      ],
      "source": [
        "data_try = get_correct_labels(my_df)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FTjPgy1aK2l_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d31d02-d297-453c-fccd-c3f35938380e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'am', 'going', 'to', 'Jammu', '-', 'Kashmir']\n",
            "[None, 0, 1, 2, 3, 4, 5, 6, None]\n",
            "I PRON\n",
            "am AUX\n",
            "going VERB\n",
            "to ADP\n",
            "Jammu PROPN\n",
            "- PUNCT\n",
            "Kashmir PROPN\n"
          ]
        }
      ],
      "source": [
        "t = tokenizer.tokenize(\"I am going to Jammu-Kashmir\")\n",
        "print(t)\n",
        "ti = tokenizer(\"I am going to Jammu-Kashmir\")\n",
        "print(ti.word_ids())\n",
        "\n",
        "d = nlp(\"I am going to Jammu-Kashmir\")\n",
        "for t in d:\n",
        "  print(t.text,t.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL\n"
      ],
      "metadata": {
        "id": "8qOrw5Ajf6na"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "riozd-JnECcn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "df = pd.DataFrame(data_try)\n",
        "\n",
        "#train_df, val_df = train_test_split(df, train_size=0.8)\n",
        "train_df = df[:10000]\n",
        "val_df = df[10000:]\n",
        "\n",
        "my_dataset = DatasetDict({\n",
        "     \"train\":Dataset.from_pandas(train_df),\n",
        "     \"eval\": Dataset.from_pandas(val_df)\n",
        " })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HlFwOGCXEaoW"
      },
      "outputs": [],
      "source": [
        "my_dataset = my_dataset.remove_columns([\"token_type_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3AaJGJPvP6xS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True, return_tensors='pt')\n",
        "\n",
        "train_dataset = my_dataset[\"train\"].shuffle(seed=42)\n",
        "eval_dataset = my_dataset[\"eval\"].shuffle(seed=42)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, shuffle = True, batch_size=16, collate_fn=data_collator)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=16,collate_fn=data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IkJEBwHJQBsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7775e0-fa26-457d-ee3a-ad5f168ac8d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LwGoAsIMQBu3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "3358278e90b9458d88390fbbb2e6cb6e",
            "cbc07186385c4b37b50eb727662771ba",
            "175d284632e1436e8addeeed81d5322d",
            "8e290ceaf69d4c999ac6f8a29a7c011a",
            "fad7256560b049b5a68b68d80420140e",
            "8ffcc7274ba94dca8951744ac308f3f6",
            "3757c2b535954390812fd851bc2fac50",
            "05ee25a8a525470a843e86b874de4663",
            "d2b357cf59964412a09d5b0227d9ada3",
            "1285747a9da440c9bd8c3a9458938dc2",
            "7916d1a4ee2c4c3e9aea19aa757b6118"
          ]
        },
        "outputId": "71b1d655-653f-4881-ce7b-75725e44fddb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3358278e90b9458d88390fbbb2e6cb6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "from torch.optim import AdamW\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=18)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Iw86nNfuZgrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728a47a3-3911-4fb8-d1e8-bb8f4a41e4d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pnAk7l1QP44",
        "outputId": "857d6334-b9b3-458b-9352-b017efdb31a4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "Batch  0 :  tensor(2.9611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  1 :  tensor(2.9378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  2 :  tensor(2.8915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  3 :  tensor(2.8863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  4 :  tensor(2.8191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  5 :  tensor(2.7752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  6 :  tensor(2.7696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  7 :  tensor(2.6664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  8 :  tensor(2.7190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  9 :  tensor(2.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  10 :  tensor(2.5906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  11 :  tensor(2.5505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  12 :  tensor(2.5159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  13 :  tensor(2.4548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  14 :  tensor(2.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  15 :  tensor(2.4852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  16 :  tensor(2.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  17 :  tensor(2.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  18 :  tensor(2.2537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  19 :  tensor(2.3140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  20 :  tensor(2.2735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  21 :  tensor(2.3060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  22 :  tensor(2.1306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  23 :  tensor(2.2666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  24 :  tensor(1.9688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  25 :  tensor(2.2123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  26 :  tensor(2.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  27 :  tensor(2.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  28 :  tensor(1.9661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  29 :  tensor(2.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  30 :  tensor(1.7549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  31 :  tensor(1.9621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  32 :  tensor(2.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  33 :  tensor(1.8817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  34 :  tensor(2.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  35 :  tensor(1.6695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  36 :  tensor(2.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  37 :  tensor(1.6495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  38 :  tensor(1.8609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  39 :  tensor(1.7337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  40 :  tensor(1.8468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  41 :  tensor(1.7937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  42 :  tensor(1.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  43 :  tensor(1.5675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  44 :  tensor(1.6561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  45 :  tensor(1.4072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  46 :  tensor(1.5191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  47 :  tensor(1.8428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  48 :  tensor(1.4524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  49 :  tensor(1.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  50 :  tensor(1.4622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  51 :  tensor(1.3298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  52 :  tensor(1.3888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  53 :  tensor(1.2962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  54 :  tensor(1.4469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  55 :  tensor(1.5101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  56 :  tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  57 :  tensor(1.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  58 :  tensor(1.3734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  59 :  tensor(1.2400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  60 :  tensor(1.2682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  61 :  tensor(1.1209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  62 :  tensor(1.1265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  63 :  tensor(1.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  64 :  tensor(1.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  65 :  tensor(1.3598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  66 :  tensor(1.1217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  67 :  tensor(1.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  68 :  tensor(1.1010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  69 :  tensor(0.9796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  70 :  tensor(0.9808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  71 :  tensor(0.8927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  72 :  tensor(0.8917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  73 :  tensor(1.2080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  74 :  tensor(1.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  75 :  tensor(1.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  76 :  tensor(1.2142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  77 :  tensor(0.9665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  78 :  tensor(0.8965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  79 :  tensor(0.7777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  80 :  tensor(0.8548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  81 :  tensor(0.8605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  82 :  tensor(0.8930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  83 :  tensor(0.7655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  84 :  tensor(0.6695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  85 :  tensor(0.9031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  86 :  tensor(0.8656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  87 :  tensor(0.7347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  88 :  tensor(0.8527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  89 :  tensor(0.6774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  90 :  tensor(0.8036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  91 :  tensor(0.7042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  92 :  tensor(0.7121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  93 :  tensor(0.7291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  94 :  tensor(0.6324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  95 :  tensor(0.6485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  96 :  tensor(0.6099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  97 :  tensor(0.5700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  98 :  tensor(0.8489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  99 :  tensor(0.4981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  100 :  tensor(0.8448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  101 :  tensor(0.9747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  102 :  tensor(0.6884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  103 :  tensor(0.5693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  104 :  tensor(0.6273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  105 :  tensor(0.6667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  106 :  tensor(0.5273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  107 :  tensor(0.7554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  108 :  tensor(0.5206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  109 :  tensor(0.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  110 :  tensor(0.6968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  111 :  tensor(0.5383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  112 :  tensor(0.4238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  113 :  tensor(0.5841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  114 :  tensor(0.5352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  115 :  tensor(1.1237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  116 :  tensor(0.6710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  117 :  tensor(0.9366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  118 :  tensor(0.6245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  119 :  tensor(0.5928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  120 :  tensor(0.4346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  121 :  tensor(0.3576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  122 :  tensor(0.7770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  123 :  tensor(0.4938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  124 :  tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  125 :  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  126 :  tensor(0.3616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  127 :  tensor(0.5352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  128 :  tensor(0.4767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  129 :  tensor(0.3947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  130 :  tensor(0.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  131 :  tensor(0.4338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  132 :  tensor(0.3153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  133 :  tensor(0.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  134 :  tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  135 :  tensor(0.5971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  136 :  tensor(0.5208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  137 :  tensor(0.4703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  138 :  tensor(0.4917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  139 :  tensor(0.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  140 :  tensor(0.5074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  141 :  tensor(0.4869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  142 :  tensor(0.5372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  143 :  tensor(0.2429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  144 :  tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  145 :  tensor(0.3233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  146 :  tensor(0.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  147 :  tensor(0.3098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  148 :  tensor(0.3556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  149 :  tensor(0.7093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  150 :  tensor(0.2986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  151 :  tensor(1.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  152 :  tensor(0.3322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  153 :  tensor(0.8577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  154 :  tensor(0.2709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  155 :  tensor(0.2577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  156 :  tensor(0.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  157 :  tensor(0.3013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  158 :  tensor(0.3565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  159 :  tensor(0.6664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  160 :  tensor(0.3319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  161 :  tensor(0.9320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  162 :  tensor(0.2989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  163 :  tensor(0.3789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  164 :  tensor(0.5829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  165 :  tensor(0.3560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  166 :  tensor(0.4726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  167 :  tensor(0.3478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  168 :  tensor(0.2703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  169 :  tensor(0.6184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  170 :  tensor(0.6888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  171 :  tensor(0.6794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  172 :  tensor(0.9081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  173 :  tensor(0.2671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  174 :  tensor(0.3812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  175 :  tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  176 :  tensor(0.4277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  177 :  tensor(0.6237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  178 :  tensor(0.2463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  179 :  tensor(0.8801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  180 :  tensor(0.7135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  181 :  tensor(0.3817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  182 :  tensor(0.3123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  183 :  tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  184 :  tensor(0.3082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  185 :  tensor(0.2728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  186 :  tensor(0.5639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  187 :  tensor(0.2639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  188 :  tensor(0.2795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  189 :  tensor(0.9243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  190 :  tensor(0.4267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  191 :  tensor(0.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  192 :  tensor(0.3299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  193 :  tensor(0.2139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  194 :  tensor(0.2139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  195 :  tensor(0.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  196 :  tensor(0.4408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  197 :  tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  198 :  tensor(0.2900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  199 :  tensor(0.2248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  200 :  tensor(0.4973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  201 :  tensor(0.2223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  202 :  tensor(0.4951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  203 :  tensor(0.4935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  204 :  tensor(0.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  205 :  tensor(0.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  206 :  tensor(0.2991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  207 :  tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  208 :  tensor(0.5079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  209 :  tensor(1.2578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  210 :  tensor(1.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  211 :  tensor(0.3043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  212 :  tensor(1.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  213 :  tensor(0.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  214 :  tensor(0.3661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  215 :  tensor(0.2118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  216 :  tensor(0.2334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  217 :  tensor(0.2155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  218 :  tensor(0.2934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  219 :  tensor(0.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  220 :  tensor(0.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  221 :  tensor(0.2644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  222 :  tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  223 :  tensor(0.2282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  224 :  tensor(0.3784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  225 :  tensor(0.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  226 :  tensor(1.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  227 :  tensor(0.3107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  228 :  tensor(0.1952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  229 :  tensor(1.0614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  230 :  tensor(0.4833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  231 :  tensor(0.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  232 :  tensor(0.4798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  233 :  tensor(0.5841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  234 :  tensor(0.5727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  235 :  tensor(0.3455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  236 :  tensor(0.2273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  237 :  tensor(0.4756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  238 :  tensor(0.2586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  239 :  tensor(0.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  240 :  tensor(1.1181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  241 :  tensor(0.2485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  242 :  tensor(0.2568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  243 :  tensor(0.2589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  244 :  tensor(0.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  245 :  tensor(0.3613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  246 :  tensor(0.2422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  247 :  tensor(0.2295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  248 :  tensor(0.5474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  249 :  tensor(0.2050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  250 :  tensor(0.2610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  251 :  tensor(0.2176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  252 :  tensor(0.8230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  253 :  tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  254 :  tensor(0.2130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  255 :  tensor(0.2973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  256 :  tensor(0.4447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  257 :  tensor(0.3066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  258 :  tensor(0.2840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  259 :  tensor(0.6585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  260 :  tensor(0.3120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  261 :  tensor(0.2283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  262 :  tensor(0.3333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  263 :  tensor(0.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  264 :  tensor(0.6902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  265 :  tensor(0.5527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  266 :  tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  267 :  tensor(0.2309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  268 :  tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  269 :  tensor(0.2891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  270 :  tensor(0.9109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  271 :  tensor(0.3043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  272 :  tensor(0.3399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  273 :  tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  274 :  tensor(0.2787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  275 :  tensor(0.4398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  276 :  tensor(0.3033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  277 :  tensor(0.7884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  278 :  tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  279 :  tensor(0.5274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  280 :  tensor(0.6227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  281 :  tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  282 :  tensor(0.2070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  283 :  tensor(0.3468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  284 :  tensor(0.5199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  285 :  tensor(0.3761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  286 :  tensor(0.2844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  287 :  tensor(0.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  288 :  tensor(0.1530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  289 :  tensor(0.3146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  290 :  tensor(0.2563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  291 :  tensor(0.4319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  292 :  tensor(0.5005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  293 :  tensor(0.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  294 :  tensor(0.3305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  295 :  tensor(0.4834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  296 :  tensor(0.4217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  297 :  tensor(0.4067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  298 :  tensor(0.1858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  299 :  tensor(0.2886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  300 :  tensor(0.1638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  301 :  tensor(0.2189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  302 :  tensor(0.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  303 :  tensor(0.2534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  304 :  tensor(0.2158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  305 :  tensor(0.3101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  306 :  tensor(0.3776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  307 :  tensor(0.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  308 :  tensor(0.3583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  309 :  tensor(0.2039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  310 :  tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  311 :  tensor(0.8093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  312 :  tensor(0.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  313 :  tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  314 :  tensor(0.7270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  315 :  tensor(0.2090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  316 :  tensor(0.1845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  317 :  tensor(0.1234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  318 :  tensor(0.2167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  319 :  tensor(0.3259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  320 :  tensor(0.1937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  321 :  tensor(0.7992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  322 :  tensor(0.5444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  323 :  tensor(0.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  324 :  tensor(0.2019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  325 :  tensor(0.2848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  326 :  tensor(0.3308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  327 :  tensor(0.5128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  328 :  tensor(0.1863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  329 :  tensor(0.1819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  330 :  tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  331 :  tensor(0.2926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  332 :  tensor(0.3876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  333 :  tensor(0.4730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  334 :  tensor(0.2355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  335 :  tensor(0.8939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  336 :  tensor(0.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  337 :  tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  338 :  tensor(0.2199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  339 :  tensor(0.7603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  340 :  tensor(0.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  341 :  tensor(0.3154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  342 :  tensor(0.6951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  343 :  tensor(0.4770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  344 :  tensor(0.2678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  345 :  tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  346 :  tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  347 :  tensor(0.7216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  348 :  tensor(0.2850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  349 :  tensor(0.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  350 :  tensor(0.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  351 :  tensor(0.5444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  352 :  tensor(0.4162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  353 :  tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  354 :  tensor(0.6723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  355 :  tensor(0.2502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  356 :  tensor(0.1850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  357 :  tensor(0.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  358 :  tensor(0.3808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  359 :  tensor(0.4444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  360 :  tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  361 :  tensor(0.3498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  362 :  tensor(0.3065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  363 :  tensor(0.2476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  364 :  tensor(0.3062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  365 :  tensor(0.4918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  366 :  tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  367 :  tensor(0.4258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  368 :  tensor(0.3809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  369 :  tensor(0.2240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  370 :  tensor(0.3263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  371 :  tensor(0.1859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  372 :  tensor(0.2636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  373 :  tensor(0.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  374 :  tensor(0.2941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  375 :  tensor(0.3436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  376 :  tensor(0.5448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  377 :  tensor(0.4820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  378 :  tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  379 :  tensor(1.0714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  380 :  tensor(0.5533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  381 :  tensor(0.4572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  382 :  tensor(0.3906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  383 :  tensor(0.2888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  384 :  tensor(0.2088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  385 :  tensor(0.8876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  386 :  tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  387 :  tensor(0.4069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  388 :  tensor(0.1747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  389 :  tensor(0.2010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  390 :  tensor(0.7730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  391 :  tensor(0.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  392 :  tensor(0.2572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  393 :  tensor(0.2615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  394 :  tensor(0.5325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  395 :  tensor(0.3244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  396 :  tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  397 :  tensor(0.6479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  398 :  tensor(0.3450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  399 :  tensor(0.2621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  400 :  tensor(0.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  401 :  tensor(0.2902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  402 :  tensor(0.7215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  403 :  tensor(0.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  404 :  tensor(0.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  405 :  tensor(0.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  406 :  tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  407 :  tensor(0.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  408 :  tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  409 :  tensor(0.2140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  410 :  tensor(0.5082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  411 :  tensor(0.8322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  412 :  tensor(0.2363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  413 :  tensor(0.6365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  414 :  tensor(0.1010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  415 :  tensor(0.2310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  416 :  tensor(0.2149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  417 :  tensor(0.6522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  418 :  tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  419 :  tensor(0.3904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  420 :  tensor(0.2201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  421 :  tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  422 :  tensor(0.5179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  423 :  tensor(0.4319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  424 :  tensor(0.5861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  425 :  tensor(0.2523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  426 :  tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  427 :  tensor(0.2475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  428 :  tensor(0.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  429 :  tensor(0.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  430 :  tensor(0.7834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  431 :  tensor(0.3060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  432 :  tensor(0.5228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  433 :  tensor(0.3976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  434 :  tensor(0.4510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  435 :  tensor(0.3653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  436 :  tensor(0.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  437 :  tensor(0.3779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  438 :  tensor(0.2100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  439 :  tensor(0.7900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  440 :  tensor(0.3014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  441 :  tensor(0.6279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  442 :  tensor(0.2636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  443 :  tensor(0.5304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  444 :  tensor(0.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  445 :  tensor(0.3796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  446 :  tensor(0.2153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  447 :  tensor(0.4165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  448 :  tensor(0.2248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  449 :  tensor(0.3289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  450 :  tensor(0.1434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  451 :  tensor(0.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  452 :  tensor(0.1850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  453 :  tensor(0.3501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  454 :  tensor(0.1524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  455 :  tensor(0.2903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  456 :  tensor(0.2285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  457 :  tensor(0.3039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  458 :  tensor(0.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  459 :  tensor(0.2191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  460 :  tensor(0.1476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  461 :  tensor(0.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  462 :  tensor(0.2078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  463 :  tensor(0.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  464 :  tensor(0.3373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  465 :  tensor(0.3850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  466 :  tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  467 :  tensor(0.2059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  468 :  tensor(0.3301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  469 :  tensor(0.1936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  470 :  tensor(0.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  471 :  tensor(0.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  472 :  tensor(0.1033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  473 :  tensor(0.1237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  474 :  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  475 :  tensor(0.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  476 :  tensor(0.2429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  477 :  tensor(0.4461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  478 :  tensor(0.7298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  479 :  tensor(0.2454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  480 :  tensor(0.2195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  481 :  tensor(0.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  482 :  tensor(0.3325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  483 :  tensor(0.6535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  484 :  tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  485 :  tensor(0.1861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  486 :  tensor(0.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  487 :  tensor(0.6883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  488 :  tensor(0.2273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  489 :  tensor(0.1331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  490 :  tensor(0.6432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  491 :  tensor(0.1553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  492 :  tensor(0.1710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  493 :  tensor(0.1454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  494 :  tensor(0.3309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  495 :  tensor(0.6003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  496 :  tensor(0.7699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  497 :  tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  498 :  tensor(0.2487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  499 :  tensor(0.4392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  500 :  tensor(0.2638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  501 :  tensor(0.6532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  502 :  tensor(0.8446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  503 :  tensor(0.4561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  504 :  tensor(0.2412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  505 :  tensor(0.1788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  506 :  tensor(0.1112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  507 :  tensor(0.7188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  508 :  tensor(0.1595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  509 :  tensor(0.1650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  510 :  tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  511 :  tensor(0.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  512 :  tensor(0.2077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  513 :  tensor(0.4346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  514 :  tensor(0.4591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  515 :  tensor(0.4997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  516 :  tensor(0.6961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  517 :  tensor(0.2353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  518 :  tensor(0.1932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  519 :  tensor(0.2162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  520 :  tensor(0.3438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  521 :  tensor(0.9156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  522 :  tensor(0.2244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  523 :  tensor(0.2486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  524 :  tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  525 :  tensor(0.4634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  526 :  tensor(0.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  527 :  tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  528 :  tensor(0.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  529 :  tensor(0.2166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  530 :  tensor(0.3291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  531 :  tensor(0.1601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  532 :  tensor(0.3082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  533 :  tensor(0.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  534 :  tensor(0.1560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  535 :  tensor(0.7457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  536 :  tensor(0.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  537 :  tensor(0.3922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  538 :  tensor(0.2911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  539 :  tensor(0.3291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  540 :  tensor(0.2541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  541 :  tensor(0.5423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  542 :  tensor(0.3149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  543 :  tensor(0.4059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  544 :  tensor(0.1641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  545 :  tensor(0.2982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  546 :  tensor(0.1855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  547 :  tensor(0.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  548 :  tensor(0.2333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  549 :  tensor(0.2734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  550 :  tensor(0.1918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  551 :  tensor(0.4855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  552 :  tensor(0.2304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  553 :  tensor(0.2961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  554 :  tensor(0.2672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  555 :  tensor(0.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  556 :  tensor(0.2320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  557 :  tensor(0.4788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  558 :  tensor(0.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  559 :  tensor(0.1726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  560 :  tensor(0.1806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  561 :  tensor(0.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  562 :  tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  563 :  tensor(0.6465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  564 :  tensor(0.2787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  565 :  tensor(0.1415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  566 :  tensor(0.4478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  567 :  tensor(0.7056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  568 :  tensor(0.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  569 :  tensor(0.4924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  570 :  tensor(0.2043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  571 :  tensor(0.3677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  572 :  tensor(0.2156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  573 :  tensor(0.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  574 :  tensor(0.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  575 :  tensor(0.1599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  576 :  tensor(0.1171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  577 :  tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  578 :  tensor(0.4569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  579 :  tensor(0.1957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  580 :  tensor(0.7063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  581 :  tensor(0.3733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  582 :  tensor(0.1703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  583 :  tensor(0.3092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  584 :  tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  585 :  tensor(0.2516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  586 :  tensor(0.6246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  587 :  tensor(0.1375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  588 :  tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  589 :  tensor(0.5244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  590 :  tensor(0.1910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  591 :  tensor(0.4568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  592 :  tensor(0.5385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  593 :  tensor(0.4002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  594 :  tensor(0.4163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  595 :  tensor(0.2178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  596 :  tensor(0.2658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  597 :  tensor(0.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  598 :  tensor(0.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  599 :  tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  600 :  tensor(0.2671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  601 :  tensor(0.5604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  602 :  tensor(0.2046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  603 :  tensor(0.2020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  604 :  tensor(0.6396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  605 :  tensor(0.3767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  606 :  tensor(0.7390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  607 :  tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  608 :  tensor(0.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  609 :  tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  610 :  tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  611 :  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  612 :  tensor(0.3397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  613 :  tensor(0.1611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  614 :  tensor(0.4509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  615 :  tensor(0.8909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  616 :  tensor(0.3436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  617 :  tensor(0.4413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  618 :  tensor(0.1393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  619 :  tensor(0.3980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  620 :  tensor(0.1803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  621 :  tensor(0.2649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  622 :  tensor(0.2240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  623 :  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  624 :  tensor(1.0276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "TRAIN LOSS: tensor(0.5794, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch : 2\n",
            "Batch  0 :  tensor(0.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  1 :  tensor(0.2013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  2 :  tensor(0.1457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  3 :  tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  4 :  tensor(0.1398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  5 :  tensor(0.2367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  6 :  tensor(0.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  7 :  tensor(0.4479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  8 :  tensor(0.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  9 :  tensor(0.1977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  10 :  tensor(0.1503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  11 :  tensor(0.3304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  12 :  tensor(0.2339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  13 :  tensor(0.4479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  14 :  tensor(0.3161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  15 :  tensor(0.2176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  16 :  tensor(0.1169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  17 :  tensor(0.1526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  18 :  tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  19 :  tensor(0.1496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  20 :  tensor(0.2709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  21 :  tensor(0.1336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  22 :  tensor(0.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  23 :  tensor(0.1279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  24 :  tensor(0.7178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  25 :  tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  26 :  tensor(0.7093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  27 :  tensor(0.1529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  28 :  tensor(0.8012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  29 :  tensor(0.3409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  30 :  tensor(0.2775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  31 :  tensor(0.1551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  32 :  tensor(0.3973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  33 :  tensor(0.1332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  34 :  tensor(0.1650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  35 :  tensor(0.2659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  36 :  tensor(0.8696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  37 :  tensor(0.4555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  38 :  tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  39 :  tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  40 :  tensor(0.1525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  41 :  tensor(0.5900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  42 :  tensor(0.2442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  43 :  tensor(0.7429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  44 :  tensor(0.1876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  45 :  tensor(0.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  46 :  tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  47 :  tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  48 :  tensor(0.2330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  49 :  tensor(0.4295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  50 :  tensor(0.2939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  51 :  tensor(0.1668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  52 :  tensor(0.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  53 :  tensor(0.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  54 :  tensor(0.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  55 :  tensor(0.6399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  56 :  tensor(0.4500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  57 :  tensor(0.2650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  58 :  tensor(0.5171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  59 :  tensor(0.4649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  60 :  tensor(0.3352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  61 :  tensor(0.6832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  62 :  tensor(0.1764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  63 :  tensor(0.1746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  64 :  tensor(0.3530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  65 :  tensor(0.5391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  66 :  tensor(0.5782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  67 :  tensor(0.2864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  68 :  tensor(0.6493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  69 :  tensor(0.4026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  70 :  tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  71 :  tensor(0.1640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  72 :  tensor(0.2017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  73 :  tensor(0.2120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  74 :  tensor(0.3393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  75 :  tensor(0.2474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  76 :  tensor(0.5876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  77 :  tensor(0.2242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  78 :  tensor(0.1843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  79 :  tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  80 :  tensor(0.1218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  81 :  tensor(0.1981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  82 :  tensor(0.9124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  83 :  tensor(0.2478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  84 :  tensor(0.2153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  85 :  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  86 :  tensor(0.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  87 :  tensor(0.4615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  88 :  tensor(0.6963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  89 :  tensor(0.2233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  90 :  tensor(1.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  91 :  tensor(0.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  92 :  tensor(0.3589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  93 :  tensor(0.1980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  94 :  tensor(0.2898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  95 :  tensor(0.1724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  96 :  tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  97 :  tensor(0.9317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  98 :  tensor(0.1520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  99 :  tensor(0.1456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  100 :  tensor(0.2570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  101 :  tensor(0.4018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  102 :  tensor(0.2131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  103 :  tensor(0.3548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  104 :  tensor(0.5378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  105 :  tensor(0.6742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  106 :  tensor(0.1731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  107 :  tensor(0.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  108 :  tensor(0.4276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  109 :  tensor(0.7608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  110 :  tensor(0.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  111 :  tensor(0.2594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  112 :  tensor(0.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  113 :  tensor(0.4405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  114 :  tensor(0.5995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  115 :  tensor(0.4135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  116 :  tensor(0.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  117 :  tensor(0.4652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  118 :  tensor(0.5613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  119 :  tensor(0.2207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  120 :  tensor(0.6206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  121 :  tensor(0.2717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  122 :  tensor(0.2884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  123 :  tensor(0.2060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  124 :  tensor(0.4199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  125 :  tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  126 :  tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  127 :  tensor(0.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  128 :  tensor(0.1876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  129 :  tensor(0.7525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  130 :  tensor(0.3110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  131 :  tensor(0.5184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  132 :  tensor(0.5559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  133 :  tensor(0.3045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  134 :  tensor(0.1914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  135 :  tensor(0.2384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  136 :  tensor(0.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  137 :  tensor(0.1239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  138 :  tensor(0.3055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  139 :  tensor(0.4254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  140 :  tensor(0.2772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  141 :  tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  142 :  tensor(0.1139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  143 :  tensor(0.2053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  144 :  tensor(0.1826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  145 :  tensor(0.2327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  146 :  tensor(0.5198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  147 :  tensor(0.3557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  148 :  tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  149 :  tensor(0.7524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  150 :  tensor(0.7620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  151 :  tensor(0.5156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  152 :  tensor(0.1903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  153 :  tensor(0.4494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  154 :  tensor(0.3557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  155 :  tensor(0.1377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  156 :  tensor(0.2434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  157 :  tensor(0.2143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  158 :  tensor(0.3711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  159 :  tensor(0.4755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  160 :  tensor(0.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  161 :  tensor(0.1921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  162 :  tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  163 :  tensor(0.6455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  164 :  tensor(0.2018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  165 :  tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  166 :  tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  167 :  tensor(0.2239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  168 :  tensor(0.1471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  169 :  tensor(0.2937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  170 :  tensor(0.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  171 :  tensor(0.1569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  172 :  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  173 :  tensor(0.4022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  174 :  tensor(0.1271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  175 :  tensor(0.4537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  176 :  tensor(0.1441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  177 :  tensor(0.2030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  178 :  tensor(0.2337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  179 :  tensor(1.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  180 :  tensor(0.2374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  181 :  tensor(0.4238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  182 :  tensor(0.5117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  183 :  tensor(0.7494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  184 :  tensor(0.3161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  185 :  tensor(0.3532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  186 :  tensor(0.2346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  187 :  tensor(0.2226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  188 :  tensor(0.2989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  189 :  tensor(0.3242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  190 :  tensor(0.1310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  191 :  tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  192 :  tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  193 :  tensor(0.6680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  194 :  tensor(0.1770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  195 :  tensor(0.3017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  196 :  tensor(0.1508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  197 :  tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  198 :  tensor(0.3278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  199 :  tensor(0.1442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  200 :  tensor(0.6403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  201 :  tensor(0.1349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  202 :  tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  203 :  tensor(0.5147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  204 :  tensor(0.1995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  205 :  tensor(0.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  206 :  tensor(0.8495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  207 :  tensor(0.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  208 :  tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  209 :  tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  210 :  tensor(0.2413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  211 :  tensor(0.2113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  212 :  tensor(0.1003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  213 :  tensor(0.2482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  214 :  tensor(0.4470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  215 :  tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  216 :  tensor(0.1707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  217 :  tensor(0.1206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  218 :  tensor(0.2504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  219 :  tensor(0.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  220 :  tensor(0.3767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  221 :  tensor(0.0866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  222 :  tensor(0.1356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  223 :  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  224 :  tensor(0.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  225 :  tensor(0.8746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  226 :  tensor(0.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  227 :  tensor(0.3207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  228 :  tensor(0.2817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  229 :  tensor(0.3838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  230 :  tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  231 :  tensor(0.1492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  232 :  tensor(0.2678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  233 :  tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  234 :  tensor(0.1430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  235 :  tensor(0.2249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  236 :  tensor(0.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  237 :  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  238 :  tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  239 :  tensor(0.1191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  240 :  tensor(0.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  241 :  tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  242 :  tensor(0.1326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  243 :  tensor(0.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  244 :  tensor(0.1275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  245 :  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  246 :  tensor(0.2712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  247 :  tensor(0.2184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  248 :  tensor(0.1985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  249 :  tensor(0.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  250 :  tensor(0.1268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  251 :  tensor(0.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  252 :  tensor(0.1637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  253 :  tensor(0.3806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  254 :  tensor(0.8743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  255 :  tensor(0.1259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  256 :  tensor(0.3632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  257 :  tensor(0.1563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  258 :  tensor(0.3264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  259 :  tensor(0.1724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  260 :  tensor(0.3012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  261 :  tensor(0.2448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  262 :  tensor(0.2558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  263 :  tensor(0.3369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  264 :  tensor(0.3303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  265 :  tensor(0.1769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  266 :  tensor(0.3435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  267 :  tensor(0.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  268 :  tensor(0.2930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  269 :  tensor(0.2399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  270 :  tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  271 :  tensor(0.5383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  272 :  tensor(0.1974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  273 :  tensor(0.1649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  274 :  tensor(0.2503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  275 :  tensor(0.2075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  276 :  tensor(0.1589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  277 :  tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  278 :  tensor(0.7067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  279 :  tensor(0.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  280 :  tensor(0.4422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  281 :  tensor(0.4942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  282 :  tensor(0.3340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  283 :  tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  284 :  tensor(0.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  285 :  tensor(0.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  286 :  tensor(0.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  287 :  tensor(0.2998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  288 :  tensor(0.1908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  289 :  tensor(0.1132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  290 :  tensor(0.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  291 :  tensor(0.2184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  292 :  tensor(0.1747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  293 :  tensor(0.3540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  294 :  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  295 :  tensor(0.1115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  296 :  tensor(0.1382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  297 :  tensor(0.3945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  298 :  tensor(0.1438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  299 :  tensor(0.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  300 :  tensor(0.1472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  301 :  tensor(0.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  302 :  tensor(0.2273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  303 :  tensor(0.5179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  304 :  tensor(0.6470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  305 :  tensor(0.1400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  306 :  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  307 :  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  308 :  tensor(0.3985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  309 :  tensor(0.4877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  310 :  tensor(0.2308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  311 :  tensor(0.1479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  312 :  tensor(1.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  313 :  tensor(0.3706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  314 :  tensor(0.2608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  315 :  tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  316 :  tensor(0.3360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  317 :  tensor(0.1623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  318 :  tensor(0.2291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  319 :  tensor(0.2162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  320 :  tensor(0.7274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  321 :  tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  322 :  tensor(0.4595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  323 :  tensor(0.1974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  324 :  tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  325 :  tensor(0.1088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  326 :  tensor(0.4943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  327 :  tensor(0.1889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  328 :  tensor(0.4831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  329 :  tensor(0.5839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  330 :  tensor(0.3738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  331 :  tensor(0.6487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  332 :  tensor(0.4647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  333 :  tensor(0.1741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  334 :  tensor(0.1853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  335 :  tensor(0.2884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  336 :  tensor(0.9796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  337 :  tensor(0.1534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  338 :  tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  339 :  tensor(0.5436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  340 :  tensor(0.2824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  341 :  tensor(0.2528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  342 :  tensor(0.3778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  343 :  tensor(0.2720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  344 :  tensor(0.1436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  345 :  tensor(0.2500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  346 :  tensor(0.8240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  347 :  tensor(0.4450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  348 :  tensor(0.6198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  349 :  tensor(0.1489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  350 :  tensor(0.9562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  351 :  tensor(0.3554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  352 :  tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  353 :  tensor(0.1697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  354 :  tensor(0.2872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  355 :  tensor(0.3502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  356 :  tensor(0.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  357 :  tensor(0.2020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  358 :  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  359 :  tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  360 :  tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  361 :  tensor(0.0785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  362 :  tensor(0.5928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  363 :  tensor(0.2234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  364 :  tensor(0.2213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  365 :  tensor(0.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  366 :  tensor(0.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  367 :  tensor(0.4397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  368 :  tensor(0.7122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  369 :  tensor(0.2433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  370 :  tensor(0.2164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  371 :  tensor(0.6492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  372 :  tensor(0.1863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  373 :  tensor(0.1891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  374 :  tensor(0.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  375 :  tensor(0.1234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  376 :  tensor(0.4604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  377 :  tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  378 :  tensor(0.1893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  379 :  tensor(0.1635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  380 :  tensor(0.1601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  381 :  tensor(0.4022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  382 :  tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  383 :  tensor(0.0991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  384 :  tensor(0.1860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  385 :  tensor(0.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  386 :  tensor(0.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  387 :  tensor(0.1695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  388 :  tensor(0.1924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  389 :  tensor(0.2729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  390 :  tensor(0.1181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  391 :  tensor(0.1627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  392 :  tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  393 :  tensor(0.3759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  394 :  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  395 :  tensor(0.1836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  396 :  tensor(0.2945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  397 :  tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  398 :  tensor(0.3275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  399 :  tensor(0.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  400 :  tensor(0.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  401 :  tensor(0.1565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  402 :  tensor(0.2969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  403 :  tensor(0.2259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  404 :  tensor(0.3748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  405 :  tensor(0.1953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  406 :  tensor(0.1065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  407 :  tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  408 :  tensor(0.2062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  409 :  tensor(0.1538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  410 :  tensor(0.5110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  411 :  tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  412 :  tensor(0.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  413 :  tensor(0.5711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  414 :  tensor(0.0866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  415 :  tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  416 :  tensor(0.2060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  417 :  tensor(0.1314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  418 :  tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  419 :  tensor(0.3944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  420 :  tensor(0.2024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  421 :  tensor(0.4142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  422 :  tensor(0.1499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  423 :  tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  424 :  tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  425 :  tensor(0.1683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  426 :  tensor(0.4538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  427 :  tensor(0.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  428 :  tensor(0.1712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  429 :  tensor(0.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  430 :  tensor(0.1280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  431 :  tensor(0.1831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  432 :  tensor(0.1226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  433 :  tensor(0.1726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  434 :  tensor(0.1104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  435 :  tensor(0.1398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  436 :  tensor(0.1089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  437 :  tensor(0.1813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  438 :  tensor(0.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  439 :  tensor(0.1783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  440 :  tensor(0.5016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  441 :  tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  442 :  tensor(0.1089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  443 :  tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  444 :  tensor(0.0794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  445 :  tensor(0.2210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  446 :  tensor(0.2153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  447 :  tensor(0.5738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  448 :  tensor(0.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  449 :  tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  450 :  tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  451 :  tensor(0.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  452 :  tensor(0.4238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  453 :  tensor(0.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  454 :  tensor(0.2243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  455 :  tensor(0.4030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  456 :  tensor(0.5747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  457 :  tensor(0.1406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  458 :  tensor(0.1214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  459 :  tensor(0.2492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  460 :  tensor(0.3469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  461 :  tensor(0.1109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  462 :  tensor(0.2073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  463 :  tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  464 :  tensor(0.1727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  465 :  tensor(0.1448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  466 :  tensor(0.5407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  467 :  tensor(0.1384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  468 :  tensor(0.2499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  469 :  tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  470 :  tensor(0.1752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  471 :  tensor(0.0906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  472 :  tensor(0.1556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  473 :  tensor(0.2593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  474 :  tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  475 :  tensor(0.5245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  476 :  tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  477 :  tensor(0.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  478 :  tensor(0.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  479 :  tensor(0.5691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  480 :  tensor(0.2230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  481 :  tensor(0.1496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  482 :  tensor(0.5132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  483 :  tensor(0.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  484 :  tensor(0.1300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  485 :  tensor(0.1557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  486 :  tensor(0.1095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  487 :  tensor(0.1839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  488 :  tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  489 :  tensor(0.1295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  490 :  tensor(0.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  491 :  tensor(0.1399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  492 :  tensor(0.8387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  493 :  tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  494 :  tensor(0.1513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  495 :  tensor(0.2477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  496 :  tensor(0.5282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  497 :  tensor(0.4731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  498 :  tensor(0.1654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  499 :  tensor(0.1041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  500 :  tensor(0.5075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  501 :  tensor(0.3981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  502 :  tensor(0.2924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  503 :  tensor(0.2033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  504 :  tensor(0.1523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  505 :  tensor(0.2674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  506 :  tensor(0.9117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  507 :  tensor(0.7316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  508 :  tensor(0.4094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  509 :  tensor(0.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  510 :  tensor(0.2306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  511 :  tensor(0.1659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  512 :  tensor(0.1728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  513 :  tensor(0.2758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  514 :  tensor(0.1645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  515 :  tensor(0.4701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  516 :  tensor(0.3663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  517 :  tensor(0.1020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  518 :  tensor(0.1539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  519 :  tensor(0.1914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  520 :  tensor(0.1631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  521 :  tensor(0.1513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  522 :  tensor(0.6883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  523 :  tensor(0.6216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  524 :  tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  525 :  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  526 :  tensor(0.1350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  527 :  tensor(0.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  528 :  tensor(0.5118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  529 :  tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  530 :  tensor(0.1433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  531 :  tensor(0.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  532 :  tensor(0.2139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  533 :  tensor(0.1503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  534 :  tensor(0.2113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  535 :  tensor(0.3791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  536 :  tensor(0.1191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  537 :  tensor(0.3816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  538 :  tensor(0.7546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  539 :  tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  540 :  tensor(0.5607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  541 :  tensor(0.1707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  542 :  tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  543 :  tensor(0.3450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  544 :  tensor(0.1935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  545 :  tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  546 :  tensor(0.1927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  547 :  tensor(0.3911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  548 :  tensor(0.1224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  549 :  tensor(0.2161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  550 :  tensor(0.0958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  551 :  tensor(0.3887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  552 :  tensor(0.2171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  553 :  tensor(0.6677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  554 :  tensor(0.3007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  555 :  tensor(0.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  556 :  tensor(0.2652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  557 :  tensor(0.1274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  558 :  tensor(0.5115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  559 :  tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  560 :  tensor(0.3148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  561 :  tensor(0.2294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  562 :  tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  563 :  tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  564 :  tensor(0.1686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  565 :  tensor(0.1630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  566 :  tensor(0.2221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  567 :  tensor(0.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  568 :  tensor(0.2824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  569 :  tensor(0.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  570 :  tensor(0.4189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  571 :  tensor(0.3954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  572 :  tensor(0.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  573 :  tensor(0.1757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  574 :  tensor(0.5213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  575 :  tensor(0.1411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  576 :  tensor(0.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  577 :  tensor(0.2376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  578 :  tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  579 :  tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  580 :  tensor(0.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  581 :  tensor(0.4353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  582 :  tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  583 :  tensor(0.1226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  584 :  tensor(0.2184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  585 :  tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  586 :  tensor(0.1637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  587 :  tensor(0.3323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  588 :  tensor(0.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  589 :  tensor(0.3756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  590 :  tensor(0.2264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  591 :  tensor(0.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  592 :  tensor(0.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  593 :  tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  594 :  tensor(0.1350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  595 :  tensor(0.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  596 :  tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  597 :  tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  598 :  tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  599 :  tensor(0.1165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  600 :  tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  601 :  tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  602 :  tensor(0.1943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  603 :  tensor(0.1113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  604 :  tensor(0.3338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  605 :  tensor(0.2878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  606 :  tensor(0.5415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  607 :  tensor(0.1630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  608 :  tensor(0.5454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  609 :  tensor(0.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  610 :  tensor(0.3490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  611 :  tensor(0.3615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  612 :  tensor(0.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  613 :  tensor(0.6482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  614 :  tensor(0.3029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  615 :  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  616 :  tensor(0.5288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  617 :  tensor(0.3298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  618 :  tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  619 :  tensor(0.2992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  620 :  tensor(0.4758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  621 :  tensor(0.1502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  622 :  tensor(0.5366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  623 :  tensor(0.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  624 :  tensor(0.1917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "TRAIN LOSS: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch : 3\n",
            "Batch  0 :  tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  1 :  tensor(0.1433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  2 :  tensor(0.1832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  3 :  tensor(0.1606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  4 :  tensor(0.2059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  5 :  tensor(0.3197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  6 :  tensor(0.1873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  7 :  tensor(0.1045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  8 :  tensor(0.2906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  9 :  tensor(0.3949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  10 :  tensor(0.5066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  11 :  tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  12 :  tensor(0.1288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  13 :  tensor(0.1459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  14 :  tensor(0.2137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  15 :  tensor(0.1242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  16 :  tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  17 :  tensor(0.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  18 :  tensor(0.0981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  19 :  tensor(0.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  20 :  tensor(0.8959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  21 :  tensor(0.5840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  22 :  tensor(0.4838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  23 :  tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  24 :  tensor(0.1929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  25 :  tensor(0.8347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  26 :  tensor(0.1377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  27 :  tensor(0.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  28 :  tensor(0.2502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  29 :  tensor(0.2050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  30 :  tensor(0.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  31 :  tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  32 :  tensor(0.2917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  33 :  tensor(0.2076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  34 :  tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  35 :  tensor(0.3009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  36 :  tensor(0.1096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  37 :  tensor(0.1109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  38 :  tensor(0.2220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  39 :  tensor(0.1510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  40 :  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  41 :  tensor(0.1808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  42 :  tensor(0.2044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  43 :  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  44 :  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  45 :  tensor(0.2543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  46 :  tensor(0.1095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  47 :  tensor(0.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  48 :  tensor(0.1592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  49 :  tensor(0.2313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  50 :  tensor(0.1013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  51 :  tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  52 :  tensor(0.1261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  53 :  tensor(0.3245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  54 :  tensor(0.5320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  55 :  tensor(0.2115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  56 :  tensor(0.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  57 :  tensor(0.5136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  58 :  tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  59 :  tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  60 :  tensor(0.3988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  61 :  tensor(0.2178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  62 :  tensor(0.5414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  63 :  tensor(0.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  64 :  tensor(0.3820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  65 :  tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  66 :  tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  67 :  tensor(0.4088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  68 :  tensor(0.2088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  69 :  tensor(0.2012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  70 :  tensor(0.6380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  71 :  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  72 :  tensor(0.1816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  73 :  tensor(0.2538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  74 :  tensor(0.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  75 :  tensor(0.2779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  76 :  tensor(0.1300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  77 :  tensor(0.1879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  78 :  tensor(0.2427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  79 :  tensor(0.2440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  80 :  tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  81 :  tensor(0.1772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  82 :  tensor(0.1158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  83 :  tensor(0.2969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  84 :  tensor(0.1426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  85 :  tensor(0.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  86 :  tensor(0.1523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  87 :  tensor(0.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  88 :  tensor(0.7856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  89 :  tensor(0.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  90 :  tensor(0.6823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  91 :  tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  92 :  tensor(0.3905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  93 :  tensor(0.4312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  94 :  tensor(0.1388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  95 :  tensor(0.4743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  96 :  tensor(0.3082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  97 :  tensor(0.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  98 :  tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  99 :  tensor(0.2129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  100 :  tensor(0.1895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  101 :  tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  102 :  tensor(0.5111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  103 :  tensor(0.1357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  104 :  tensor(0.5584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  105 :  tensor(0.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  106 :  tensor(0.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  107 :  tensor(0.1871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  108 :  tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  109 :  tensor(0.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  110 :  tensor(0.4938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  111 :  tensor(0.2197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  112 :  tensor(0.3875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  113 :  tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  114 :  tensor(0.3114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  115 :  tensor(0.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  116 :  tensor(0.0826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  117 :  tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  118 :  tensor(0.2880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  119 :  tensor(0.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  120 :  tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  121 :  tensor(0.2751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  122 :  tensor(0.4252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  123 :  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  124 :  tensor(0.1087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  125 :  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  126 :  tensor(0.1396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  127 :  tensor(0.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  128 :  tensor(0.5547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  129 :  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  130 :  tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  131 :  tensor(0.3479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  132 :  tensor(0.1395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  133 :  tensor(0.2488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  134 :  tensor(0.4306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  135 :  tensor(0.1867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  136 :  tensor(0.1904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  137 :  tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  138 :  tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  139 :  tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  140 :  tensor(0.5914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  141 :  tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  142 :  tensor(0.3892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  143 :  tensor(0.4082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  144 :  tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  145 :  tensor(0.3315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  146 :  tensor(0.3502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  147 :  tensor(0.1425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  148 :  tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  149 :  tensor(0.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  150 :  tensor(0.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  151 :  tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  152 :  tensor(0.1951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  153 :  tensor(0.3181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  154 :  tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  155 :  tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  156 :  tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  157 :  tensor(0.4282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  158 :  tensor(0.7661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  159 :  tensor(0.1591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  160 :  tensor(0.3421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  161 :  tensor(0.3667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  162 :  tensor(0.1681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  163 :  tensor(0.4510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  164 :  tensor(0.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  165 :  tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  166 :  tensor(0.4500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  167 :  tensor(0.1894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  168 :  tensor(0.2300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  169 :  tensor(0.1454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  170 :  tensor(0.3011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  171 :  tensor(0.2127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  172 :  tensor(0.1352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  173 :  tensor(0.1186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  174 :  tensor(0.5883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  175 :  tensor(0.1130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  176 :  tensor(0.1440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  177 :  tensor(0.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  178 :  tensor(0.4555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  179 :  tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  180 :  tensor(0.4831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  181 :  tensor(0.1621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  182 :  tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  183 :  tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  184 :  tensor(0.1924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  185 :  tensor(0.2047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  186 :  tensor(0.3891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  187 :  tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  188 :  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  189 :  tensor(0.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  190 :  tensor(0.4073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  191 :  tensor(0.2275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  192 :  tensor(0.1181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  193 :  tensor(0.1747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  194 :  tensor(0.0702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  195 :  tensor(0.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  196 :  tensor(0.4407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  197 :  tensor(0.3221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  198 :  tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  199 :  tensor(0.1404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  200 :  tensor(0.1368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  201 :  tensor(0.2787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  202 :  tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  203 :  tensor(0.2529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  204 :  tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  205 :  tensor(0.2574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  206 :  tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  207 :  tensor(0.0781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  208 :  tensor(0.6266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  209 :  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  210 :  tensor(0.0925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  211 :  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  212 :  tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  213 :  tensor(0.0776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  214 :  tensor(0.4964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  215 :  tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  216 :  tensor(0.1805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  217 :  tensor(0.3763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  218 :  tensor(0.1939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  219 :  tensor(0.2415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  220 :  tensor(0.1811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  221 :  tensor(0.1342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  222 :  tensor(0.0759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  223 :  tensor(0.2755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  224 :  tensor(0.2899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  225 :  tensor(0.0924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  226 :  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  227 :  tensor(0.1980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  228 :  tensor(0.1374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  229 :  tensor(0.1293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  230 :  tensor(0.2761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  231 :  tensor(0.1149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  232 :  tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  233 :  tensor(0.1020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  234 :  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  235 :  tensor(0.0420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  236 :  tensor(0.2206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  237 :  tensor(0.1379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  238 :  tensor(0.3662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  239 :  tensor(0.2728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  240 :  tensor(0.1259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  241 :  tensor(0.3791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  242 :  tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  243 :  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  244 :  tensor(0.8345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  245 :  tensor(0.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  246 :  tensor(0.3707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  247 :  tensor(0.1159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  248 :  tensor(0.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  249 :  tensor(0.5064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  250 :  tensor(0.1083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  251 :  tensor(0.4098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  252 :  tensor(0.6212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  253 :  tensor(0.3971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  254 :  tensor(0.6443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  255 :  tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  256 :  tensor(0.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  257 :  tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  258 :  tensor(0.2414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  259 :  tensor(0.4080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  260 :  tensor(0.2504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  261 :  tensor(0.1170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  262 :  tensor(0.3009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  263 :  tensor(0.1961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  264 :  tensor(0.1589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  265 :  tensor(0.4947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  266 :  tensor(0.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  267 :  tensor(0.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  268 :  tensor(0.2249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  269 :  tensor(0.2521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  270 :  tensor(0.1158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  271 :  tensor(0.1802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  272 :  tensor(0.1800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  273 :  tensor(0.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  274 :  tensor(0.2532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  275 :  tensor(0.1446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  276 :  tensor(0.1118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  277 :  tensor(0.1466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  278 :  tensor(0.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  279 :  tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  280 :  tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  281 :  tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  282 :  tensor(0.7170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  283 :  tensor(0.2527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  284 :  tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  285 :  tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  286 :  tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  287 :  tensor(0.0989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  288 :  tensor(0.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  289 :  tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  290 :  tensor(0.2402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  291 :  tensor(0.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  292 :  tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  293 :  tensor(0.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  294 :  tensor(0.1150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  295 :  tensor(0.2143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  296 :  tensor(0.3722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  297 :  tensor(0.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  298 :  tensor(0.1145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  299 :  tensor(0.1327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  300 :  tensor(0.0774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  301 :  tensor(0.0924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  302 :  tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  303 :  tensor(0.2872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  304 :  tensor(0.3374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  305 :  tensor(0.1010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  306 :  tensor(0.1739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  307 :  tensor(0.3176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  308 :  tensor(0.5203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  309 :  tensor(0.6859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  310 :  tensor(0.1113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  311 :  tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  312 :  tensor(0.2060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  313 :  tensor(0.5896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  314 :  tensor(0.2524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  315 :  tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  316 :  tensor(0.1178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  317 :  tensor(0.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  318 :  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  319 :  tensor(0.6770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  320 :  tensor(0.1909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  321 :  tensor(0.2608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  322 :  tensor(0.5182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  323 :  tensor(0.2196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  324 :  tensor(0.0971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  325 :  tensor(0.3043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  326 :  tensor(0.1595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  327 :  tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  328 :  tensor(0.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  329 :  tensor(0.8146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  330 :  tensor(0.1261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  331 :  tensor(0.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  332 :  tensor(0.3234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  333 :  tensor(0.3131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  334 :  tensor(0.2194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  335 :  tensor(0.2832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  336 :  tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  337 :  tensor(0.4301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  338 :  tensor(0.4360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  339 :  tensor(0.1800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  340 :  tensor(0.8677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  341 :  tensor(0.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  342 :  tensor(0.3056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  343 :  tensor(0.1646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  344 :  tensor(0.4392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  345 :  tensor(0.3247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  346 :  tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  347 :  tensor(0.1240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  348 :  tensor(0.0955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  349 :  tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  350 :  tensor(0.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  351 :  tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  352 :  tensor(0.3799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  353 :  tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  354 :  tensor(0.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  355 :  tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  356 :  tensor(0.2626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  357 :  tensor(0.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  358 :  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  359 :  tensor(0.1601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  360 :  tensor(0.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  361 :  tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  362 :  tensor(0.5963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  363 :  tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  364 :  tensor(0.2314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  365 :  tensor(0.2737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  366 :  tensor(0.1719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  367 :  tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  368 :  tensor(0.2200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  369 :  tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  370 :  tensor(0.3223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  371 :  tensor(0.2935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  372 :  tensor(0.0993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  373 :  tensor(0.2631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  374 :  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  375 :  tensor(0.3367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  376 :  tensor(0.2822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  377 :  tensor(0.1225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  378 :  tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  379 :  tensor(0.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  380 :  tensor(0.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  381 :  tensor(0.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  382 :  tensor(0.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  383 :  tensor(0.1909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  384 :  tensor(0.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  385 :  tensor(0.1432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  386 :  tensor(0.3037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  387 :  tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  388 :  tensor(0.0777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  389 :  tensor(0.1761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  390 :  tensor(0.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  391 :  tensor(0.5777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  392 :  tensor(0.4942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  393 :  tensor(0.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  394 :  tensor(0.1256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  395 :  tensor(0.2660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  396 :  tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  397 :  tensor(0.1265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  398 :  tensor(0.1066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  399 :  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  400 :  tensor(0.3645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  401 :  tensor(0.4205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  402 :  tensor(0.2048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  403 :  tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  404 :  tensor(0.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  405 :  tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  406 :  tensor(0.2068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  407 :  tensor(0.2813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  408 :  tensor(0.3069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  409 :  tensor(0.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  410 :  tensor(0.1564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  411 :  tensor(0.0798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  412 :  tensor(0.1346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  413 :  tensor(0.1391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  414 :  tensor(0.1748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  415 :  tensor(0.1763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  416 :  tensor(0.1185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  417 :  tensor(0.5163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  418 :  tensor(0.1054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  419 :  tensor(0.1760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  420 :  tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  421 :  tensor(0.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  422 :  tensor(0.1119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  423 :  tensor(0.3575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  424 :  tensor(0.5076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  425 :  tensor(0.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  426 :  tensor(0.4685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  427 :  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  428 :  tensor(0.3210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  429 :  tensor(0.4129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  430 :  tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  431 :  tensor(0.2578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  432 :  tensor(0.3334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  433 :  tensor(0.2404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  434 :  tensor(0.1639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  435 :  tensor(0.1442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  436 :  tensor(0.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  437 :  tensor(0.3274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  438 :  tensor(0.3288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  439 :  tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  440 :  tensor(0.2995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  441 :  tensor(0.2743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  442 :  tensor(0.1921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  443 :  tensor(0.1391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  444 :  tensor(0.3948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  445 :  tensor(0.2279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  446 :  tensor(0.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  447 :  tensor(0.1619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  448 :  tensor(0.3919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  449 :  tensor(0.2042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  450 :  tensor(0.1424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  451 :  tensor(0.3681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  452 :  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  453 :  tensor(0.0925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  454 :  tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  455 :  tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  456 :  tensor(0.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  457 :  tensor(0.1274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  458 :  tensor(0.3747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  459 :  tensor(0.1754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  460 :  tensor(0.1375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  461 :  tensor(1.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  462 :  tensor(0.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  463 :  tensor(0.5731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  464 :  tensor(0.2182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  465 :  tensor(0.1362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  466 :  tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  467 :  tensor(0.0932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  468 :  tensor(0.2898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  469 :  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  470 :  tensor(0.3864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  471 :  tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  472 :  tensor(0.1275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  473 :  tensor(0.4847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  474 :  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  475 :  tensor(0.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  476 :  tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  477 :  tensor(0.1112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  478 :  tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  479 :  tensor(0.5269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  480 :  tensor(0.4785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  481 :  tensor(0.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  482 :  tensor(0.1737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  483 :  tensor(0.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  484 :  tensor(0.4649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  485 :  tensor(0.2257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  486 :  tensor(0.1314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  487 :  tensor(0.3459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  488 :  tensor(0.1299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  489 :  tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  490 :  tensor(0.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  491 :  tensor(0.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  492 :  tensor(0.4839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  493 :  tensor(0.2762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  494 :  tensor(0.2260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  495 :  tensor(0.2835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  496 :  tensor(0.0937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  497 :  tensor(0.4400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  498 :  tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  499 :  tensor(0.5123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  500 :  tensor(0.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  501 :  tensor(0.4895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  502 :  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  503 :  tensor(0.1280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  504 :  tensor(0.5369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  505 :  tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  506 :  tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  507 :  tensor(0.1395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  508 :  tensor(0.4590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  509 :  tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  510 :  tensor(0.2294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  511 :  tensor(0.1909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  512 :  tensor(0.5140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  513 :  tensor(0.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  514 :  tensor(0.5090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  515 :  tensor(0.2682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  516 :  tensor(0.2670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  517 :  tensor(0.3826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  518 :  tensor(0.1893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  519 :  tensor(0.4388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  520 :  tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  521 :  tensor(0.1331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  522 :  tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  523 :  tensor(0.2085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  524 :  tensor(0.4055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  525 :  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  526 :  tensor(0.2351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  527 :  tensor(0.2857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  528 :  tensor(0.3973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  529 :  tensor(1.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  530 :  tensor(0.1359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  531 :  tensor(0.3215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  532 :  tensor(0.2863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  533 :  tensor(0.1670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  534 :  tensor(0.7867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  535 :  tensor(0.1017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  536 :  tensor(0.1242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  537 :  tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  538 :  tensor(0.1980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  539 :  tensor(0.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  540 :  tensor(0.3577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  541 :  tensor(0.2098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  542 :  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  543 :  tensor(0.1619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  544 :  tensor(0.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  545 :  tensor(0.1541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  546 :  tensor(0.1058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  547 :  tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  548 :  tensor(0.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  549 :  tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  550 :  tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  551 :  tensor(0.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  552 :  tensor(0.1510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  553 :  tensor(0.7151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  554 :  tensor(0.1380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  555 :  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  556 :  tensor(0.1834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  557 :  tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  558 :  tensor(0.4534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  559 :  tensor(0.0687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  560 :  tensor(0.0981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  561 :  tensor(0.3489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  562 :  tensor(0.1439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  563 :  tensor(0.0779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  564 :  tensor(0.1766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  565 :  tensor(0.6476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  566 :  tensor(0.7332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  567 :  tensor(0.5768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  568 :  tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  569 :  tensor(0.1993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  570 :  tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  571 :  tensor(0.6774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  572 :  tensor(0.1364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  573 :  tensor(0.1661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  574 :  tensor(0.1448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  575 :  tensor(0.5418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  576 :  tensor(0.6356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  577 :  tensor(0.3193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  578 :  tensor(0.3012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  579 :  tensor(0.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  580 :  tensor(0.1610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  581 :  tensor(0.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  582 :  tensor(0.2478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  583 :  tensor(0.3364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  584 :  tensor(0.3208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  585 :  tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  586 :  tensor(0.3061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  587 :  tensor(0.1442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  588 :  tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  589 :  tensor(0.5791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  590 :  tensor(0.2670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  591 :  tensor(0.2407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  592 :  tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  593 :  tensor(0.1880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  594 :  tensor(0.6575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  595 :  tensor(0.4960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  596 :  tensor(0.1749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  597 :  tensor(0.1085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  598 :  tensor(0.1683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  599 :  tensor(0.3319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  600 :  tensor(0.1704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  601 :  tensor(0.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  602 :  tensor(0.4469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  603 :  tensor(0.1978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  604 :  tensor(0.3762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  605 :  tensor(0.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  606 :  tensor(0.5786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  607 :  tensor(0.1589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  608 :  tensor(0.3274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  609 :  tensor(0.3708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  610 :  tensor(0.2751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  611 :  tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  612 :  tensor(0.1815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  613 :  tensor(0.1769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  614 :  tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  615 :  tensor(0.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  616 :  tensor(0.1908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  617 :  tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  618 :  tensor(0.3284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  619 :  tensor(0.1245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  620 :  tensor(0.5240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  621 :  tensor(0.1802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  622 :  tensor(0.1898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  623 :  tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  624 :  tensor(0.1308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "TRAIN LOSS: tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch : 4\n",
            "Batch  0 :  tensor(0.1200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  1 :  tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  2 :  tensor(0.1125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  3 :  tensor(0.4148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  4 :  tensor(0.1912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  5 :  tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  6 :  tensor(0.1413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  7 :  tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  8 :  tensor(0.1184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  9 :  tensor(0.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  10 :  tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  11 :  tensor(0.0693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  12 :  tensor(0.1619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  13 :  tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  14 :  tensor(0.1163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  15 :  tensor(0.2697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  16 :  tensor(0.3192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  17 :  tensor(0.2253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  18 :  tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  19 :  tensor(0.0913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  20 :  tensor(0.3129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  21 :  tensor(0.1910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  22 :  tensor(0.1543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  23 :  tensor(0.1602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  24 :  tensor(0.1395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  25 :  tensor(0.3012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  26 :  tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  27 :  tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  28 :  tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  29 :  tensor(0.0561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  30 :  tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  31 :  tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  32 :  tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  33 :  tensor(0.4231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  34 :  tensor(0.1242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  35 :  tensor(0.1990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  36 :  tensor(0.1919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  37 :  tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  38 :  tensor(0.1130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  39 :  tensor(0.3610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  40 :  tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  41 :  tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  42 :  tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  43 :  tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  44 :  tensor(0.3553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  45 :  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  46 :  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  47 :  tensor(0.3328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  48 :  tensor(0.4940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  49 :  tensor(0.4286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  50 :  tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  51 :  tensor(0.2313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  52 :  tensor(0.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  53 :  tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  54 :  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  55 :  tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  56 :  tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  57 :  tensor(0.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  58 :  tensor(0.2471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  59 :  tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  60 :  tensor(0.2340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  61 :  tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  62 :  tensor(0.4074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  63 :  tensor(0.1986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  64 :  tensor(0.3246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  65 :  tensor(0.0765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  66 :  tensor(0.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  67 :  tensor(0.1360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  68 :  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  69 :  tensor(0.1891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  70 :  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  71 :  tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  72 :  tensor(0.3352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  73 :  tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  74 :  tensor(0.1208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  75 :  tensor(0.1834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  76 :  tensor(0.3752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  77 :  tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  78 :  tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  79 :  tensor(0.2916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  80 :  tensor(0.3039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  81 :  tensor(0.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  82 :  tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  83 :  tensor(0.1957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  84 :  tensor(0.2610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  85 :  tensor(0.1012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  86 :  tensor(0.1044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  87 :  tensor(0.5925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  88 :  tensor(0.1990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  89 :  tensor(0.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  90 :  tensor(0.3051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  91 :  tensor(0.5616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  92 :  tensor(0.2275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  93 :  tensor(0.2826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  94 :  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  95 :  tensor(0.3286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  96 :  tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  97 :  tensor(0.4784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  98 :  tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  99 :  tensor(0.1678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  100 :  tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  101 :  tensor(0.2339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  102 :  tensor(0.0866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  103 :  tensor(0.2131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  104 :  tensor(0.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  105 :  tensor(0.5190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  106 :  tensor(0.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  107 :  tensor(0.0760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  108 :  tensor(0.2021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  109 :  tensor(0.2691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  110 :  tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  111 :  tensor(0.2547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  112 :  tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  113 :  tensor(0.1918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  114 :  tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  115 :  tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  116 :  tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  117 :  tensor(0.2101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  118 :  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  119 :  tensor(0.1133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  120 :  tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  121 :  tensor(0.2290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  122 :  tensor(0.2880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  123 :  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  124 :  tensor(0.2500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  125 :  tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  126 :  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  127 :  tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  128 :  tensor(0.2307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  129 :  tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  130 :  tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  131 :  tensor(0.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  132 :  tensor(0.4288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  133 :  tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  134 :  tensor(0.4917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  135 :  tensor(0.3123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  136 :  tensor(0.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  137 :  tensor(0.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  138 :  tensor(0.1952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  139 :  tensor(0.1489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  140 :  tensor(0.2104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  141 :  tensor(0.2132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  142 :  tensor(0.2931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  143 :  tensor(0.0647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  144 :  tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  145 :  tensor(0.3170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  146 :  tensor(0.3715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  147 :  tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  148 :  tensor(0.1293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  149 :  tensor(0.1413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  150 :  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  151 :  tensor(0.4297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  152 :  tensor(0.1837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  153 :  tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  154 :  tensor(0.2283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  155 :  tensor(0.2393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  156 :  tensor(0.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  157 :  tensor(0.3694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  158 :  tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  159 :  tensor(0.1519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  160 :  tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  161 :  tensor(0.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  162 :  tensor(0.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  163 :  tensor(0.1070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  164 :  tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  165 :  tensor(0.3215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  166 :  tensor(0.1111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  167 :  tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  168 :  tensor(0.4410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  169 :  tensor(0.1430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  170 :  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  171 :  tensor(0.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  172 :  tensor(0.0647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  173 :  tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  174 :  tensor(0.3262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  175 :  tensor(0.3931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  176 :  tensor(0.1901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  177 :  tensor(0.1200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  178 :  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  179 :  tensor(0.3240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  180 :  tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  181 :  tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  182 :  tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  183 :  tensor(0.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  184 :  tensor(0.2437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  185 :  tensor(0.1133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  186 :  tensor(0.0975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  187 :  tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  188 :  tensor(0.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  189 :  tensor(0.1476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  190 :  tensor(0.6590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  191 :  tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  192 :  tensor(0.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  193 :  tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  194 :  tensor(0.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  195 :  tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  196 :  tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  197 :  tensor(0.4644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  198 :  tensor(0.5224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  199 :  tensor(0.4062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  200 :  tensor(0.3718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  201 :  tensor(0.0955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  202 :  tensor(0.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  203 :  tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  204 :  tensor(0.2436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  205 :  tensor(0.4795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  206 :  tensor(0.1780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  207 :  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  208 :  tensor(0.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  209 :  tensor(0.1276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  210 :  tensor(0.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  211 :  tensor(0.1550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  212 :  tensor(0.3113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  213 :  tensor(0.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  214 :  tensor(0.6801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  215 :  tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  216 :  tensor(0.2573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  217 :  tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  218 :  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  219 :  tensor(0.1522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  220 :  tensor(0.2698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  221 :  tensor(0.2448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  222 :  tensor(0.6435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  223 :  tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  224 :  tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  225 :  tensor(0.1275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  226 :  tensor(0.0679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  227 :  tensor(0.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  228 :  tensor(0.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  229 :  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  230 :  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  231 :  tensor(0.1709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  232 :  tensor(0.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  233 :  tensor(0.1810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  234 :  tensor(0.1141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  235 :  tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  236 :  tensor(0.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  237 :  tensor(0.2350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  238 :  tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  239 :  tensor(0.5979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  240 :  tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  241 :  tensor(0.1038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  242 :  tensor(0.2296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  243 :  tensor(0.2554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  244 :  tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  245 :  tensor(0.2819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  246 :  tensor(0.2658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  247 :  tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  248 :  tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  249 :  tensor(0.2868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  250 :  tensor(0.0926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  251 :  tensor(0.3044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  252 :  tensor(0.1510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  253 :  tensor(0.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  254 :  tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  255 :  tensor(0.6749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  256 :  tensor(0.2506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  257 :  tensor(0.2570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  258 :  tensor(0.2493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  259 :  tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  260 :  tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  261 :  tensor(0.1650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  262 :  tensor(0.3263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  263 :  tensor(0.1834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  264 :  tensor(0.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  265 :  tensor(0.2774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  266 :  tensor(0.1705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  267 :  tensor(0.0952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  268 :  tensor(0.1870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  269 :  tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  270 :  tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  271 :  tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  272 :  tensor(0.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  273 :  tensor(0.1565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  274 :  tensor(0.0780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  275 :  tensor(0.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  276 :  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  277 :  tensor(0.1379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  278 :  tensor(0.3401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  279 :  tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  280 :  tensor(0.0480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  281 :  tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  282 :  tensor(0.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  283 :  tensor(0.5407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  284 :  tensor(0.3450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  285 :  tensor(0.3713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  286 :  tensor(0.1007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  287 :  tensor(0.3111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  288 :  tensor(0.1562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  289 :  tensor(0.2580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  290 :  tensor(0.6384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  291 :  tensor(0.3593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  292 :  tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  293 :  tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  294 :  tensor(0.1185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  295 :  tensor(0.2173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  296 :  tensor(0.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  297 :  tensor(0.4889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  298 :  tensor(0.1399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  299 :  tensor(0.1610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  300 :  tensor(0.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  301 :  tensor(0.1601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  302 :  tensor(0.3099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  303 :  tensor(0.3792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  304 :  tensor(0.2572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  305 :  tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  306 :  tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  307 :  tensor(0.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  308 :  tensor(0.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  309 :  tensor(0.3504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  310 :  tensor(0.1583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  311 :  tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  312 :  tensor(0.1480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  313 :  tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  314 :  tensor(0.1024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  315 :  tensor(0.0903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  316 :  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  317 :  tensor(0.3132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  318 :  tensor(0.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  319 :  tensor(0.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  320 :  tensor(0.1335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  321 :  tensor(0.4536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  322 :  tensor(0.2375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  323 :  tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  324 :  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  325 :  tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  326 :  tensor(0.0916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  327 :  tensor(0.2033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  328 :  tensor(0.1701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  329 :  tensor(0.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  330 :  tensor(0.1191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  331 :  tensor(0.2612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  332 :  tensor(0.4595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  333 :  tensor(0.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  334 :  tensor(0.2456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  335 :  tensor(0.4241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  336 :  tensor(0.1338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  337 :  tensor(0.1667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  338 :  tensor(0.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  339 :  tensor(0.5005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  340 :  tensor(0.1507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  341 :  tensor(0.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  342 :  tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  343 :  tensor(0.2935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  344 :  tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  345 :  tensor(0.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  346 :  tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  347 :  tensor(0.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  348 :  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  349 :  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  350 :  tensor(0.1754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  351 :  tensor(0.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  352 :  tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  353 :  tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  354 :  tensor(0.2119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  355 :  tensor(0.1501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  356 :  tensor(0.0949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  357 :  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  358 :  tensor(0.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  359 :  tensor(0.3129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  360 :  tensor(0.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  361 :  tensor(0.2043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  362 :  tensor(0.1076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  363 :  tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  364 :  tensor(0.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  365 :  tensor(0.5966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  366 :  tensor(0.3152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  367 :  tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  368 :  tensor(0.1440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  369 :  tensor(0.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  370 :  tensor(0.4141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  371 :  tensor(0.0933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  372 :  tensor(0.3735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  373 :  tensor(0.3947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  374 :  tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  375 :  tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  376 :  tensor(0.3239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  377 :  tensor(0.4862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  378 :  tensor(0.1207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  379 :  tensor(0.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  380 :  tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  381 :  tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  382 :  tensor(0.2639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  383 :  tensor(0.3646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  384 :  tensor(0.1072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  385 :  tensor(0.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  386 :  tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  387 :  tensor(0.5901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  388 :  tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  389 :  tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  390 :  tensor(0.2939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  391 :  tensor(0.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  392 :  tensor(0.1949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  393 :  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  394 :  tensor(0.4313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  395 :  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  396 :  tensor(0.4516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  397 :  tensor(0.0829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  398 :  tensor(0.4243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  399 :  tensor(0.1169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  400 :  tensor(0.1322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  401 :  tensor(0.2479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  402 :  tensor(0.3006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  403 :  tensor(0.1400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  404 :  tensor(0.2226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  405 :  tensor(0.1569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  406 :  tensor(0.4312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  407 :  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  408 :  tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  409 :  tensor(0.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  410 :  tensor(0.2984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  411 :  tensor(0.3310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  412 :  tensor(0.4373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  413 :  tensor(0.5371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  414 :  tensor(0.2187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  415 :  tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  416 :  tensor(0.3897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  417 :  tensor(0.2555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  418 :  tensor(0.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  419 :  tensor(0.5336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  420 :  tensor(0.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  421 :  tensor(0.2395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  422 :  tensor(0.2264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  423 :  tensor(0.1848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  424 :  tensor(0.1160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  425 :  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  426 :  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  427 :  tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  428 :  tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  429 :  tensor(0.5985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  430 :  tensor(0.1333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  431 :  tensor(0.1333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  432 :  tensor(0.1870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  433 :  tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  434 :  tensor(0.0887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  435 :  tensor(0.0734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  436 :  tensor(0.1479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  437 :  tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  438 :  tensor(0.3787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  439 :  tensor(0.0914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  440 :  tensor(0.1879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  441 :  tensor(0.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  442 :  tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  443 :  tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  444 :  tensor(0.4121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  445 :  tensor(0.5067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  446 :  tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  447 :  tensor(0.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  448 :  tensor(0.2036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  449 :  tensor(0.2320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  450 :  tensor(0.1224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  451 :  tensor(0.1242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  452 :  tensor(0.5951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  453 :  tensor(0.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  454 :  tensor(0.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  455 :  tensor(0.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  456 :  tensor(0.2907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  457 :  tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  458 :  tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  459 :  tensor(0.1244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  460 :  tensor(0.2950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  461 :  tensor(0.1687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  462 :  tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  463 :  tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  464 :  tensor(0.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  465 :  tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  466 :  tensor(0.5303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  467 :  tensor(0.2957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  468 :  tensor(0.1898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  469 :  tensor(0.1777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  470 :  tensor(0.1264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  471 :  tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  472 :  tensor(0.2233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  473 :  tensor(0.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  474 :  tensor(0.2827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  475 :  tensor(0.3458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  476 :  tensor(0.0693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  477 :  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  478 :  tensor(0.5905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  479 :  tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  480 :  tensor(0.1231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  481 :  tensor(0.1935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  482 :  tensor(0.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  483 :  tensor(0.1619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  484 :  tensor(0.1055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  485 :  tensor(0.0444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  486 :  tensor(0.2656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  487 :  tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  488 :  tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  489 :  tensor(0.1096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  490 :  tensor(0.1589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  491 :  tensor(0.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  492 :  tensor(0.3803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  493 :  tensor(0.4163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  494 :  tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  495 :  tensor(0.1112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  496 :  tensor(0.5214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  497 :  tensor(0.1160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  498 :  tensor(0.1298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  499 :  tensor(0.2293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  500 :  tensor(0.1897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  501 :  tensor(0.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  502 :  tensor(0.2702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  503 :  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  504 :  tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  505 :  tensor(0.1375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  506 :  tensor(0.4971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  507 :  tensor(0.1556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  508 :  tensor(0.1141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  509 :  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  510 :  tensor(0.1160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  511 :  tensor(0.1472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  512 :  tensor(0.3721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  513 :  tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  514 :  tensor(0.6876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  515 :  tensor(0.1850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  516 :  tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  517 :  tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  518 :  tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  519 :  tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  520 :  tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  521 :  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  522 :  tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  523 :  tensor(0.0807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  524 :  tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  525 :  tensor(0.1008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  526 :  tensor(0.0896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  527 :  tensor(0.2775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  528 :  tensor(0.3471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  529 :  tensor(0.0760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  530 :  tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  531 :  tensor(0.0580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  532 :  tensor(0.2860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  533 :  tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  534 :  tensor(0.0322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  535 :  tensor(0.2416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  536 :  tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  537 :  tensor(0.0958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  538 :  tensor(0.1303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  539 :  tensor(0.5485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  540 :  tensor(0.2711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  541 :  tensor(0.1243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  542 :  tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  543 :  tensor(0.0807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  544 :  tensor(0.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  545 :  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  546 :  tensor(0.2210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  547 :  tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  548 :  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  549 :  tensor(0.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  550 :  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  551 :  tensor(0.4226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  552 :  tensor(0.1382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  553 :  tensor(0.2186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  554 :  tensor(0.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  555 :  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  556 :  tensor(0.2686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  557 :  tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  558 :  tensor(0.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  559 :  tensor(0.1950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  560 :  tensor(0.1810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  561 :  tensor(0.0890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  562 :  tensor(0.4042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  563 :  tensor(0.4177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  564 :  tensor(0.1921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  565 :  tensor(0.1505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  566 :  tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  567 :  tensor(0.4017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  568 :  tensor(0.1860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  569 :  tensor(0.2257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  570 :  tensor(0.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  571 :  tensor(0.2037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  572 :  tensor(0.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  573 :  tensor(0.3799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  574 :  tensor(0.2684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  575 :  tensor(0.4000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  576 :  tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  577 :  tensor(0.1259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  578 :  tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  579 :  tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  580 :  tensor(0.1826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  581 :  tensor(0.0841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  582 :  tensor(0.1279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  583 :  tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  584 :  tensor(0.3280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  585 :  tensor(0.1159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  586 :  tensor(0.5890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  587 :  tensor(0.1449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  588 :  tensor(0.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  589 :  tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  590 :  tensor(0.3525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  591 :  tensor(0.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  592 :  tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  593 :  tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  594 :  tensor(0.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  595 :  tensor(0.1449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  596 :  tensor(0.3790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  597 :  tensor(0.1997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  598 :  tensor(0.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  599 :  tensor(0.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  600 :  tensor(0.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  601 :  tensor(0.2302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  602 :  tensor(0.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  603 :  tensor(0.5055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  604 :  tensor(0.1385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  605 :  tensor(0.1747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  606 :  tensor(0.1251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  607 :  tensor(0.2178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  608 :  tensor(0.0724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  609 :  tensor(0.1434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  610 :  tensor(0.4189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  611 :  tensor(0.1621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  612 :  tensor(0.1312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  613 :  tensor(0.1820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  614 :  tensor(0.0790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  615 :  tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  616 :  tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  617 :  tensor(0.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  618 :  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  619 :  tensor(0.3963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  620 :  tensor(0.5326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  621 :  tensor(0.1245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  622 :  tensor(0.5528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  623 :  tensor(0.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  624 :  tensor(0.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "TRAIN LOSS: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch : 5\n",
            "Batch  0 :  tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  1 :  tensor(0.2342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  2 :  tensor(0.1921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  3 :  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  4 :  tensor(0.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  5 :  tensor(0.0501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  6 :  tensor(0.1325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  7 :  tensor(0.2267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  8 :  tensor(0.4236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  9 :  tensor(0.3893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  10 :  tensor(0.3344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  11 :  tensor(0.1719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  12 :  tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  13 :  tensor(0.2698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  14 :  tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  15 :  tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  16 :  tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  17 :  tensor(0.2421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  18 :  tensor(0.1108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  19 :  tensor(0.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  20 :  tensor(0.2995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  21 :  tensor(0.0717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  22 :  tensor(0.1217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  23 :  tensor(0.1180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  24 :  tensor(0.2037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  25 :  tensor(0.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  26 :  tensor(0.0575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  27 :  tensor(0.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  28 :  tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  29 :  tensor(0.1004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  30 :  tensor(0.2787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  31 :  tensor(0.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  32 :  tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  33 :  tensor(0.0463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  34 :  tensor(0.1961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  35 :  tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  36 :  tensor(0.1372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  37 :  tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  38 :  tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  39 :  tensor(0.2862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  40 :  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  41 :  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  42 :  tensor(0.1077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  43 :  tensor(0.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  44 :  tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  45 :  tensor(0.1765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  46 :  tensor(0.5288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  47 :  tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  48 :  tensor(0.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  49 :  tensor(0.2416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  50 :  tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  51 :  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  52 :  tensor(0.3173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  53 :  tensor(0.0485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  54 :  tensor(0.1206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  55 :  tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  56 :  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  57 :  tensor(0.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  58 :  tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  59 :  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  60 :  tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  61 :  tensor(0.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  62 :  tensor(0.2501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  63 :  tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  64 :  tensor(0.1551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  65 :  tensor(0.2495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  66 :  tensor(0.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  67 :  tensor(0.1042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  68 :  tensor(0.1800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  69 :  tensor(0.4578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  70 :  tensor(0.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  71 :  tensor(0.1845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  72 :  tensor(0.2524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  73 :  tensor(0.0773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  74 :  tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  75 :  tensor(0.1338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  76 :  tensor(0.1895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  77 :  tensor(0.2927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  78 :  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  79 :  tensor(0.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  80 :  tensor(0.1593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  81 :  tensor(0.1597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  82 :  tensor(0.1209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  83 :  tensor(0.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  84 :  tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  85 :  tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  86 :  tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  87 :  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  88 :  tensor(0.1075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  89 :  tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  90 :  tensor(0.4798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  91 :  tensor(0.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  92 :  tensor(0.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  93 :  tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  94 :  tensor(0.2489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  95 :  tensor(0.2938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  96 :  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  97 :  tensor(0.0957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  98 :  tensor(0.1525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  99 :  tensor(0.1287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  100 :  tensor(0.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  101 :  tensor(0.1820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  102 :  tensor(0.1252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  103 :  tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  104 :  tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  105 :  tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  106 :  tensor(0.1588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  107 :  tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  108 :  tensor(0.1181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  109 :  tensor(0.4965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  110 :  tensor(0.0325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  111 :  tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  112 :  tensor(0.0670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  113 :  tensor(0.0786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  114 :  tensor(0.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  115 :  tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  116 :  tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  117 :  tensor(0.4796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  118 :  tensor(0.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  119 :  tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  120 :  tensor(0.2062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  121 :  tensor(0.0438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  122 :  tensor(0.1795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  123 :  tensor(0.2474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  124 :  tensor(0.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  125 :  tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  126 :  tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  127 :  tensor(0.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  128 :  tensor(0.1178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  129 :  tensor(0.3081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  130 :  tensor(0.3736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  131 :  tensor(0.1077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  132 :  tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  133 :  tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  134 :  tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  135 :  tensor(0.2508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  136 :  tensor(0.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  137 :  tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  138 :  tensor(0.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  139 :  tensor(0.1587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  140 :  tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  141 :  tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  142 :  tensor(0.0845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  143 :  tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  144 :  tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  145 :  tensor(0.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  146 :  tensor(0.0327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  147 :  tensor(0.5438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  148 :  tensor(0.1734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  149 :  tensor(0.6353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  150 :  tensor(0.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  151 :  tensor(0.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  152 :  tensor(0.2528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  153 :  tensor(0.1082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  154 :  tensor(0.3835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  155 :  tensor(0.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  156 :  tensor(0.1449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  157 :  tensor(0.0828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  158 :  tensor(0.2092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  159 :  tensor(0.1377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  160 :  tensor(0.3219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  161 :  tensor(0.2250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  162 :  tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  163 :  tensor(0.2641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  164 :  tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  165 :  tensor(0.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  166 :  tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  167 :  tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  168 :  tensor(0.2819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  169 :  tensor(0.0654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  170 :  tensor(0.1955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  171 :  tensor(0.0955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  172 :  tensor(0.1487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  173 :  tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  174 :  tensor(0.4319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  175 :  tensor(0.1529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  176 :  tensor(0.0970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  177 :  tensor(0.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  178 :  tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  179 :  tensor(0.2266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  180 :  tensor(0.3102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  181 :  tensor(0.2193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  182 :  tensor(0.1252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  183 :  tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  184 :  tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  185 :  tensor(0.1231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  186 :  tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  187 :  tensor(0.3295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  188 :  tensor(0.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  189 :  tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  190 :  tensor(0.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  191 :  tensor(0.1404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  192 :  tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  193 :  tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  194 :  tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  195 :  tensor(0.1411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  196 :  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  197 :  tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  198 :  tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  199 :  tensor(0.1446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  200 :  tensor(0.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  201 :  tensor(0.3510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  202 :  tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  203 :  tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  204 :  tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  205 :  tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  206 :  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  207 :  tensor(0.3201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  208 :  tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  209 :  tensor(0.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  210 :  tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  211 :  tensor(0.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  212 :  tensor(0.2583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  213 :  tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  214 :  tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  215 :  tensor(0.1210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  216 :  tensor(0.2851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  217 :  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  218 :  tensor(0.2904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  219 :  tensor(0.1825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  220 :  tensor(0.2376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  221 :  tensor(0.3993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  222 :  tensor(0.2448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  223 :  tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  224 :  tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  225 :  tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  226 :  tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  227 :  tensor(0.1688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  228 :  tensor(0.1435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  229 :  tensor(0.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  230 :  tensor(0.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  231 :  tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  232 :  tensor(0.0375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  233 :  tensor(0.3405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  234 :  tensor(0.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  235 :  tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  236 :  tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  237 :  tensor(0.0670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  238 :  tensor(0.1066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  239 :  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  240 :  tensor(0.1678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  241 :  tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  242 :  tensor(0.1746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  243 :  tensor(0.4397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  244 :  tensor(0.1318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  245 :  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  246 :  tensor(0.2310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  247 :  tensor(0.5568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  248 :  tensor(0.2297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  249 :  tensor(0.1113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  250 :  tensor(0.1163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  251 :  tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  252 :  tensor(0.3708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  253 :  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  254 :  tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  255 :  tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  256 :  tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  257 :  tensor(0.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  258 :  tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  259 :  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  260 :  tensor(0.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  261 :  tensor(0.1340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  262 :  tensor(0.4001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  263 :  tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  264 :  tensor(0.0735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  265 :  tensor(0.4821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  266 :  tensor(0.1076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  267 :  tensor(0.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  268 :  tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  269 :  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  270 :  tensor(0.1352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  271 :  tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  272 :  tensor(0.1330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  273 :  tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  274 :  tensor(0.0926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  275 :  tensor(0.1253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  276 :  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  277 :  tensor(0.0679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  278 :  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  279 :  tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  280 :  tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  281 :  tensor(0.3523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  282 :  tensor(0.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  283 :  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  284 :  tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  285 :  tensor(0.2748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  286 :  tensor(0.1559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  287 :  tensor(0.0903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  288 :  tensor(0.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  289 :  tensor(0.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  290 :  tensor(0.1287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  291 :  tensor(0.4010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  292 :  tensor(0.3333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  293 :  tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  294 :  tensor(0.1751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  295 :  tensor(0.2209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  296 :  tensor(0.1590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  297 :  tensor(0.0674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  298 :  tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  299 :  tensor(0.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  300 :  tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  301 :  tensor(0.3000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  302 :  tensor(0.2634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  303 :  tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  304 :  tensor(0.4651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  305 :  tensor(0.5063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  306 :  tensor(0.2067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  307 :  tensor(0.0780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  308 :  tensor(0.1526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  309 :  tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  310 :  tensor(0.2246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  311 :  tensor(0.3710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  312 :  tensor(0.2355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  313 :  tensor(0.2085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  314 :  tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  315 :  tensor(0.1977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  316 :  tensor(0.0925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  317 :  tensor(0.0668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  318 :  tensor(0.4798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  319 :  tensor(0.3073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  320 :  tensor(0.2249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  321 :  tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  322 :  tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  323 :  tensor(0.1926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  324 :  tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  325 :  tensor(0.3304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  326 :  tensor(0.1592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  327 :  tensor(0.2018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  328 :  tensor(0.1547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  329 :  tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  330 :  tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  331 :  tensor(0.0788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  332 :  tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  333 :  tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  334 :  tensor(0.3157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  335 :  tensor(0.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  336 :  tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  337 :  tensor(0.3576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  338 :  tensor(0.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  339 :  tensor(0.1287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  340 :  tensor(0.1457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  341 :  tensor(0.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  342 :  tensor(0.4738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  343 :  tensor(0.4641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  344 :  tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  345 :  tensor(0.1036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  346 :  tensor(0.1407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  347 :  tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  348 :  tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  349 :  tensor(0.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  350 :  tensor(0.1236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  351 :  tensor(0.1279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  352 :  tensor(0.0850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  353 :  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  354 :  tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  355 :  tensor(0.1637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  356 :  tensor(0.1939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  357 :  tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  358 :  tensor(0.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  359 :  tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  360 :  tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  361 :  tensor(0.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  362 :  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  363 :  tensor(0.2344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  364 :  tensor(0.3488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  365 :  tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  366 :  tensor(0.1212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  367 :  tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  368 :  tensor(0.1336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  369 :  tensor(0.1356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  370 :  tensor(0.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  371 :  tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  372 :  tensor(0.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  373 :  tensor(0.2553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  374 :  tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  375 :  tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  376 :  tensor(0.2116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  377 :  tensor(0.2470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  378 :  tensor(0.3601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  379 :  tensor(0.1240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  380 :  tensor(0.4172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  381 :  tensor(0.1082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  382 :  tensor(0.2810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  383 :  tensor(0.2498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  384 :  tensor(0.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  385 :  tensor(0.1229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  386 :  tensor(0.1013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  387 :  tensor(0.1891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  388 :  tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  389 :  tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  390 :  tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  391 :  tensor(0.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  392 :  tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  393 :  tensor(0.1430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  394 :  tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  395 :  tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  396 :  tensor(0.0913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  397 :  tensor(0.0783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  398 :  tensor(0.1583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  399 :  tensor(0.5277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  400 :  tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  401 :  tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  402 :  tensor(0.2421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  403 :  tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  404 :  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  405 :  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  406 :  tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  407 :  tensor(0.0553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  408 :  tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  409 :  tensor(0.2783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  410 :  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  411 :  tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  412 :  tensor(0.1376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  413 :  tensor(0.3384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  414 :  tensor(0.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  415 :  tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  416 :  tensor(0.0853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  417 :  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  418 :  tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  419 :  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  420 :  tensor(0.2617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  421 :  tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  422 :  tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  423 :  tensor(0.1516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  424 :  tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  425 :  tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  426 :  tensor(0.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  427 :  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  428 :  tensor(0.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  429 :  tensor(0.1890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  430 :  tensor(0.1777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  431 :  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  432 :  tensor(0.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  433 :  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  434 :  tensor(0.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  435 :  tensor(0.1146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  436 :  tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  437 :  tensor(0.2753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  438 :  tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  439 :  tensor(0.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  440 :  tensor(0.2437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  441 :  tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  442 :  tensor(0.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  443 :  tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  444 :  tensor(0.3072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  445 :  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  446 :  tensor(0.1243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  447 :  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  448 :  tensor(0.1216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  449 :  tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  450 :  tensor(0.1602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  451 :  tensor(0.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  452 :  tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  453 :  tensor(0.1424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  454 :  tensor(0.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  455 :  tensor(0.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  456 :  tensor(0.3441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  457 :  tensor(0.3582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  458 :  tensor(0.0914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  459 :  tensor(0.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  460 :  tensor(0.1060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  461 :  tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  462 :  tensor(0.2518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  463 :  tensor(0.1205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  464 :  tensor(0.1441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  465 :  tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  466 :  tensor(0.2919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  467 :  tensor(0.2245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  468 :  tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  469 :  tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  470 :  tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  471 :  tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  472 :  tensor(0.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  473 :  tensor(0.0760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  474 :  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  475 :  tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  476 :  tensor(0.0935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  477 :  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  478 :  tensor(0.5890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  479 :  tensor(0.2074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  480 :  tensor(0.0966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  481 :  tensor(0.1759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  482 :  tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  483 :  tensor(0.1670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  484 :  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  485 :  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  486 :  tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  487 :  tensor(0.2293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  488 :  tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  489 :  tensor(0.2431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  490 :  tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  491 :  tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  492 :  tensor(0.0781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  493 :  tensor(0.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  494 :  tensor(0.2381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  495 :  tensor(0.3405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  496 :  tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  497 :  tensor(0.1060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  498 :  tensor(0.1354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  499 :  tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  500 :  tensor(0.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  501 :  tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  502 :  tensor(0.1848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  503 :  tensor(0.1779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  504 :  tensor(0.3509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  505 :  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  506 :  tensor(0.1460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  507 :  tensor(0.3022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  508 :  tensor(0.1265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  509 :  tensor(0.0784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  510 :  tensor(0.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  511 :  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  512 :  tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  513 :  tensor(0.1386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  514 :  tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  515 :  tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  516 :  tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  517 :  tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  518 :  tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  519 :  tensor(0.1518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  520 :  tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  521 :  tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  522 :  tensor(0.1048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  523 :  tensor(0.1233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  524 :  tensor(0.1701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  525 :  tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  526 :  tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  527 :  tensor(0.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  528 :  tensor(0.3154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  529 :  tensor(0.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  530 :  tensor(0.1540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  531 :  tensor(0.2554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  532 :  tensor(0.2729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  533 :  tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  534 :  tensor(0.1376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  535 :  tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  536 :  tensor(0.2626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  537 :  tensor(0.0759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  538 :  tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  539 :  tensor(0.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  540 :  tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  541 :  tensor(0.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  542 :  tensor(0.1868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  543 :  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  544 :  tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  545 :  tensor(0.1687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  546 :  tensor(0.5079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  547 :  tensor(0.1923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  548 :  tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  549 :  tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  550 :  tensor(0.1622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  551 :  tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  552 :  tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  553 :  tensor(0.1961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  554 :  tensor(0.2102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  555 :  tensor(0.1530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  556 :  tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  557 :  tensor(0.3144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  558 :  tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  559 :  tensor(0.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  560 :  tensor(0.0677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  561 :  tensor(0.0948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  562 :  tensor(0.2349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  563 :  tensor(0.1925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  564 :  tensor(0.1015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  565 :  tensor(0.2369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  566 :  tensor(0.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  567 :  tensor(0.0982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  568 :  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  569 :  tensor(0.4945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  570 :  tensor(0.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  571 :  tensor(0.2091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  572 :  tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  573 :  tensor(0.4554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  574 :  tensor(0.1437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  575 :  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  576 :  tensor(0.0866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  577 :  tensor(0.2076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  578 :  tensor(0.0964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  579 :  tensor(0.1362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  580 :  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  581 :  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  582 :  tensor(0.0942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  583 :  tensor(0.0651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  584 :  tensor(0.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  585 :  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  586 :  tensor(0.3127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  587 :  tensor(0.2454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  588 :  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  589 :  tensor(0.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  590 :  tensor(0.0828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  591 :  tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  592 :  tensor(0.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  593 :  tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  594 :  tensor(0.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  595 :  tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  596 :  tensor(0.8577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  597 :  tensor(0.2581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  598 :  tensor(0.2689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  599 :  tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  600 :  tensor(0.1103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  601 :  tensor(0.1659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  602 :  tensor(0.4258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  603 :  tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  604 :  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  605 :  tensor(0.1044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  606 :  tensor(0.1560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  607 :  tensor(0.2836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  608 :  tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  609 :  tensor(0.1584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  610 :  tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  611 :  tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  612 :  tensor(0.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  613 :  tensor(0.1464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  614 :  tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  615 :  tensor(0.1361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  616 :  tensor(0.4001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  617 :  tensor(0.3586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  618 :  tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  619 :  tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  620 :  tensor(0.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  621 :  tensor(0.0779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  622 :  tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  623 :  tensor(0.1394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch  624 :  tensor(0.1633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "TRAIN LOSS: tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  j=0\n",
        "  total_train_loss = 0.0\n",
        "  total_eval_loss = 0.0\n",
        "  print(f\"Epoch : {epoch+1}\")\n",
        "  model.train()\n",
        "  for batch in train_dataloader:\n",
        "    \n",
        "    batch = {k: v.to(device) for k,v in batch.items()}  #this will form dictionary like structure.Here k is \"labels\",\"input_ids\",\"attention_masks\"\n",
        " \n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "    print(\"Batch \",j,\": \",loss)\n",
        "    total_train_loss+=loss\n",
        "    run[\"training/batch_train_loss\"].log(loss)\n",
        "    \n",
        "\n",
        "    \n",
        "    loss.backward()  #compute gradient of the weights with respect to loss\n",
        "    optimizer.step()  # optimize means update the weights of the network based on computed gradients\n",
        "   \n",
        "    optimizer.zero_grad()\n",
        "    j=j+1\n",
        "\n",
        "    # model.eval()\n",
        "    # with torch.no_grad():\n",
        "    #   for batch in eval_dataloader:\n",
        "    #     batch = {k: v.to(device) for k,v in batch.items()}\n",
        "    #     outputs = model(**batch)\n",
        "    #     loss = outputs.loss\n",
        "    #     run[\"training/batch_val_loss\"].log(loss)\n",
        "    #     total_eval_loss += loss\n",
        "\n",
        "  print(f\"TRAIN LOSS: \"+ str(total_train_loss/len(train_dataloader)))\n",
        "  #print(f\"VALI LOSS: \"+ str(total_eval_loss/len(eval_dataloader)))\n",
        "\n",
        "  run[\"training/epoch_train_loss\"].log(total_train_loss/len(train_dataloader))\n",
        "  #run[\"training/epoch_val_loss\"].log(total_eval_loss/len(eval_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "H1aiLh-nNSxh"
      },
      "outputs": [],
      "source": [
        "  model_save_name = 'pos_model.pt'\n",
        "  path = F\"/content/drive/My Drive/{model_save_name}\" \n",
        "  torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qyNaPX-uQQhc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def accuracy_fun3(actual_label, predicted_label):\n",
        "  correct=0\n",
        "  total=0\n",
        "\n",
        "  for i in range(actual_label.shape[0]):\n",
        "    actual_new = []\n",
        "    predicted_new = []\n",
        "    for j in range(actual_label.shape[1]):\n",
        "      \n",
        "      if actual_label[i][j]!=-100:\n",
        "        actual_new.append(actual_label[i][j])\n",
        "        predicted_new.append(predicted_label[i][j])\n",
        "    \n",
        "    actual_new_ten = torch.stack(actual_new, dim=0)  # 1d tensor for single sentence\n",
        "    predicted_new_ten = torch.stack(predicted_new, dim=0)\n",
        "    #print(actual_new_ten.shape[0])\n",
        "    for k in range(actual_new_ten.shape[0]):\n",
        "      if actual_new_ten[k] == predicted_new_ten[k]:\n",
        "        correct+=1\n",
        "      total+=1\n",
        "\n",
        "  return correct, total\n",
        "\n",
        "\n",
        "def remove_padding(actual_label,predicted_label):\n",
        "  act= torch.Tensor()\n",
        "  pred=torch.Tensor()\n",
        "  act = act.to(device)\n",
        "  pred = pred.to(device)\n",
        "  for i in range(actual_label.shape[0]):\n",
        "  \n",
        "    actual_new = []\n",
        "    predicted_new = []\n",
        "    actual_new_ten = torch.Tensor()\n",
        "    predicted_new_ten = torch.Tensor()\n",
        "    actual_new_ten = actual_new_ten.to(device)\n",
        "    \n",
        "    predicted_new_ten = predicted_new_ten.to(device)\n",
        "    for j in range(actual_label.shape[1]):\n",
        "    \n",
        "\n",
        "      if actual_label[i][j]!=-100:\n",
        "        actual_new.append(actual_label[i][j])\n",
        "        predicted_new.append(predicted_label[i][j])\n",
        "\n",
        "\n",
        "    actual_new_ten = torch.stack(actual_new, dim=0)   # 1d tensor for a single sentence\n",
        "    predicted_new_ten = torch.stack(predicted_new, dim=0)\n",
        "    \n",
        "\n",
        "    act = torch.cat((act,actual_new_ten), dim=0)  # 1d tensor for entire batch\n",
        "    pred = torch.cat((pred, predicted_new_ten), dim=0)  # 1d tensor for entire batch\n",
        "\n",
        "  return act, pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING"
      ],
      "metadata": {
        "id": "zxIodTifgZ9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ikMaa2ybz-N",
        "outputId": "d031d3a6-b456-4443-983c-49aead8b2246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[ 15618    146    102    142     56    109     26     48     55     12\n",
            "      76    215      4     21     52      7      0      0]\n",
            " [    58  21355    108     54     44     78      3     45     70      8\n",
            "       8    286      0     67     14      0      0      0]\n",
            " [    49     19  42649    627    103    323      7    306     25     17\n",
            "      41     55      5      3      8      8      0      0]\n",
            " [   114    136    128  83785    535   4762    267   1756    126    195\n",
            "     186    888      2     67     46     17      0      0]\n",
            " [    94     17    438    344  50570    596     22    132    159     90\n",
            "      18     91      1     50     93     42      0      0]\n",
            " [   108    121    117   3342    202 121700    173   1192     83    326\n",
            "     143    312      2    134     21    105      0      0]\n",
            " [     1      0      0     21      0    128  19057      2      0      6\n",
            "       0      0      0      0      0      0      0      0]\n",
            " [    15     15     26   2085     85   1362     33  27315    155     40\n",
            "      38    491      0     15     13      0      0      0]\n",
            " [    38     17     19    217    152    292     28    272  10599      4\n",
            "      23    146      2      8     43      0      0      0]\n",
            " [    11      5      7    176     27    271     39     42      5  16999\n",
            "      15     11      0      6      3     42      0      0]\n",
            " [    35     19     58    120     27    161     12     67     33     12\n",
            "   12065     68      1     10      9      0      0      0]\n",
            " [   134     74    190   1591    330    767     25    865     75     27\n",
            "      39  35822      0     78     51      1      0      0]\n",
            " [   112     38     87    124     47    359      3     53     28     26\n",
            "      63     83      7      9     36      0      0      0]\n",
            " [     3     33     10     53    110     50      1     11     10      5\n",
            "       6    147      0   5765      0      0      0      0]\n",
            " [   119     10     46     28    214     50      2      5     22      3\n",
            "       9     12      1      3   4198      1      0      0]\n",
            " [     2      0      0     33      7    187      1     16     17     34\n",
            "       4      1      0      9      1    129      0      0]\n",
            " [     3      0      1     44      5     71      1      6     10      0\n",
            "       0      5      2      0      0      4     16      0]\n",
            " [     0      0      0      4      0      7      0      0      0     16\n",
            "       0      1      0      0      0      7      0      0]]\n",
            "Validation Accuracy 3: 0.9300636020476757\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "sum=0.0\n",
        "sum2=0.0\n",
        "\n",
        "i=0\n",
        "recent_correct=0\n",
        "recent_total=0\n",
        "\n",
        "act= torch.Tensor()\n",
        "pred=torch.Tensor()\n",
        "\n",
        "act = act.to(device)\n",
        "pred = pred.to(device)\n",
        "for batch in eval_dataloader:\n",
        "  batch = {k: v.to(device) for k,v in batch.items()}\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**batch)     # no gradient calculation\n",
        "  \n",
        "  loss = outputs.loss\n",
        "  logits = outputs.logits\n",
        "  predictions = torch.argmax(logits, dim=-1)      # argmax is applied along last dimension\n",
        "  \n",
        "  predictions.to(device)\n",
        "  \n",
        "  correct, total = accuracy_fun3(batch[\"labels\"], predictions)  #correct and total for batch\n",
        "  recent_correct+=correct\n",
        "  recent_total+=total\n",
        "\n",
        "  ground_truth, predic = remove_padding(batch[\"labels\"], predictions) \n",
        "  act = torch.cat((act,ground_truth), dim=0)  # 1d tensor for entire dataloader\n",
        "  pred = torch.cat((pred, predic), dim=0)  # 1d tensor for entire dataloader\n",
        "\n",
        "\n",
        "act = act.detach().cpu().numpy()\n",
        "pred = pred.detach().cpu().numpy()\n",
        "\n",
        "cm = confusion_matrix(act, pred,labels=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17])\n",
        "print(type(cm))\n",
        "print(cm)\n",
        "\n",
        "\n",
        "acc3 = recent_correct/recent_total\n",
        "  \n",
        "print(\"Validation Accuracy 3: \" + str(acc3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiSgWtdL4LvC"
      },
      "outputs": [],
      "source": [
        "run[\"validation/accuracy\"] = acc3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XlQibH-pn6Dm",
        "outputId": "3260302f-c45b-41a0-9764-3aa220b08101"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f71782d7340>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17])\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "disp.plot(ax=ax)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DE1JK17tiEsP"
      },
      "outputs": [],
      "source": [
        "run[\"validation/cm\"].upload(fig)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff7c6524f6c74659bfdc058328daa632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfd432854bdd4cb7bb635b93bfff0cae",
              "IPY_MODEL_5d6da665b56241fdbe6c0d5d814b6665",
              "IPY_MODEL_b7e51d07e93540eab6264db0a7531b55"
            ],
            "layout": "IPY_MODEL_a71a3385cf6b4432974c55f0c19934f8"
          }
        },
        "dfd432854bdd4cb7bb635b93bfff0cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ba470d8a3d4b27ad8367623307d4bf",
            "placeholder": "​",
            "style": "IPY_MODEL_99ab02e502bb4a0488ae2e777e810355",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "5d6da665b56241fdbe6c0d5d814b6665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0374c77185941d5b21d7edca7e17ccf",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14edc4bf48644cb094ecd4efe5c81795",
            "value": 29
          }
        },
        "b7e51d07e93540eab6264db0a7531b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78e06f1432f0494bb036dca504dfdb1e",
            "placeholder": "​",
            "style": "IPY_MODEL_cb65876576874200871b32071c25671a",
            "value": " 29.0/29.0 [00:00&lt;00:00, 851B/s]"
          }
        },
        "a71a3385cf6b4432974c55f0c19934f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ba470d8a3d4b27ad8367623307d4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ab02e502bb4a0488ae2e777e810355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0374c77185941d5b21d7edca7e17ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14edc4bf48644cb094ecd4efe5c81795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78e06f1432f0494bb036dca504dfdb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb65876576874200871b32071c25671a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af370a0a35f84d55a781d16dde8f6010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bd30675bf0743bc86f895f24d2d0287",
              "IPY_MODEL_f6ecfc1766834469a4d21718dd5cb6fb",
              "IPY_MODEL_8cfb33d9c4244be0854966dd23a0b2ac"
            ],
            "layout": "IPY_MODEL_03fcee6969cb4313ac1c737cb69cf4b1"
          }
        },
        "4bd30675bf0743bc86f895f24d2d0287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9983f33465ee46e5aaf21693f1812ca3",
            "placeholder": "​",
            "style": "IPY_MODEL_8ae1de94e26b4276985fa79181d67896",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "f6ecfc1766834469a4d21718dd5cb6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14762929b6a6481380e38ce9d517e40c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be8482e8804c4483894ebd1756014c4a",
            "value": 570
          }
        },
        "8cfb33d9c4244be0854966dd23a0b2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6edce16893348328ab461e67a66de90",
            "placeholder": "​",
            "style": "IPY_MODEL_75b686fcc51e47adb8b207367a1f848c",
            "value": " 570/570 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "03fcee6969cb4313ac1c737cb69cf4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9983f33465ee46e5aaf21693f1812ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae1de94e26b4276985fa79181d67896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14762929b6a6481380e38ce9d517e40c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8482e8804c4483894ebd1756014c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6edce16893348328ab461e67a66de90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b686fcc51e47adb8b207367a1f848c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef61595ad26e45b18c0cd3e9abed4dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae9d20c281094f0c86a6e2349907e43e",
              "IPY_MODEL_23735a9cd0094049a0c366f8c3650504",
              "IPY_MODEL_63f6e9ae55584721965697c42a565108"
            ],
            "layout": "IPY_MODEL_29ecc76d04ae4e6f8b50264a2eb64c0e"
          }
        },
        "ae9d20c281094f0c86a6e2349907e43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36ccd5a55b324ff4be93647bad596d1e",
            "placeholder": "​",
            "style": "IPY_MODEL_05183ccae2fb42b48d9b414649963def",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "23735a9cd0094049a0c366f8c3650504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9774c56c1bf54a13a14ca0540d1845d1",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b786f7de85a8451c8d559c448fe02503",
            "value": 213450
          }
        },
        "63f6e9ae55584721965697c42a565108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff25082d9a884c8d80da53b254ac1855",
            "placeholder": "​",
            "style": "IPY_MODEL_892bd00d605643eb93bc12bf261f030a",
            "value": " 213k/213k [00:00&lt;00:00, 1.71MB/s]"
          }
        },
        "29ecc76d04ae4e6f8b50264a2eb64c0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ccd5a55b324ff4be93647bad596d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05183ccae2fb42b48d9b414649963def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9774c56c1bf54a13a14ca0540d1845d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b786f7de85a8451c8d559c448fe02503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff25082d9a884c8d80da53b254ac1855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892bd00d605643eb93bc12bf261f030a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d82fe389b67c42febf2dc87395ead953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88722dceb5344b699eb70440e8eabc44",
              "IPY_MODEL_cc29b3b6516f4e92b76a120719f56372",
              "IPY_MODEL_c4ebc5a2310e408984e3e751d96818c5"
            ],
            "layout": "IPY_MODEL_b82ef592db634da4b9993c2324076d30"
          }
        },
        "88722dceb5344b699eb70440e8eabc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e84190e863b140e4921cee986eea5513",
            "placeholder": "​",
            "style": "IPY_MODEL_0198a1c5b7b4439ebf414ac51fbae123",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "cc29b3b6516f4e92b76a120719f56372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5699a2d020f41a380a35d2ad9905487",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a6c9cd404ea4a47991bfebfa786e9fb",
            "value": 435797
          }
        },
        "c4ebc5a2310e408984e3e751d96818c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc0a3408ceb34961952112fb28322e72",
            "placeholder": "​",
            "style": "IPY_MODEL_ecc822cd94db4d6aadee326fa64fc938",
            "value": " 436k/436k [00:00&lt;00:00, 2.45MB/s]"
          }
        },
        "b82ef592db634da4b9993c2324076d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84190e863b140e4921cee986eea5513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0198a1c5b7b4439ebf414ac51fbae123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5699a2d020f41a380a35d2ad9905487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6c9cd404ea4a47991bfebfa786e9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc0a3408ceb34961952112fb28322e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc822cd94db4d6aadee326fa64fc938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3358278e90b9458d88390fbbb2e6cb6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbc07186385c4b37b50eb727662771ba",
              "IPY_MODEL_175d284632e1436e8addeeed81d5322d",
              "IPY_MODEL_8e290ceaf69d4c999ac6f8a29a7c011a"
            ],
            "layout": "IPY_MODEL_fad7256560b049b5a68b68d80420140e"
          }
        },
        "cbc07186385c4b37b50eb727662771ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ffcc7274ba94dca8951744ac308f3f6",
            "placeholder": "​",
            "style": "IPY_MODEL_3757c2b535954390812fd851bc2fac50",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "175d284632e1436e8addeeed81d5322d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ee25a8a525470a843e86b874de4663",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2b357cf59964412a09d5b0227d9ada3",
            "value": 435779157
          }
        },
        "8e290ceaf69d4c999ac6f8a29a7c011a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1285747a9da440c9bd8c3a9458938dc2",
            "placeholder": "​",
            "style": "IPY_MODEL_7916d1a4ee2c4c3e9aea19aa757b6118",
            "value": " 436M/436M [00:04&lt;00:00, 111MB/s]"
          }
        },
        "fad7256560b049b5a68b68d80420140e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ffcc7274ba94dca8951744ac308f3f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3757c2b535954390812fd851bc2fac50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05ee25a8a525470a843e86b874de4663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b357cf59964412a09d5b0227d9ada3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1285747a9da440c9bd8c3a9458938dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7916d1a4ee2c4c3e9aea19aa757b6118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}